<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[后端架构图]]></title>
    <url>%2F2020%2F04%2F11%2F%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[后端架构基础组件多线程 队列 高性能网络层 插件 压缩 加密 反射 调度 特性 扩张方法 表达式树基础监控业务监控业务操作完成量 业务操作完成时间用户行为访问人数、在线人数 访问热点 访问轨迹软件应用监控执行性能，性能趋势报表图 页面级别 方法级别 数据库操作 可用性 服务、页面使用量 开源组件性能监视软件系统监控磁盘 内存 CPU 网络硬件监控硬件资源的消耗趋势（容量规划） 硬件资源的使用趋势（细化到进程） 硬件资源的总体利用率通用报警基于统计值 基于状态 事件处理流程 短信群发平台 集中化配置 邮件、短信通道 跨平台的客户端 分组+权限+自定义间隔 信息模板 细节报警信息页面引擎MVC扩展基础横切组件封装（ActionFilter等） 模板集中存储+后台修改 IOC支持 执行性能 组件全局注册轻量级的ashx容器组件脚本样式合并 分布式会话 验证码 各种控件横切关注日志、异常、状态信息集中收集 MongoDB 后台集中查阅 自动附加信息 异步队列提交通用性能只要提供Dictionary&lt;string.long&gt;数据源就可以实现性能监控 多级分组 通用性能查看后台（highchart+ajax) 支持各个粒度的数据聚合 数据类型支持TextValue、TotalValue、StateValue、ExpressionValue 数据源支持推模式和拉模式缓存本地缓存 远端缓存 基于Redis 各种过期模式 平滑过期 绝对时间过期 依赖过期 过期回调 容量限制配置配置集中化（消除本地配置） 支持横向扩容（同步） 支持复杂类型（自定义类型） 列表 字典 枚举 继承 抽象类 配置后台（考虑多环境同步问题) 考虑实现配置实用率跟踪 自动根据默认值初始化 考虑默认值的使用策略 全局配配置和私有配置，支持分组 更新回调 考虑细化到某个点 基于行的版本（同步）控制 高性能 缓存+数据库同步任意数据的同步支持 水平扩容支持 拉模式和推模式支持NOSQL客户端配置集中 统一的客户端 集群管理权限IOCAOP分布式数据访问ORM特性查询表达器 缓存（多级） 关系 延迟加载 映射配置 代码生成 多数据库支持 锁支持 枚举支持其他特性监控性能 NOSQL集成 领域驱动支持Shard特性分库规则和路由 分表规则和路由 集群 高可用 负载均衡策略 软负载 可用性探测 读写分离 高性能 分布式事物 多写 迁移辅助 基于元数据还是映射的策略 跨节点排序分页支持服务端组件 分布式文件系统 分布式缓存系统 分布式计算 分布式存储系统 分布式队列系统 分布式计数器 分布式锁 分布式服务远程调用同步调用 异步调用 双向调用 事件回调 （软）负载均衡 随机、轮训、最小调用 高级QoS均衡 根据性能决定均衡策略 失败容错 重试、日志、后台容错 调用拦截 增加横切 平滑重启 优雅升降级 分布式事务 批量调用 提高性能 本地伪装 本地Mock逻辑用于容错 隐式传参 客户端和服务端同步上下文 服务分组 允许一个接口多种实现 客户端代理生成插件 异步调用协议集成Hession WebService Protobuf 自定义二进制序列化集群监控可用性 性能 版本 路径 依赖动态部署服务容器 守护、更新 自动部署 平滑回滚服务治理服务注册发现 服务测试 服务路由 机房感知、机器、上下文 服务安全限制 调用验证 信息加密 服务依赖关系 服务负责人 信息通知 服务文档 服务声明周期 服务命名空间 服务限流 并发、流程脑图]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>脑图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架]]></title>
    <url>%2F2020%2F04%2F11%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Java集合框架CollectionListArrayList 排列有序，可重复 底层使用数组 速度快，增删慢，getter()和setter()快 线程不安全 当容量不够，ArrayList是当前容量*1.5+1 Vector 排列有序，可重复 底层使用数组 速度快，增删慢 线程安全，效率低 当容量不够，默认扩张一倍容量 LinkedList 排列有序，可重复 底层使用双向循环链表数据结构 查询速度慢，增删快，add（）和remove（）方法快 线程不安全SetHashSet 排列无序，不可重复 底层使用hash表实现 存取速度快 内部是HashMap TreeSet 排列无序，不可重复 底层使用二叉树实现 排序存储 内部是TreeMap的SortedSet LinkedHashSet 采用Hash表存储，并用双向链表记录插入顺序 内部是LinkedHashMapQueue在两端出入的List，所以也可以用数组或链表来实现MapHashMap键不可重复，值可重复 底层hash表 线程不安全 允许key值为null，值为nullHashTable键不可重复，值可重复 底层Hash表 线程安全 键和值都不可为nullTreeMap键不可重复，值可重复 底层二叉树思维导图]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>集合，面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring常见问题总结]]></title>
    <url>%2F2020%2F04%2F10%2FSpring%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Spring常见问题总结 引用自 1 什么是 Spring 框架?我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：核心容器、数据访问/集成,、Web、AOP（面向切面编程）、工具、消息和测试模块。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。 2 Spring 官网列出的 Spring 的 6 个特征: 核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。 数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。 Web支持 : Spring MVC和Spring WebFlux Web框架。 集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。 语言 ：Kotlin，Groovy，动态语言。 3 列举一些重要的Spring模块？ Spring Core： 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注入功能。 Spring Aspects ：该模块为与AspectJ的集成提供支持。 Spring AOP ：提供了面向切面的编程实现。 Spring JDBC : Java数据库连接。 Spring JMS ：Java消息服务。 Spring ORM : 用于支持Hibernate等ORM工具。 Spring Web : 为创建Web应用程序提供支持。 Spring Test : 提供了对 JUnit 和 TestNG 测试的支持。 4 @RestController vs @Controller Controller 返回一个页面 对应于前后端不分离的情况。 如果你需要在Spring4之前开发 RESTful Web服务的话，你需要使用@Controller 并结合@ResponseBody注解，也就是说@Controller +@ResponseBody= @RestController（Spring 4 之后新加的注解）。 @RestController 返回JSON 或 XML 形式数据 前后端分离 5 谈谈自己对于 Spring IoC 和 AOP 的理解 IoC（Inverse of Control:控制反转）是一种设计思想 将原本在程序中手动创建对象的控制权，交由Spring框架来管理 IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。 AOP(Aspect-Oriented Programming:面向切面编程 事务处理、日志管理、权限控制 减少系统的重复代码，降低模块间的耦合度 Spring AOP就是基于动态代理的 如果要代理的对象，实现了某个接口，那么Spring AOP会使用JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用Cglib ，这时候Spring AOP会使用 Cglib 生成一个被代理对象的子类来作为代理 6 Spring AOP 和 AspectJ AOP 有什么区别？ Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ AspectJ 相比于 Spring AOP 功能更加强大 Spring AOP 相对来说更简单， 切面比较少，那么两者性能差异不大 当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。 7 Spring 中的 bean 的作用域有哪些? singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。 session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。 global-session：全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话 8 Spring 中的单例 bean 的线程安全问题了解吗？ 当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题 在Bean对象中尽量避免定义可变的成员变量（不太现实）。 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 9 Spring 中的 bean 生命周期? Bean 容器找到配置文件中 Spring Bean 的定义。 Bean 容器利用 Java Reflection API 创建一个Bean的实例。 如果涉及到一些属性值 利用 set()方法设置一些属性值。 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入Bean的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果Bean实现了 BeanFactoryAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoade r对象的实例。 与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法 当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。 10 说说自己对于 Spring MVC 了解? Model1 时代 整个 Web 应用几乎全部用 JSP 页面组成，只用少量的 JavaBean 来处理数据库连接、访问等操作 ①将控制逻辑和表现逻辑混杂在一起，导致代码重用率极低； ②前端和后端相互依赖，难以进行测试并且开发效率极低； Model2 时代即JavaWeb MVC “Java Bean(Model)+ JSP（View,）+Servlet（Controller） 重复造轮子 应运而生比如Struts2但是 Struts2 比较笨重 Spring MVC 使用更加简单和方便 开发效率更高，并且 Spring MVC 运行速度更快。 SpringMVC 工作原理 流程说明（重要）： 1：客户端（浏览器）发送请求，直接请求到 DispatcherServlet。 2： DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。 3： 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。 4：HandlerAdapter 会根据 Handler来调用真正的处理器开处理请求，并处理相应的业务逻辑。 5： 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。 6： ViewResolver 会根据逻辑 View 查找实际的 View。 7：DispaterServlet 把返回的 Model 传给 View（视图渲染）。 8：把 View 返回给请求者（浏览器） 11 Spring 框架中用到了哪些设计模式？ 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 12 @Component 和 @Bean 的区别是什么？ 作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。 @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。 13 将一个类声明为Spring的 bean 的注解有哪些? 使用 @Autowired 注解自动装配 bean @Component ：通用的注解，可标注任意类为 Spring 组件。如果一个Bean不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。 @Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。 14 Spring 管理事务的方式有几种？ 编程式事务，在代码中硬编码。(不推荐使用) 声明式事务，在配置文件中配置（推荐使用） 基于XML的声明式事务 基于注解的声明式事务 15 Spring 事务中的隔离级别有哪几种? TransactionDefinition.ISOLATION_DEFAULT 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别. TransactionDefinition.ISOLATION_READ_UNCOMMITTED 最低的隔离级别，允许读取尚未提交的数据变更 可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED 允许读取并发事务已经提交的数据 可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改 可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰， 该级别可以防止脏读、不可重复读以及幻读 严重影响程序的性能。通常情况下也不会用到该级别。 16 Spring 事务中哪几种事务传播行为? 支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRED 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 不支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRES_NEW 创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER 以非事务方式运行，如果当前存在事务，则抛出异常。 其他情况： TransactionDefinition.PROPAGATION_NESTED 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 17 @Transactional(rollbackFor = Exception.class)注解了解吗？ Exception分为运行时异常RuntimeException和非运行时异常 Transactional 如果类或者方法加了这个注解，那么这个类里面的方法抛出异常，就会回滚 不配置rollbackFor属性，事物只会在遇到RuntimeException的时候才会回滚 加上rollbackFor=Exception.class,可以让事物在遇到非运行时异常时也回滚。 18 如何使用JPA在数据库中非持久化一个字段？ static 修饰 final 修饰 transient 修饰 @Transient 注解修饰 思维导图]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精细阅读的杀手锏——SQ3R阅读法]]></title>
    <url>%2F2020%2F04%2F10%2F%E7%B2%BE%E7%BB%86%E9%98%85%E8%AF%BB%E7%9A%84%E6%9D%80%E6%89%8B%E9%94%8F%E2%80%94%E2%80%94SQ3R%E9%98%85%E8%AF%BB%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一. 什么是SQ3R阅读法 美国俄亥俄州州立大学心理学教授罗宾逊（F. P. Robinson） 1946年在他的著作Effective Study有所提及 综览（Survey）、发问（Question）、阅读（Read）、背诵（Recite）、复习（Review） 二. SQ3R阅读法的具体实施步骤1. Survey阶段 封面、扉页、前言 目录 各级标题 开头和结尾 2. Question阶段 这本书/这篇文章主要说的什么 掌握了多少？ 提问贯穿于整个阅读过程 只要有问题，你都可以用笔或借助电子设备将问题记录下来。 布朗和基利的《学会提问》 3.Read阶段加粗字段、重点图标 阅读难度较高的篇章时要放慢速度。 遇到不明白的地方，要停下来，再重读一遍。 一次只阅读一小段并背诵那一段。 阅读辅助说明的图象。 ——Study Guides and Strategies 博客网站4. Recite阶段非背诵，而是复述，尽可能多和详细 听、说、读、写 联想记忆法 关键词记忆法 谐音等记忆法5. Review阶段 Recite后半天Review一次； 一天后再Review一次； 三天后再Review一次； 一个星期后再Review一次； 一个月后再简单地Review一次。 思维导图]]></content>
      <tags>
        <tag>学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运动改造大脑]]></title>
    <url>%2F2020%2F04%2F07%2F%E8%BF%90%E5%8A%A8%E6%94%B9%E9%80%A0%E5%A4%A7%E8%84%91%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>读后感</category>
      </categories>
      <tags>
        <tag>运动，读后感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出Java多线程]]></title>
    <url>%2F2020%2F04%2F03%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[基础篇进程与线程的基本概念进程产生的背景指令—》指令集（批处理） 缺点：串行，效率低 进程： 应用程序在内存中分配的空间，正在运行的程序。 进程优点： 操作系统并发成为可能。 线程: 一个线程执行一个子任务，一个进程包含多个线程。 优点：让进程的内部并发成为了可能。 多进程的方式也可以实现并发，为什么我们要使用多线程？ 进程通信复杂，线程间可共享资源，通信较线程容易; 进程重量级，线程轻量级，系统开销小。 进程线程的区别？ 本质区别：能否单独占有内存空间及其他系统资源（如：I/O); 进程是操作系统进行资源分配的基本单位，而线程是操作系统进行系统调度的基本单位，即CPU时间的分配单位。 上下文切换上下文： 某一时间点CPU寄存器和程序计数器的内容。 上下文切换: CPU从一个进程/线程切换到另一个进程/线程。 缺点： 上先文切换是计算密集型的，消耗大量的CPU时间，故线程也不是越多越好。 java多线程入门类和接口Thread类和Runnable接口Java如何实现多线程？ 继承Thread类，并重写run()方法。 实现Runnable接口的run()方法。 继承Thread类需注意什么？ thread.start()方法后，该线程才算启动，调用start()后，虚拟机会先为我们创建一个线程，然后等到这个线程第一次得到时间片时，再调用run()方法。start()不可多次调用，否则抛异常。 Java8函数式编程 new Thread(()-&gt;{System.out.println(&quot;java8&quot;);}).start();Thread类的构造方法 Thread(Runnable target) Thread(Runnable target, String name)Thread类的几个常用方法 currentThread(); // 静态方法，返回正在执行线程的引用。 start(); // 启动线程。 yield(); // 让出当前处理器的占用。 sleep(); // 静态方法，休眠。 join(); // 当前线程等待另一个线程执行完毕后再继续执行。内部调用的Object.wait()。Thread类与Runnable比较？ Java单继承多实现，Runnable比Thread灵活； Runnable更符合面向对象，将线程单独进行对象的封装; Runnable降低了线程对象和线程任务的耦合性； 若不用Thread类诸多方法，Runnable更轻量级，适合实现多线程。 Callable、Future与FutureTask为啥用Callable Future FutureTask?因为Runnable和Thread创建的线程没有返回值。当我们希望开启一个线程执行完一个任务后有返回值则用以上方式（异步模型）。 Callable特点？ 有返回值，支持泛型 Callable咋用？ 伪代码 ExecutorService.submit(Callable) return一个Future， 通过Future的get方法获取结果。Future接口注意项 cancel() 试图取消，并不一定取消成功。 FutureTask类总结 Future类的实现类。 FutureTask实现了RunnableFuture接口，RunnableFuture同时继承了Runnable接口和Future接口。 为什么要用FutureTask?高并发下，Callable和FutureTask会创建多次。FutureTask能确保任务只执行一次。 FutureTask有几个状态?分别是？及其转换关系？六个状态分别是： NEW = 0 // 新建 COMPLETING = 1 // 完成 NORMAL = 2 // 正常 EXCEPTIONAL = 3 // 异常 CANCELLED = 4 // 取消 INTERRUPTING = 5 // 打断中 INTERRUPTED = 6 // 打断了的 转变路径 0 -&gt; 1 -&gt; 2 0 -&gt; 1 -&gt; 3 0 -&gt; 4 0 -&gt; 5 -&gt; 6线程组和线程优先级线程组（ThreadGroup）线程组作用？ java线程的状态和主要转化方法Java线程间的通信Java内存模型基础知识Java内存模型基础知识重排序与happens-beforevolatilesynchronized与锁CAS与原子操作AQSJDK工具线程池原理阻塞队列锁接口和类并发集合容器简介CopyOnWrite通信工具类Fork/Join框架Java8 Stream并行计算原理计划任务]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM]]></title>
    <url>%2F2020%2F03%2F29%2FJVM%2F</url>
    <content type="text"><![CDATA[第一讲 初识JVMJVM概念 JVM发展历史 JVM种类 JAVA语言规范 语法 变量 类型 文法 JVM规范 Class文件类型 运行时数据 帧栈 虚拟机的启动 虚拟机的指令集 Class 文件格式数字的内部表示和存储Byte -128 to 127 (-27 to 27 - 1)returnAddress 数据类型定义指向操作码的指针。不对应Java数据类型，不能在运行时修改。Finally实现需要定义PC堆栈方法区]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试准备]]></title>
    <url>%2F2020%2F03%2F28%2F%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[redis 缓存雪崩(多个key过期)缓存雪崩： 我们可以简单的理解为：由同一时间热点缓存大面积失效，(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。 解决办法： 大多数系统设计者考虑用加锁（ 最多的解决方案）或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时将缓存失效时间分散开。 或者设置热点数据永不过期，有更新操作的时候更新下缓存，电商首页用这个策略，保险 缓存击穿（当单个key过期）问题：一些设置了过期时间的key，这些key可能会在某些时间点被超高并发访问，是一种非常热点的数据，这个时候请求发现缓存过期了，会直接读取db，大并发可能会搞垮db 解决方案0：热点数据永不过期 解决方案1：使用互斥锁：（SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。） 业界比较常用的方式是使用metex。简单的来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（setnx）去set一个mutex key，当操作成功时，再进行load db的操作并设置缓存，否则就重试整个get缓存的方法 优点：思路简单、保证一致性 缺点：代码复杂度增大、存在死锁的风险 12345678910111213141516String get(String key) &#123; String value = redis.get(key); if (value == null) &#123; if (redis.setnx(key_mutex, "1")) &#123; // 3 min timeout to avoid mutex holder crash redis.expire(key_mutex, 3 * 60) value = db.get(key); redis.set(key, value); redis.delete(key_mutex); &#125; else &#123; //其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; &#125; 解决方案2：异步构建缓存 在这种方案下，构建缓存采取异步策略，会从线程池中取线程来异步构建缓存，从而不会让所有的请求直接怼到数据库上。该方案redis自己维护一个timeout，当timeout小于System.currentTimeMillis()时，则进行缓存更新，否则直接返回value值。 优点：用户无需等待 缺点：无法保证缓存一致性 集群环境的redis代码如下所示: 123456789101112131415161718192021String get(final String key) &#123; V v = redis.get(key); String value = v.getValue(); long timeout = v.getTimeout(); if (v.timeout &lt;= System.currentTimeMillis()) &#123; // 异步更新后台异常执行 threadPool.execute(new Runnable() &#123; public void run() &#123; String keyMutex = "mutex:" + key; if (redis.setnx(keyMutex, "1")) &#123; // 3 min timeout to avoid mutex holder crash redis.expire(keyMutex, 3 * 60); String dbValue = db.get(key); redis.set(key, dbValue); redis.delete(keyMutex); &#125; &#125; &#125;); &#125; return value; &#125; 解决方案3： 布隆过滤器 优点：思路简单、保证一致性、性能强 缺点：代码复杂度增大、需要另外维护一个集合来存放缓存的key、不支持删值操作 缓存穿透问题：查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果db查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到db去，在流量大时，db可能就挂掉了 比如说：查询一个不存在id都是1开始自增上去的，如果查询一个id为-1的值 解决方案： 接口添加校验，比如用户鉴权，参数合法校验，比如id&lt;0的直接拦截等。 1.最常见的就是布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力 2.更简单粗暴的方法：如果一个查询返回的数据为空（不管数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，设置一个比较短的过期时间 双写一致问题数据库跟缓存同时操作肯定会出现不一致的问题 解决方案：延时双删策略 先删除redis，更新数据库，删除redis 参考文章：https://www.cnblogs.com/rjzheng/p/9041659.html redis与memcached有什么区别？为什么选用redis作为缓存的中间件 redis支持复杂结构，如果需要缓存支持复杂的结构和操作，redis 是不错的选择 redis原生支持集群模式：memcached需要依赖客户端来实现往集群中分片写入数据。 性能对比redis只是用单核，而memcached可以使用多核，所有平均每一个核上redis在存储小数据时比memcached性能更高，而在100k以上的数据中，memcached性能要高于redis redis线程模型内部使用文件事件处理器 file event handler，这个是单线程的，所以redis才叫单线程的模型，它采用io多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理。 文件事件处理器，结构包括四个部分： 多个socket io多路复用程序 文件时间分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） Redis有哪些数据结构啊？ String、Hash、List、Set、SortedSet 以上五个基本类型，如果你是中高级用户的话，还有HyperLogLog、Geo、Pub、Sub 如果还想加分，还可以说玩过Redis Module，像BloomFilter、RedisSearch、Redis-ML 如果有大量的key需要设置同一时间过期，一般需要注意什么？ 如果过期时间设置的过于集中，到过期的时候，Redis可能会出现短暂的卡顿现象，严重的话会出现缓存雪崩，一般在时间上加一个随机值，使得过期时间分散一些 电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点涌入大量访问，就可能缓存雪崩 你使用过Redis分布式锁么，它是怎么回事？ 先拿setnx来争抢锁，抢到之后，再用Expire给锁加一个过期时间防止锁忘记释放。 如果在setnx之后，执行expire之前，进程意外重启维护了，会怎么样？ 这个时候你一定要给予惊讶的反馈，是哦，这个锁就永远得不到释放了，紧接着，你抓了抓自己的头发，故作思考：我记得set指令有个非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的 假如redis里有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将他们全部找出来？ 使用keys指令可以扫出指定模式的key列表 继续追问：如果这个redis正在给线上的业务提供服务，那么使用keys指令会有什么问题? redis是单线程的，使用keys会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，这个时候可以使用scan指令，scan指令可以无阻塞的取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，单整体花费的时间会比直接使用keys指令长 redis是怎么持久化的？服务主从数据是怎么交互的？ rdb做镜像全量持久化，aof做增量持久化。因为rdb会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用rdb持久化文件重构内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态 这里很好理解的，把rdb理解为一整个表全量的数据，aof理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是可能不完整，这个时候再回放一下日志，数据不就完整了嘛。不过redis本身的机制是aof持久化开启且存在aof文件时，优先加载aof文件；aof关闭或者aof文件不存在时，加载rdb文件；加载aof/rdb文件成功后，redis启动成功；aof/rdb文件存在错误时，redis启动失败并打印错误信息 对方追问如果突然机器停电会怎样? 取决于aof日志sync属性的配置，如果不要求心梗，在每一条写指令时都sync一下磁盘，就不会丢失数据，但是在高性能要求下每次都sync是不现实的，一般都使用定时sync，比如1s/1次，这个时候最多就会丢失1s的数据 对方继续追问rdb的原理是什么？ 这个问题给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行rdb操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会主键和子进程分离开来 Pipeline有什么好处，为什么要用Pipeline？ 可以将多次io往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目 是否使用过redis集群，集群的高可用怎么保证，集群的原理是什么？ redis Sentinel着眼于高可用，在master宕机时会自动将slave升级为master，继续提供服务 。 redis cluster 着眼于扩展性，在单个redis内存不足时，使用cluster进行分片存储 哨兵、持久化、主从、手撕LRU在上面了解完基础知识已经一些缓存的常见问题之后，聊聊下面的 为什么redis那么快 先看一下关系型数据库跟redis本质上的区别，如下图： Redis采用的是单进程单线程模型的kv数据库，由c编写，官方提供的数据是达到10w的qps（每秒内查询次数） 完全基于内存，绝大部分请求是纯粹的内存操作，非常快。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1); 数据结构简单，对数据操作也简单，redis中的数据结构是专门进行设计的 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换消耗，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 使用多路i/o复用模型，非阻塞io； 使用底层模型不同，他么之间底层实现方式以及与客户端之间通信的应用协议不一样，redis直接自己构建了vm机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求 我可以问一下啥是上下文切换吗？为啥可能线程不安全？ 好比你看一本英文书，你看到第十页发现有个单词不会，你加了个书签，然后去查字典，过了一会你回来继续从书签那里读，ok目前为止没问题。 问题来了，你去查字典的时候，别人过来翻了一下你的书，然后走了，然后你回来了，你再看书的时候发现书不是你看的那一页了。 那他是单线程，我们服务器都是多核的，那不是浪费吗？ 虽然他是单线程的，但是我们可以单机开多个实例啊 既然提到了单机会有瓶颈，那你们是怎么解决这个瓶颈的？ 我们用到了集群的部署方式也就是redis cluster,并且是主从同步读写分离，类似Mysql的主从同步，Redis cluster支撑n个redis mater node，并且每个master node 都可以挂载多个salve node 这样整个Redis就可以横向扩容了，如果你要吃成更大数据量的缓存，那就横向扩容更多的master节点，每个master节点就能存放更多的数据了。 那么问题来了，他们之间是怎么进行数据交互的？以及redis 是怎么进行持久化的？Redis数据都在内存中，一断电或者重启不就木有了吗？ 是的，持久化的话是redis高可用中的重要一点，因为redis数据在内存的特性，持久化必须有，我了解方式有两种： RDB：是对redis中的数据进行周期性的持久化 AOF：对每条写入命令作为日志，以[只追加]【append-only】的方式写入到一个日志文件中，没有任何磁盘寻址的开销，所以很快，有点像mysql中binlog 这两种方式都可以把redis内存中的数据持久化到磁盘上，rdb更适合做冷备，aof更适合做热备 tip：两种机制全部开启的时候，redis在重启的时候回默认使用aof去重新构建数据，因为aof的数据是比rdb更完整的 那这两种机制各自优缺点是啥？ RDB 优点： 会生成多个数据文件，每个数据文件都代表了某一时刻redis里面的数据，这种方式，很适合做冷备 rdb对redis性能影响较小，是因为在同步时候他只是fork了一个子进程去做持久化的，而且他在数据恢复的时候速度比aof来得快 缺点： rdb都是快照文件，都是默认五分钟甚至更久的时间才生成一次，意味着两次同步之间五分钟的数据可能全部丢失，aof则最多丢1秒的数据 还有就是rdb在生成数据快照的时候，如果文件很大， 客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候它刚搞在这个时候fork了一个子进程去生成一个大快照 AOF 优点：一秒生成一个，只追加的方式写，性能惊人 缺点： 一样的数据aof文件比rdb还要大，aof开启后redis支持写的qps会比rdb支持写的要低 那两者如何选择呢？ 两个都要，出现事故，第一时间用rdb恢复，在用aof补全 Redis还有其他保证集群高可用的方式吗？ 还要哨兵集群sentinel（森提nou） 哨兵必须用三个实例去保证自己的健壮性，哨兵+主从并不能保证数据不丢失，但是可以保证集群的高可用 一个机器挂了，剩下两个机器需要选举出来一个执行故障转移，如果只有两台机器的话，挂了一个就剩下一个了，没有哨兵去允许故障转移了 Redis的同步机制 redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存，加载完成后，通知主节点将期间修改的操作记录同步到点进行重放就完成了同步过程。后续的增量数据通过aof日志同步即知，有点类似数据库的binlog。 说一下他的内存淘汰机制 Redis的过期策略有两种，定期删除+惰性删除 定期删除：默认100ms就随意抽一些设置了过期时间的key，检查是否过期，过期就删除 为什么不扫描全部设置了过期时间的key呢？ 因为太慢，浪费资源 如果没随机到很多key，里面不就存在大量的无效key了？ 好问题，不是还有惰性删除吗 惰性删除：我不主动删，我懒，等你来查询了，我看看有没有过期，过期就删了还不给你返回，没过期就那么挂着 1.13 双写一致性、并发竞争、线程模型mysql索引索引有哪些数据结构Hash、B+ 去创建索引的时候，可以选择索引的类型 为什么hash、完全平衡二叉树、b树、b+树都可以优化查询，mysql为什么喜欢b+树？先说hash索引，字段值所对应的数据下标是哈希随机算出来的，可能会出现hash冲突。 举例：where name = ‘鸡蛋’，“鸡蛋”可以直接hash出他的数组下标，然后直接从数据中取出来 举例2：where name &gt;’鸡蛋’，那么hash表就无能为力了，他可以精确查询，但是不支持范围查询，就算做成索引，速度也很慢，要扫全表。 hash表的适合场景？hash表是无序的。 redis、Memcached这些nosql的中间件。kv结构的 说的是无序的hash表，有没有有序的结构？有序数组，等值查询和范围查询都很好 缺点：适合做静态数据，因为增删改会改变他的结构 适用：静态存储的索引啊，比如说2019年的支付宝账单，等等历史记录，都是不会变动的数据 二叉树二叉树是有序的，所以支持范围查询，但是时间复杂度是o(log(n)),为了维持这个时间复杂度，更新的时间复杂度也得是o(log(n))，那就得保持这棵树是完全平衡二叉树了 索引页不止在内存里存储的，也要落盘持久化的，如果数据多了，树就很高了，查询成本随着树变高而高 如果公司为了节约成本用的机械盘，来一次千万级别的查询，那不得慢死了 B树 b树比完全平衡二叉树要矮，原因是b树中的一个节点可以存储多个元素 B+树 同样的元素，b+树会比b树要“胖”，原因在于B+树中的非叶子节点会冗余一份在叶子节点中，并且叶子节点之间用指针相连 B+树 优势Hash不支持范围查询 二叉树太高 只有B树可以跟b+比一比 b树一个节点存储多个元素，相对于完全平衡二叉树的树高整体降低了，磁盘io效率提高了 b+树是b树的升级版，只是把非叶子节点冗余一下，这样可以提高范围查找的效率：原因是会有指针指向下一个节点的叶子节点 一个b+树节点可以存储多少个元素？懵逼，换个角度，b+树中一个节点到底多大合适？ b+树中一个节点为一页或者页的倍数最合适 基础回表是什么? 大概就是有个主键为ID的索引，和一天个普通字段 name 的索引，我们在普通字段上搜索： select * from table where name = ‘“丙丙” 执行的流程是：先查询name索引上的“丙丙”，然后找到他id是2，最后去主键索引，找到id为2对应的值。 回到主键索引树搜索的过程，就是回表。 覆盖索引可以避免回表 覆盖索引是什么？ 比如说刚才的 select * ，查询所有的，如果我们只是需要id，那么其实name字段的索引上就已经有了，就不需要回表了 很多联合索引的建立，就是为了支持覆盖索引，特定的业务能极大的提升效率 char 、varchar的区别是什么？varchar 是变长，而char是长度固定的，如果你的内容是固定大小的，使用char性能更好 truncate与delete的区别是什么？truncate 是永久删出表中的每一行，且不可恢复 什么是触发器？触发器是指一段代码，当触发某个事件时，自动执行这些代码。在mysql数据库中有如下6种触发器：1.Before Insert 2.After Insert 3.Before Update 4.After Update 5.Before Delete 6.After Delete float与double的区别是什么？fioat存储至多8位十进制数，内存占用4字节 double存储至多18位十进制数，内存占用8字节 如果在mysql获取当前日期1select current_date(); 如何查询第n高的工资1select distinct(salary) from employee order by salary Desc limit n-1,1 请说明innodb和mylsam的区别 innodb，支持事务 innodb，支持崩溃后的恢复 请列举三个以上表引擎innodb 、MylSAM、Memory varchar和text的区别 varchar可以指定字符数，text不能指定 内部存储varchar是存入的实际字符数+1个字节（n&lt;=255）或2个字节（n&gt;255）,text是实际字符数+2个字节 text不能有默认值,默认值为null varchar可以直接创建索引，text创建索引要指定前多少个字符，varchar查询速度快于text，在都创建索引的情况下，text的索引几乎不起作用。 查询text需要创建临时表 varchar（50）中50的含义最多存放50个字符 varchar（50）和（200）存储“hello”所占用的空间是一样的，但是200在排序时会消耗更多内存。 int（20）中20的含义是指显示字符的长度，不影响内部存储，只是当定义了ZEROFILL时，前面补多少个0 索引、主键、唯一索引、联合索引的区别，对数据库性能有什么影响？ 唯一索引：数据列不允许重复，可以null，一个表可以创建多个 主键索引：一定是唯一索引，不允许null，一个表只能有一个 主键可以与外键构成曹肇完整性约束，防止数据不一致。 联合索引：将多个列组合在一起创建索引，可以覆盖多个列。 外检索引：基本不用，只有innodb类型的表才可以使用 全文索引：mysql自带的全文索引只能用于mylSAM，并且只能对英文进行全文检索（基本不用） 最左前缀顾名思义，就是最左优先，在创建多列索引时，需要根据业务需求，where字句中使用最频繁的一列放在最左边。 12345678以 index(a,b,c) 为例,(注意和顺序有关)where a=2 可以用到索引where a=1 and b=2 可以用到索引where a=1 and b=2 and c=3 可以用到索引where b=1 / c=1 不能用到索引where a=1 and c=1 a可以发挥索引，c不能使用到索引where a=1 and b&gt;10 and c=1 a可以发挥索引，b也可以发挥索引，c不能发挥索引where a=1 and b like &apos;xxx%&apos; and c=1 a可以发挥索引，b可以发挥索引，c不能发挥索引 组合索引的生效原则是 从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的索引没有起作用； 联合索引最左匹配原则最左前缀匹配原则在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：对列col1、列col2和列col3建一个联合索引 1KEY test_col1_col2_col3 on test(col1,col2,col3); 联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。 1SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4” 上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。 注意索引的字段可以是任意顺序的，如： 12SELECT * FROM test WHERE col1=“1” AND clo2=“2”SELECT * FROM test WHERE col2=“2” AND clo1=“1” 这两个查询语句都会用到索引(col1,col2)，mysql创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段col1的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段col2进行排序。其实就相当于实现了类似 order by col1 col2这样一种排序规则。 有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引(col1,col2)中的col1、col2两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助mysql查询优化器explain，explain会纠正sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。 为什么要使用联合索引 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！ 引申对于联合索引(col1,col2,col3)，查询语句SELECT * FROM test WHERE col2=2;是否能够触发索引？大多数人都会说NO，实际上却是YES。原因： 12EXPLAIN SELECT * FROM test WHERE col2=2;EXPLAIN SELECT * FROM test WHERE col1=1; 观察上述两个explain结果中的type字段。查询中分别是： type: index type: ref index：这种类型表示mysql会对整个该索引进行扫描。要想用到这种类型的索引，对这个索引并无特别要求，只要是索引，或者某个联合索引的一部分，mysql都可能会采用index类型的方式扫描。但是呢，缺点是效率不高，mysql会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。所以，上述语句会触发索引。 ref：这种类型表示mysql会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。简单说，也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。 索引算法btree是最常用的，也是mysql默认的算法，因为它不仅仅可以用在=、&gt;、&gt;=、&lt;、&lt;=和between这些比较操作符上，也可以用于like操作符，只要他的查询条件不是一通配符开头的常量 12select * from user where name like ‘jack%’---使用索引select * from user where name like ‘%jack’---不使用索引 hash索引只能用于对等比较，例如=、&lt;=&gt;（相当于=）操作符。由于是一次定位数据，不像btree索引需要从根节点到枝节点，最后才能访问到叶节点这样多次io访问，所以hash索引的效率远高于btree索引 索引的设计原则 适合索引的列是出现在where字句中的列，或者连接字句中指定的列 基数较小的列，索引效果差，没必要在此列建立索引 使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间 不要过度索引，占用额外的磁盘空间，并降低写操作的性能。在修改表能容的时候，索引进行更新甚至重构 mysql中in 和exists区别 如果查询的两个表大小想打，那么in和exists差别不大 如果一个小表，一个大表，则子查询表大的用exists，子查询表小的用in not in 和 not exists 如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not exists 的子查询依然能用到表上的索引。所以无论哪个表达，用not exists 都比not in 要快 mysql的关联查询语句有哪些？ 6中关联查询：1 交叉连接（cross join）；2 内连接（inner join）；3 外连接（left join、right join）；4 联合查询（ union 与 union all）；5 全连接（full join）； 内连接分为三类 等值连接：on a.id=b.id 不等值连接：on a.id &gt;b.id 自连接 ：select * from a t1 inner join a t2 on t1.id = t2.id 外连接（left join、right join） 左匹配连接，以左表为主，先查询出主表，按照on后的关联条件匹配右表，没有匹配到的用null填充，可以简写成left join 右匹配连接，同上 联合查询（uninon 与 union all） 1select * from a union select * from b union 。。。 就是把多个结果集集中在一起，union前的结果为准，联合查询的列数要相等，相同的记录行会合并 如果使用union all，不会合并重复的记录行 union效率高于union all mysql的隔离级别和对应的问题Read Uncomitted（读未提交）在该隔离级别，所有事务都可以看到其他未提交事务的执行结。 本级别很少用于实际应用，因为它的性能也不必其他级别好多事 问题：脏读：读取未提交的数据 Read Committed（读已提交）大多数数据库系统的默认隔离级别（但不是mysql默认的）。满足了隔离的简单定义：一个事务只能看见已提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select 可能返回不同结果。 Repeatable Read（可重复读-默认级别）这是mysql默认的事务隔离界别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。 不过理论上会导致另一个棘手的问题：幻读（Phantom Read）。简单的说，幻读指当前用户读取某一范围的数据行是，另一个书屋又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有心的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（mvcc）机制解决了该问题 Serializable（可串行化）这是最高的隔离级别，通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，就是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。这四种隔离界别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如： 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就有几列数据是未查询出来的，如果此时插入和另外一个事务插入的数据，就会报错。 在数据库中如何优化？ 对查询进行优化，尽量避免全表扫描，首先应考虑在where 及order by 涉及的列上建立索引 应尽量避免在where 字句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描 应尽量避免在where字句中使用！=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 应尽量避免在where字句中使用or来连接条件，如果一个字段有索引，一个字段没有索引，将导致全表扫描 in 和 not in 也要慎用，否则会导致全表扫描 like 模糊全匹配也将导致全表扫描 mysql的基础架构，画一下图 连接器是啥？我们要查询db，第一步就是去连接db，这个连接器就是db跟我们对接的。 他负责跟客户端建立连接、获取权限、维持、管理连接 连接的时候回经过tcp握手，然后身份验证，然后输入账号密码就好了 验证ok后，我们就脸上mysql这个服务器了，但是这个时候处于空闲状态 怎么查看空闲连接列表？show processList 其中Command列显示为sleep的这一行，就表示系统里面有一个空闲连接 如果数据库的客户端太久没有相应，连接器就自动断开了，这个时间参数是wait_timeout控制住的，默认时长是8小时。超时之后可以重新连接 除了重新连接，还有其他方法吗？使用长连接 但是优缺点：长连接后，内存飙升很快，我们知道mysql在执行过程中临时使用的内存是管理在连接对象里面的。只有在断开连接的时候才能得到释放，如果长连接，这一部分内存就得不到释放，就oom了，在jvm里面就频繁fgc mysql缓存mysql拿到一个查询请求之后，会先到缓存里面查询看看，之前是否执行过这条 如果同一条语句执行两次，第一次明显比后面的慢，这就是因为缓存的存在 跟redis类似，只要你之前执行过的语句，都会在内存里面用key-value形式存储着 为什么缓存弊大于利缓存很容易失效，只要对表有任何的更新，这个表的所有查询缓存都会被清空，出现：缓存还没使用就被清空。 只有类似于配置表这种的，适用缓存 查询的时候不想用缓存、想用缓存该如何操作？可以显示调用，把query_cache_type设置成DEMAND，这样sql默认不适用缓存，想用缓存就用sql_cache。 缓存在mysql 8.0之后就取消了 缓存查询完了，应该做啥呢？缓存没有命中的情况下，开始执行语句了，你写的sql有没有语法错误，这是接下来比较关心的点。 他会先词法分析，一条sql那么多单词，要识别每个字符代表的是什么？表名？列名？关键字？ 然后开始语法分析，根据此法分析的结果，语法分析会判断你sql的对错，错了会提示你哪里错了 下一步：优化器 主要优化什么：我们的表可能会建立很多索引，优化的有一步就是要确认使用哪个索引、执行顺序进行优化，条件那么多、先查哪个表，还是县关联？ 最后就是执行了，交给 执行器去做 线程池什么是线程池？线程池的基本思想是对象池，在程序启动时就开辟一块内存空间，里面存放了众多（未死亡的）的线程，池中的线程执行调度由池管理器来处理，当有线程任务时，从池中取一个，执行完成后线程对象归池，这样可以避免反复创建线程对象带来的性能开销，节省了系统的资源 使用线程池的好处 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用 运行线程池能有效的控制线程最大并发数，可以根据系统的承受能力 对线程进行一些简单的管理：比如：延迟执行、定时循环执行的策略等，运用线程池都能进行很好的实现 线程池的主要组件 一个线程池包括以下四个基本组成部分 线程池管理器（ThreadPool）:用于创建并管理线程池，创建、销毁线程池，添加新任务； 工作线程（WorkThread）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务 任务接口（Task）：每个任务都必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等。 任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。 ThreadPoolExecutor类这个类的线程池中最核心的一个类 线程池的主要处理流程 线程数量未达到corePoolSize，则新建一个新城（核心线程）执行任务 线程数量达到了corePools，则将任务移入队列等待 队列已满，新建线程（非核心线程）执行任务 队列已满，总线程数又达到了maxImumPoolSize，就会抛出异常 四中拒绝策略 AbortPolicy：不执行新任务，直接抛出异常，提示线程池已满，线程池默认策略 DIscardPolicy：不执行新任务，也不抛出异常，基本上为静默模式 DIsCardOldSetPolicy：将消息队列中的一个任务替换为当前新进来的任务执行 CallerRunPolicy：用于被拒绝任务的处理程序，它直接在execute方法的调用线程中被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。 5.5 java通过Executors提供四种线程池 CacheThreadPool：可缓存线程池 线程数无限制 有空闲线程则复用空闲线程，若没有则新建线程，一定程度减少频繁创建、销毁线程，减少系统开销 FixedThreadPool（）：定长线程池 可控制线程最大并发数（同时执行的线程数） 超出的线程会在队列中等待 ScheduledThreadPool 定时线程池 支持定时及周期性任务执行。 SingleThreadExecutor：单线程化的线程池 有且仅有一个工作线程任务 所有任务按照指定顺序执行，即遵循队列的入队出队规则 5.6 线程池参数设置参数的设置跟系统的负载有直接关系，下面为系统负载的相关参数： tasks，每秒需要处理的任务数（针对系统需求） threadtasks，每个线程每秒可处理任务数（针对线程本身） responsetime，系统允许任务最大的响应时间，比如每个任务的响应时间不得超过2秒 corePoolSize 系统每秒有tasks个任务需要处理理，则每个线程每钞可处理threadtasks个任务。，则需要的线程数为：tasks/threadtasks，即tasks/threadtasks个线程数。 假设系统每秒任务数为100 ~ 1000，每个线程每钞可处理10个任务，则需要100 / 10至1000 / 10，即10 ~ 100个线程。那么corePoolSize应该设置为大于10，具体数字最好根据8020原则，因为系统每秒任务数为100 ~ 1000，即80%情况下系统每秒任务数小于1000 * 20% = 200，则corePoolSize可设置为200 / 10 = 20。 queueCapacity 任务队列的长度要根据核心线程数，以及系统对任务响应时间的要求有关。队列长度可以设置为 所有核心线程每秒处理任务数 * 每个任务响应时间 = 每秒任务总响应时间 ，即(corePoolSizethreadtasks)responsetime： (2010)2=400，即队列长度可设置为400。 maxPoolSize 当系统负载达到最大值时，核心线程数已无法按时处理完所有任务，这时就需要增加线程。每秒200个任务需要20个线程，那么当每秒达到1000个任务时，则需要（tasks - queueCapacity）/ threadtasks 即(1000-400)/10，即60个线程，可将maxPoolSize设置为60。 队列长度设置过大，会导致任务响应时间过长，切忌以下写法： 12LinkedBlockingQueue queue = new LinkedBlockingQueue();复制代码 这实际上是将队列长度设置为Integer.MAX_VALUE，将会导致线程数量永远为corePoolSize，再也不会增加，当任务数量陡增时，任务响应时间也将随之陡增。 keepAliveTime 当负载降低时，可减少线程数量，当线程的空闲时间超过keepAliveTime，会自动释放线程资源。默认情况下线程池停止多余的线程并最少会保持corePoolSize个线程。 allowCoreThreadTimeout 默认情况下核心线程不会退出，可通过将该参数设置为true，让核心线程也退出。 5.7 线程池的五种状态 线程池的初始化状态running，能够接受新任务，以及对已添加的任务进行处理。 线程池出在shutdown状态时，不接受新任务，但能处理已添加的任务。调用线程池的shutdown（）接口时，线程池由running-&gt;shutdown 线程池出在stop状态时，不接受新任务，不处理已添加的任务，并且会终端正在处理的任务。调用线程池的shutdownNow（）接口时，线程池由（running or shutdown） -&gt;stop。 当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。 当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。 当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。 线程池彻底终止，就变成TERMINATED状态。线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED。 5.8 关闭线程池线程池提供两种关闭方法：shutDown()和shutDownNow() shutDown() 当线程池调用该方法时，线程池的状态则like变成shutdown状态，此时，则不能再往线程池中添加任何任务，否则将会抛出异常；但是，此时线程池不会立刻退出，直到添加到线程池中的任务都已经处理完成，才会退出 shutdownNow（） 执行该方法，线程池的状态立刻变成STOP状态，并试图停止所有正在执行的线程，不再处理线程池中等待的任务，当然，会返回那些未执行的任务；不代表立刻就能退出，可能要等待所有正在执行的任务都执行完才能退出 5.9 各种场景下怎么设置线程数高并发、任务执行时间短的业务 线程池线程数可以设置为cpu核心数+1，减少线程上下文的切换 并发不高、任务执行时间长的业务 这个需要判断执行时间是耗在那个地方了？ io操作耗时，也就是io密集型的任务，因为io操作并不占用cpu，所有不要让所有的cpu闲下来，可以适当加大线程池中的线程数目（cpu核心数*2），让cpu处理更多的业务 计算操作耗时，也就是cpu密集型任务，那么久设置cpu核心数+1，线程数设置的少一些，减少线程上下文的切换。 并发高、业务执行时间长的业务 解决这种类型任务的关键不在于线程池，而在于整体架构的设计 线程五个状态new（新建）Runnable（就绪）Running（运行）Blocked（阻塞）死亡线程的创建方式到底有几种 声明为Thread的子类，并重写run方法 12345678910111213&gt; public class MyThread extends Thread &#123;&gt; &gt; @Override&gt; public void run() &#123;&gt; System.out.println(Thread.currentThread().getName() + " Thread running...");&gt; &#125;&gt; &gt; public static void main(String[] args) throws IOException &#123;&gt; new MyThread().start();&gt; System.in.read();&gt; &#125;&gt; &#125;&gt; 实现Runnable接口 Runnable的优点： 业务代码与线程类创建启动等逻辑解耦 Runnable可以复用，Thread则需要每次创建 类可以实现多个接口，而不可以继承多个对象 1234567891011121314&gt; public class MyRunnable implements Runnable &#123;&gt; @Override&gt; public void run() &#123;&gt; System.out.println(Thread.currentThread().getName() + " Runnable running...");&gt; &#125;&gt; &gt; public static void main(String[] args) throws IOException &#123;&gt; new Thread(new MyRunnable()).start();&gt; System.in.read();&gt; &#125;&gt; &#125;&gt; // 有点&gt; &gt; 归根结底 创建线程只有一种方式，就是创建Thread对象，而构建一个线程的方式有多重，比如：创建线程类，实现Runnable接口，创建线程池，FutureTask等等 线程池创建线程：实际是由默认的工厂代为创建Thread类来实现的 1234567891011121314151617181920212223242526272829&gt; // Executors中的DefaultThreadFactory &gt; static class DefaultThreadFactory implements ThreadFactory &#123;&gt; private static final AtomicInteger poolNumber = new AtomicInteger(1);&gt; private final ThreadGroup group;&gt; private final AtomicInteger threadNumber = new AtomicInteger(1);&gt; private final String namePrefix;&gt; &gt; DefaultThreadFactory() &#123;&gt; SecurityManager s = System.getSecurityManager();&gt; group = (s != null) ? s.getThreadGroup() :&gt; Thread.currentThread().getThreadGroup();&gt; namePrefix = "pool-" +&gt; poolNumber.getAndIncrement() +&gt; "-thread-";&gt; &#125;&gt; &gt; public Thread newThread(Runnable r) &#123;&gt; Thread t = new Thread(group, r,&gt; namePrefix + threadNumber.getAndIncrement(),&gt; 0);&gt; if (t.isDaemon())&gt; t.setDaemon(false);&gt; if (t.getPriority() != Thread.NORM_PRIORITY)&gt; t.setPriority(Thread.NORM_PRIORITY);&gt; return t;&gt; &#125;&gt; &#125;&gt; //由上newThread()方法可知，即使是线程池，本质上还是使用Thread的创建线程。&gt; Callable和FutureTask创建线程，本质其实也是Thread 12345678910111213&gt; public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123;&gt; /**&gt; * Sets this Future to the result of its computation&gt; * unless it has been cancelled.&gt; */&gt; void run();&gt; &#125;&gt; &gt; public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123;&gt; ......&gt; private volatile Thread runner;&gt; ......&gt; 定时器Timer：它的TimerTask其实也是实现了Runnable接口，可以看下TimerTask这个抽象类 123456789101112131415&gt; public class TimerExample &#123;&gt; public static void main(String[] args) &#123;&gt; Timer timer = new Timer();&gt; // 每隔1s打印下自己的名字&gt; timer.scheduleAtFixedRate(new TimerTask() &#123;&gt; @Override&gt; public void run() &#123;&gt; System.out.println(Thread.currentThread().getName() + " timer running...");&gt; &#125;&gt; &#125;, 1000, 1000);&gt; &#125;&gt; &#125;&gt; &gt; &gt; 线程和进程的区别 线程是进程的子集，一个进程可以有多个线程； 不同的进程使用不同的内存空间，所有单线程共享一片相同的内存空间 用Runnable还是Thread 推荐用Runnable，因为可以继承多个接口 Thread类中的start()和run()方法有什么区别？ start()被用来启动新创建的线程，而且start()内部调用了run()方法； run(),只会在原来的线程中调用，没有新的线程启动 Runnable和Callable有什么不同 都代表那些要在不同的线程中执行的任务。Runnable从1.0开始就有了，Callable在1.5增加的； Callable的call()方法可以返回值和抛出异常 乐观锁、悲观锁简单说说乐观锁、悲观锁，他们对应的实现cas、Synchronized、ReentrantLock 锁只能升级，不能降级 乐观锁说一说casCompare and Swap 比较并且替换，是乐观锁的一种实现方式，是一种轻量级锁，juc中很多工具类的实现是基于cas的 cas是怎么实现线程安全的？线程在读取数据时不进行加锁，在准备写回数据时，先去查询原值，操作的时候比较原值是否修改，若未被其他线程修改则写回，若已修改，则重新执行读取流程，无法处理aba问题 cas操作长时间不成功的话，会导致一直自旋，相当于死循环了，cpu压力很大 乐观锁在项目中的实践？比如订单表，比如流水表，为了防止并发安问题，就会加入cas的校验过程，保证线程安全，但并不是所有场景都适用的。 cas性能很好，但是Synchronized性能不咋地，为啥1.8之后反而多了Synchronized？synchronized之前一直都是重量级的锁，但是后来java官方对他进行过升级 的，他现在采用的是锁升级的方式去做的。 针对synchronized获取锁的方式，jvm使用了锁升级的优化方式，就是先使用偏向锁优先同一进程然后再次获取锁，如果失败，就升级为cas轻量级锁，如果失败就会端在自旋，防止线程被系统挂起，最后如果以上都失败就升级为重量级锁；所有是一步步升级上去的，一开始也是通过很多轻量级的方式锁定的 悲观锁什么是悲观锁，悲观锁，就是默认你每次都是渣男，每次都要提防着你是的 Synchronized实现原理无论是修饰方法还是代码块，都是通过持有修饰对象的锁来实现同步 是如何保证同一时刻只有一个线程可以进入临界区呢？jvm层面的synchronized加锁，是最常见的线程同步收之一 synchronized，代表这个方法加锁，相当于不管哪一个线程（比如线程A），运行到这个方法的时候，都要检查有没有其他线程B（或者c、d）正在用这个方法（或者该类方法啊其他同步方法），有的话要等他运行完之后，再运行，没有的话，锁定调用这，然后直接运行。 分别从他对对象、方法、代码块三方面加锁，去介绍怎么保证线程安全的 同步方法和同步代码块底层都是通过monitor来实现同步的 对象加锁在jvm中，对象在内存中分为三块区域：对象头（header）、实例数据(Instance data)、对齐填充（padding） 对象头 以hotpot虚拟机为例，对象头主要包括两部分数据：mark word（标记字段）、klass pointer(类型指针) mark word：默认存储对象的hashcode，分代年龄和锁标志位信息。它会根据对象的状态复制自己的存储空间，也就是说：在运行期间mark word里面存储的数据会随着锁标志位的变化而变化 klass point ：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例 可以看到对象头保存了锁标志位和指向monitor对象的起始地址，如图所示，右侧就是对象对应的monitor对象 当monitor被某个线程持有后，就会处于锁定状态，如同种的 Owner部分，会指向持有monitor 对象的进程 另外 Monitor中海油两个队列分别是 EntryList和waitList，主要是用来存放进入及等待获取锁的线程，如果线程进入，则得到当前对象锁，那么别的线程在该类所有对象上的任何操作都不能进行 如果一个对象有多个资源，就不需要将整个对象加锁 由于每个对象都有锁，可以使用虚拟对象来上锁 Synchronized（new obj） ReentrantLock在介绍ReentrantLock之前，先介绍AQS（AbstractQueuedSynchronizer） AQS：队列同步器，是实现ReentrantLock的基础 AQS有一个state标记位，值为1时表示有线程占用，其他线程需要进入到同步队列等待，同步队列是一个双向链表 什么是aba什么是ABA 就是一个线程把值改成了b，又一个线程把值改回了a，对于当前线程来说，发现他的值还是a，所有就不知道这个值到底有没有被人修改过，如果只追求最后结果正确，这是没关系的 但实际过程中还是需要记录修改过程的，比如资金修改什么的，你每次修改的都应该有记录，方便回溯 如果和解决ABA问题？用版本号去保证就好， 比如说，我在修改前去查询他原来的值的时候再带一个版本号，每次判断就连值和版本号一起判断，判断成功就给版本号+1，伪代码如下 1update a set value = newValue ，vision = vision + 1 where value = #&#123;oldValue&#125; and vision = #&#123;vision&#125; // 判断原来的值和版本号是否匹配，中间有别的线程修改，值可能相等，但是版本号100%不一样 除了版本号还有别的方法保证吗比如时间戳也可以，查询的时候把时间戳一起查询出来，对的上才修改并且更新值的时候一起修改更新时间，方法很多，都是跟版本号异曲同工 Hashmap6.1.1成员变量1。集合的初始化容量（必须是2的n次幂） 1static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 HashMap构造方法可以指定集合的初始化容量大小： 1Hash(int 初始大小) //构造一个带指定初始容量和默认加载因子（0.75）的空HashMap 由此可见，当想HashMap中添加一个元素的时候，需要根据key的hash值，去确定其在数组中的具体位置。HashMap为了存取高效，要尽量减少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就是把数据存储到哪个链表中的算法 这个算法实际就是取模，hash%length，计算机中直接求余效率远不如位运算。所有源码中做了优化，使用hash&amp;（length-1），而实际上hash%length等于hash&amp;（length-1）的前提是lengtn是2的n次幂。 hash&amp;（length-1）是计算数组的索引的 为什么是2的n次幂 答：减少hash冲突，提高性能 如果不是2的n次幂会怎么样？比如如果是9？ 答：会通过无符号右移 按位或运算变为比指定容量大的最小的2的n次幂 2。默认的负载因子，默认值是0.75 1static final float DEFAULT_LOAD_FACTOR = 0.75f; 达到这个之后，会扩容，rehash 3。集合最大容量 1static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//集合最大容量的上线是2的30次幂 4。当链表的值超过8则会转红黑树（1.8新增） 1static final int TREEIFY_THRESHOLD = 8; 链表中节点的分布符合泊松分布，也就是说转变为红黑树的概率非常小 5。当链表的长度小于6则会从红黑树转回链表 1static final int UNTREEIFY_THRESHOLD = 6; 6。当map里面的数量超过这个值时，表中的桶才会树化，否则桶内元素太多时会扩容，而不是树化沦为了避免进行扩容、树化选择的冲突，这个值不能小于4*TREEIFY_THRESHOLD（8） 1static final int MIN_TREEIFY_CAPACITY = 64;//桶中结构转化为红黑树时对应数组长度最小的值 7。table用来初始化（必须是2的n次幂）（★★★★） 1transient Node&lt;K,V&gt;[] table ; table在jdk1.8中是由数组+链表+红黑树来组成的结构其中table就是hashMap中的数组，jdk8之前的数组类型是Entry&lt;K,V&gt;类型，jdk8之后就是Node&lt;K,V&gt;类型。只是换了个名字，都实现了一样的接口：Map.Entry&lt;K,V&gt;。负责存储键值对数据的 8。HashMap中存放元素的个数（★★★★） 12//存放元素的个数，注意这个不等于数组的长度 transient int size; size为HashMap中k-v的实时数量，不是数组table的长度。 9。用来记录hashMap的修改次数 1transient int modCount;//每次扩容和更改map结构的计数器 10。用来调整大小下一个容量的值计算方式（容量*负载因子）（边界值） 1int threshold; 11。哈希表的加载因子（★★★★） 1final float loadFactor; 问题1：为什么架子啊因子设置是0.75，为什么不是是0.5呢？ 考虑到hash冲突的问题， 6.1.2构造方法HashMap中重要的构造方法，他们分别如下： 1.构造一个空的hashMap，默认初始容量（16）和默认负载因子（0.75） 1public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; 2.构造一个具有指定出事容量和默认负载因子的HashMap（0.75） 123public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; 3.构造一个具有指定的初始容量和负载因子的HashMap（★★★★★） 123456789101112131415public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; // 边界值，决定是否扩容，不是数组长度 //tableSizeFor(initialCapacity); 判断指定的初始容量是否是2的n次幂，如果不是，就会变成比初始容量大的最小的2的n次幂 // 注意，jdk1.8以后的构造方法中，并没有对table这个成员变量进行初始化，table的初始化被推迟到了put方法中，在put方法中会对threshold重新计算 this.threshold = tableSizeFor(initialCapacity);&#125; 6.1.3 成员方法增加方法 put方法是比较复杂的，实现步骤大致如下： 先通过hash值计算出key映射到哪个桶（就是数组） 如果桶上没有碰撞冲突，则直接插入 如果出现碰撞冲突，则需要处理冲突 如果该桶使用红黑树处理冲突，则调用红黑树的方法插入数据 否则采用传统的链式方法插入，如果链的长度达到临界值，则把链表转化为红黑树 如果同种存在重复的键，则为该键替换为新值value； 如果size大于阈值threshold，则进行扩容 具体的方法如下 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 将链表转为红黑树 扩容方法 resize 什么时候才需要扩容？ 第一次是在putVal的时候扩容 补充：当HashMap中的其中一个链表的对象个数如果达到8个，此时如果数组长度没有达到64，那么HashMap会先扩容解决，如果已经达到64，那么这个链表会变成红黑树，节点类型由node变为treenode 当然，如果映射关系被移除后，下次执行resize方法时判断树节点个数低于6个，也会再把树转换为链表 扩容是在做什么？ jdk8之前： reHash 创建新的数组 遍历放到新的数组 jdk8开始： 扩容避免了reHash，如何避免的呢？不需要重新计算hash；扩容之后要么还是在原来的索引位置，要么就是在（原来的索引位置+旧容量）的索引位置 HashMap的扩容是什么？ 面试题：谈谈你对hashMap的理解hashmap是一种存取高效，但是不保证有序的容器。数据结构是数组+链表+红黑树，是解决hash冲突的产物，它实现了Map接口，采用kv键值对存储数据，并且实现了浅拷贝和序列化 默认大小是16，阈值是0.75，初始化大小必须是2的幂，最大是2的30次方，数组中存储的链表节点Entry类实现于Map.Entry接口，实现了对节点的通用操作 HashMap提供了四种构造方法，默认构造、指定初始容量构造、指定初始容量和阈值构造、基于Map的构造。虽然是构造方法，但是真正从初始化是在第一次添加操作里面实现的 第一次添加操作时，先判断数组有没有初始化，如果没有则先初始化 添加操作的流程： 先判断是否初始化 再判断传入的key是否为空，为空则保存在table[0]位置 key不为空的就对key进行hash，hash的结果再&amp;数组的长度就得到存储的位置 如果存储位置为空则创建节点，不为空说明存在冲突 解决冲突HashMap会先遍历链表，如果有相同的value就更新旧值，否则构建节点添加到链表头 添加还要先判断存储的节点数量是否达到阈值，达到阈值就要进行扩容 扩容2倍，是新建数组，所以要先转移节点，转移时都重新计算存储位置，可能保持不变，可能为就容量+位置 扩容结束后新插入的元素也得再hash一遍才能插入 获取节点的操作流程： 判断是否为空，为空就去table[0]找值 不为空，也是先hash，&amp;数组长度计算下标位置 遍历找相同的key返回值 HashMap是并发不安全的容器，并发添加操作中会出现丢失更新的问题；因为采用头插法在并发扩容时会产生环形链表的问题，导致cpu达到100% 解决并发问题可以采用 java类库提供的Collections工具包下的Collections.synchronizedMap()方法，返回一个线程安全的map 使用并发包下的ConcurrentHashMap。它采用的是分段锁机制实现线程安全 使用HashTable（不推荐） 回答顺序：数据结构+继承结构+基本字段+构造方法+添加操作+扩容操作+并发问题+与1.8的区别 知识点扩展说说浅拷贝与深拷贝的区别 基本数据类型：直接存储在栈中 引用数据类型：存储的是该对象在栈中引用，真实数据存放在堆内存里。 这两种都是针对于Object和Array这样的引用类型数据的 浅拷贝只复制指向某个对象的指针，而不是复制对象本身，新旧对象还是共享同一块内存，拷贝对象的时候只对基本数据类型进行了拷贝，对于引用数据类型只是进行了引用的传递，没有真实的创建一个新的对象。 深拷贝会创造一个一模一样的对象，新旧对象不共享内存 Collections.synchronizedMap()和Hashtable的区别 HashMap和Hashtable的区别 Hashtable是个过时的集合类 两者都实现了map接口，两者介乎等价，除了：Hashtable是synchronized的，这意味着线程安全，多个线程可以共享一个hashtable，java5提供了concurrentHashMap，他是Hashtable的替代，比Hashtable扩展性更好 HashMap Hashtable 线程是否安全 否 是 效率 高 低 null key 和null value 是 否 底层数据结构 数组+链表+红黑树 实现方式 继承AbstractMap类 继承了Dictionary类，是jdk1.0添加，好像已经过时了 初始化容量不同 16 11 扩容机制不同 翻倍 翻倍+1 迭代器不同 Iterator是fail-fast的 Enumerator不是fail-fast的 快速失败fail-fast是啥？原理是啥 是java集合中的一种机制，在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception 原理：在遍历的过程中使用一个modCount遍历用来记录内容变化，如果发生变化，他的值就会改变，每当迭代器使用hashNext、next遍历下一个元素之前，都会检测modCount变量 fail-fast场景？ java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改，算是一种安全机制吧。 安全失败 fail-safe java.util.concurrent包下的容器都是安全失败的，可以在多线程下并发使用，并发修改。 Hashtable效率低的原因？ 看过源码，会发现，他对数据的操作都会上锁 为啥Hashtable不允许键值为null？ Hashtable在put空值的时候回直接抛异常，HashMap却做了特殊处理 Hashtable使用的是安全失败机制，这种机制会使你此次读取到的数据不一定是最新的数据，如果你使用null值，就会使得它无法判断对应的key是不存在还是为空，因为你无法再调用一次contain（key）来对key是否存在进行判断，ConcurrentHashMap同理。 *ConcurrentHashMap *ConcurrentHashMap的数据结构，以及并发度这么高？ 底层基于数组+链表组成的，不过在jdk1.7与18中稍有不同 1.7版本 先看1.7 如图所示：是有segment数组、HashEntry组成，和HashMap一样，仍然是数组+链表 HashEntry跟HashMap差不多，不同的是，他使用了volatile修饰他的value还有next。 ConcurrentHashMap采用了分段锁，其中Segment继承于ReentrantLock。不会像Hashtable那样不管是put还是get操作都需要做同步处理，理论上他支持Segment数量的并发。 每当一个线程占用锁访问一个Segment时，不会影响到其他的Segment。 put：第一步的时候回尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则尝试自旋获取锁，如果重试的次数达到了Max_SCAN_RETRIES则改为阻塞锁获取，保证能获取成功 get：将key通过hash之后定位到具体的Segment，再通过一次Hash定位到具体的元素上。由于HashEntry中的value是volatile的，保证了内存可见性，所有每次获取的都是最新值，整个过程不需要加锁 虽然1.7支持每个Segment并发访问，但是还是存在一些问题？基本还是数组+链表的方式，查询时候，还得遍历链表，效率低下，跟1.7的HashMap存在一样的问题 1.8版本 基本抛弃了原有的Segment分段锁，采取了CAS+Synchronized来保证并发安全性，跟HashMap很像，也把之前的HashEntry改成了node，但是作用不变 值的存取过程？以及怎么保证线程安全？ put操作还是比较复杂的，大概有一下几个步骤： 根据key计算出Hashcode。 判断是否需要进行初始化。 即为当前key定位出的node，如果为空表是当前位置可以写入数据，利用cas尝试写入，失败则自选保证成功。 如果当前位置的hashCode == moved == -1，则需要进行扩容 如果都不满足，则利用synchronized锁写入数据 如果数量大于 TREEIFY_THRESHOLD，则要转换为红黑树 这里所说的cas是什么？自旋又是什么？ cas是乐观锁的一种实现方式，是一种轻量级锁，juc中很多工具类的实现就是基于cas的 CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，到下次循环才有可能机会执行。 cas就一定能保证数据没被别的线程修改过吗？ 并不能，比如经典的ABA问题，CAS就无法判断了 什么是ABA 就是一个线程把值改成了b，又一个线程把值改回了a，对于当前线程来说，发现他的值还是a，所有就不知道这个值到底有没有被人修改过，如果只追求最后结果正确，这是没关系的 但实际过程中还是需要记录修改过程的，比如资金修改什么的，你每次修改的都应该有记录，方便回溯 如果和解决ABA问题？ 用版本号去保证就好， 比如说，我在修改前去查询他原来的值的时候再带一个版本号，每次判断就连值和版本号一起判断，判断成功就给版本号+1，伪代码如下 123&gt; update a set value = newValue ，vision = vision + 1 where value = #&#123;oldValue&#125; and vision = #&#123;vision&#125; // 判断原来的值和版本号是否匹配，中间有别的线程修改，值可能相等，但是版本号100%不一样&gt; &gt; 除了版本号还有别的方法保证吗 比如时间戳也可以，查询的时候把时间戳一起查询出来，对的上才修改并且更新值的时候一起修改更新时间，方法很多，都是跟版本号异曲同工 cas性能很好，但是Synchronized性能不咋地，为啥1.8之后反而多了Synchronized？ synchronized之前一直都是重量级的锁，但是后来java官方对他进行过升级 的，他现在采用的是锁升级的方式去做的。 针对synchronized获取锁的方式，jvm使用了锁升级的优化方式，就是先使用偏向锁优先同一进程然后再次获取锁，如果失败，就升级为cas轻量级锁，如果失败就会端在自旋，防止线程被系统挂起，最后如果以上都失败就升级为重量级锁；所有是一步步升级上去的，一开始也是通过很多轻量级的方式锁定的 先来一张1.7图： jdk1.7从图中可以看出，Hashtable的锁是加在整个表上的，而ConcurrentHashMap是加在segment（每个段上的），这样我们在堆segment1操作的时候，同时也可以对segment2中的数据操作，这样效率会高很多。需要hash两次，第一次Hash定位到segment，第二次Hash定位到元素所在的链表的头部 jdk1.8 jdk8中ConcurrentHashMap参考了jdk8HashMap的实现，采用了数组+链表+红黑树的实现方式来设计，内部大量采用cas操作（CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，到下次循环才有可能机会执行。）从jdk8来看，它的数据结构已经接近HashMap，只是增加了同步的操作来控制并发 网络tcp常见面试题为什么建立连接是三次握手？两个目的：信息对等、防止超时 先从信息对等的角度来看，如下图，双方只有确定四类信息，才能建立连接，第二次握手之后，从b机器的视角看还有两个红色的no是无法确定的，只有在第三次握手之后才能确认完毕 防止脏数据，ttl网络报文的生存时间往往都会超过tcp请求超时时间，如果两次握手就建立连接，传输数据并释放连接后，第一次超时的请求才到达b机器，b机器会认为是a创建新的连接请求，然后确认统一创建连接，因为a的状态不是xx，所以直接丢了b的确认数据，以至于最后只是b机器单方面的创建连接完毕 tcp断开连接为什么是四次？为什么四次？ 确保数据能够完成传输 第一次:** A—&gt;B：我要断开连接 第二次： B—&gt;A：我答应你，但是要等我处理完数据 第三次 B—&gt;A：我处理完了，咱们断开连接把 第四次 A—-&gt;B：我答应你，咱俩掰了 快速排序快速排序经典的呢，叫单轴快排，改进的叫双轴快排 他的排序思想就是：在数组中选择一个元素作为轴进行排序 第一次将大于轴的元素放在轴右边，小于轴的元素放在轴左边，这样就完成了第一次排序，然后对轴两边分区选轴进行递归排序，直到只剩下一个元素时返回。 双轴快排使用到Arrays中是sort方法，所处理的都是基本数据类型 空间复杂度是 ologn，如果不考虑递归的话，可以达到o1 链表，反转链表二叉树遍历并发volatile可见性（✅） 会强制将修改的值写入主内存，并且其他用过的工作内存的值都无效了 原子性（❌） 自增不是原子操作，volatile也无法保证对变量的任何操作都是原子性的 valatile只能保证对单次读、写的原子性 有序性（✅❌一定程度） volatile禁止指令重排有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在他前面的操作肯定已经全部进行，且结果对后面的操作可见；在他后面的操作肯定都还没有执行 在进行指令优化时，不能讲volatile变量访问的语句放在他后面执行，也不能放到前面执行 使用场景 synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于他，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile无法保证操作的原子性 使用volatile必须具备以下两个条件（实际就是保证使用场景是原子性操作） 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 多线程1、为什么用线程池使用线程池主要是为了解决： 通过重用线程池中的线程，来减少每个线程的创建销毁的性能开销 对线程进行一些维护和管理，比如定时开始，周期执行，并发控制等等 不要用多线程去治理长连接，肯定是异步的网络模型nio，不在这里多说。 2、线程池参数什么意思？corePoolSize 常驻核心线程数，即本地任务执行完毕，核心线程也不会被销毁 maximumPoolSize 线程池最大线程数，必须大于等于1，如果待执行的线程数大于此值，需要借助第五个参数（workQueue）的帮助，缓存在队列中，如果与核心线程数一致的话，即固定了线程池大小 keepAliveTime 线程池中的线程空闲时间，当空闲时间达到此值时，线程会被销毁，只剩下核心线程 TimeUnit 时间单位，结合上面这个一起用，通常是秒 workQueue 表示缓存队列，请求的线程数大于线程池最大线程数时，线程进入BlockingQueue阻塞队列 threadFactory 线程工厂，用来生产一组相同任务的线程，线程池的命名就是通过给这个factory增加组名前缀来实现的 handler 表示执行拒绝策略的对象，当超过第五个为参数workQueue的任务缓存区上线的时候，就可以通过该策略处理请求，这是一种简单的限流保护 3、线程池中的threadpoolexecutor，每个参数是干嘛用的？4、说一下线程池内部使用规则5、用过AtomicInteger吗？怎么用的6、用过threadlocal吗？怎么用的7、程序、进程、线程的区别？举个现实的例子说明8、java中通过哪些方式创建多线程类？分别使用代码说明，并调用之9、Thread类有没有实现Runnable接口？10、当调用一个线程对象的start方法后，线程马上进入运行11、下面的代码，实际上有几个线程在运行12、线程的几种状态13、说说：sleep、yield、join、wait方法的区别join 谁调用了join，谁就会被阻塞，直到join执行完毕 当先线程等待，调用此方法的线程执行结束再继续执行 比如：在main方法中调用t.join(),那么main会进入阻塞状态，一直等待t线程执行完毕，main方法再恢复到就绪状态，准备继续执行 sleep 需要制定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态。 该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。 14、为什么不推荐使用stop和destory方法来结束线程15、写个代码说明，终止线程的典型方式16、A线程的优先级是10，b线程的优先级是1，那么当进行调度时一定会调用A吗？17、synchronized加在static关键字前和普通方法前的区别？ Synchronized修饰非静态方法，实际上是对调用该方法的对象加锁，俗称“对象锁”，不同的对象没有竞争关系 Synchronized修饰static静态方法，实际上是对该类对象加锁，俗称“类锁”，这个类所有的对象竞争一把锁 结论：类锁和对象锁不同，他们之间不会产生互斥。 18、使用Timer和TimerTask实现定时执行，定时在每天下午17：00执行19、wait方法被调用时，所在线程是否会释放所持有的锁资源？sleep方法呢？20、wait、notify、notifyAll是在Thread类中定义的方法吗？作用分别是什么？21、notify是唤醒所在对象watipool中的一个线程吗？java虚拟机说一说jvm的内存模型（每一个模块都说）方法区（Method Area） 方法区主要是放一下类似类定义、常量、编译后的代码、静态变量等，在jdk1.7中hotspot vm 的实现就把他放在了永久代中，这样的好处是可以直接使用堆中的gc算法来管理，但坏处就是经常会出现内存溢出。 所以在1.8中，取消了永久代，用元空间取而代之，元空间直接使用本地内存，perm（永久代）区的字符串常量在堆内存 常量池中的string实际是保存在堆内存中的 堆（heap） oom故障最主要的发源地，几乎存储着所有的实例对象，堆由垃圾收集器自动回收，由各子线程共享使用，通常情况下，堆占用的内存是内存区域中最大的 对的内存空间既可以固定大小，也可以运行时动态调整，但是通常为了避免堆空间的不断扩容与收缩，在线上环境时，jvm最大堆空间和最小堆空间设置成一样，避免gc后调整大小带来的额外压力 新生代：1个eden区+2个survivor区 绝大部分对象在eden区生成，当eden区满了的时候，会触发young gc。垃圾回收的时候，在eden区实现清除策略，没有被引用的对象则直接回收。依然存活的对象会被已送到Survivor区。 Survivor分为s0 和 s1两块内存空间，那么送到哪块呢？每次ygc的时候，他们将存活的对象复制到未使用的那块空间，然后将当前正在使用的空间完全清除，交换两块空间的使用状态。 如果ygc要移送的对象大于Survivor区容量的上限，则直接移交给老年代。 每个对象都有一个计数器，每次ygc都会加1，-XX：MaxTenuring Threshold参数能配置计数器的值达到某个阈值的时候，对象从新生代晋升至老年代，如果该参数配置为1，那么从新生代的eden区直接移送到年老代。 默认值是15，可以在Survivor区交换14次之后，晋升至老年代。 流程图如下： ![image-20200114135528237](img/尚学堂 java 300 讲.assets/image-20200114135528237.png) 如果Survivor区无法放下，会尝试在老年代中进行分配，如果老年代也放不下，则会触发「fgc」，如果『fgc』后依然放不下，则抛出oom，所以给jvm设置运行参数-XX：+heapDumpOnOutOfMemoryError，让jvm遇到oom异常时能输出堆信息，特别是相隔数月才出现的oom异常尤为重要 虚拟机栈 jvm在执行方法时，会在此区域中创建一个栈帧来存放方法的各种信息，比如返回值，局部变量表和各种对象引用等，方法开始执行前就先创建栈帧入栈，执行完后就出栈 只有位于栈顶帧才是有效的， 称为“当前栈” 本地方法栈 和虚拟机栈类似，不过是专门给native方法用的 程序计数器 占用很小的一块区域，我们知道jvm执行代码是一行一行执行字节码文件，所有需要一个计数器来记录当前执行的行数 说一说垃圾回收吧？有哪些垃圾回收算法标记-清除 分为两个阶段，标记阶段、清除阶段 在标记阶段，首先通过根节点（gc roots）,标记所有从根节点开始的对象，未被标记的对象是未被引用的垃圾对象，然后，在清除阶段，清除所有未被标记的对象 缺点：会带来大量的空间碎片，在分配一个较大连续空间时容易触发fgc 标记-整理 从根集合节点进行扫描，标记出所有的存活对象，并将这些存活的对象整理到内存空间的一端，形成连续的已使用空间，最后把已使用空间之外的部分全部清理掉，这样就不会产生空间碎片 标记-复制 为了能够并行的标记和整理，将空间分为了两块，每次只激活其中一块，垃圾回收时只需要把存活的对象复制到另一块未激活的空间上，然后把未激活标记为已激活，把已激活标记未激活，然后清理原空间中的对象 场景：作为主流的ygc算法进行新生代的垃圾回收 分代收集算法 目前虚拟机使用回收算法，解决了标记整理不适合老年代的问题 将内存分为各个年代，一般是来年代，和新生代，永久代（jdk1.8中被元空间替代） 新生代存活率低，可以使用复制算法 老年代对象存活率高，没有额外空间对他进行分配担保，所以只能使用标记清除或者标记整理 如何判断一个对象是否应该回收 方法1：引用计数，该对象每被一个地方引用，计数器就加+1，引用失效时，计数器-1，计数器为0时的对象就不能再被使用 缺点：很难解决循环引用的问题 方法2：可达性分析法：通过gc roots作为七点，从这些节点开始，向下搜索，当一个对象到gc roots没有任何引用链，这个对象就是不可用的，至少两次标记 什么可以作为GC ROOT呢？ 类静态属性中引用的对象（方法区） 常量引用的的对象（方法区） 虚拟机栈中引用的对象（栈帧中的本地变量表） jni引用的对象（本地方法栈） 除了垃圾回收，还有哪些工作会造成cpu负载过高，100%负载，并给出排查过程 使用top命令查找占用cpu高的进程pid 显示线程列表 ps -mp 35867 -o THREAD,tid,time—-找到占用cpu过高的tid 将需要的线程tid转换为16进制 printf “%x\n” 35889 打印线程堆栈信息 jstack 35867 |grep 8c31 -A 30 cms收集器的特点（标记-清除） 回收停顿时间比较短，四个步骤完成工作 初始标记（只是标记一下gc roots能直接关联到的对象，速度很快） 并发标记（进行gc roots tracing 追踪） 重新标记（为了修正并发标记期间因用户程序持续运行产生变动的那一部分对象的标记记录，比1长，比2短） 并发清除（） 缺点 第1、3步需要stw 对cpu资源非常敏感，在并发阶段，虽然不会导致用户线程停顿，但是因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低 因为标记-清除，会产生大量碎片，可以配置参数，强制jvm在fgc后对老年代进行压缩，但是会stw G1★★★★ 四个步骤 初始标记 并发标记 最终标记 筛选回收 g1在jdk1.7中是推荐使用，jdk11是默认的 将堆空间分割成若干个大小相同的区域，即region，包括eden、Survivor、old、Humongous四种类型，Humongous是特殊的ol的类型，专门存放大对象，防止了反复拷贝移动 这样的划分方式，意味着不需要一个连续的内存空间管理对象，g1采用的是mark-copy，不产生大量的空间碎片 g1提供两种gc模式，ygc，mixedgc，两种都是stw的 面试题String a = ‘’abc”； 和 String b = new String（“abc”）；是不是一样的？为什么？他们对应的内存空间分别是什么？ 不一样 String a = ‘’abc”是在现在栈中创建一个string类的对象引用变量，然后查找栈中有没有存放“abc”，如果没有则将“abc”放入栈，并令a指向abc new String（abc）是在堆中存放，每次new 都会在堆中存放一个 equals比较值是否相等，==比较地址是否相等 Object o = new Object()解释一下对象的创建过程（半初始化） 123456&gt; static class T&#123;&gt; int m = 8;&gt; &#125;&gt; &gt; T t = new T();&gt; 编译后的字节码如下 new 为对象申请了一块内存，m此时是默认值，半初始化 dup invokespecial #3&lt;T.&gt; 这里才会把m设置为8，第1、3步之间就是半初始化状态 astore_1 return dcl单例(Double Check Lock)到底需不需要volatile问题 上锁前检查一次，上锁后再检查一次，要不要在定义的 时候加个volatile？ 阻止对这块内存的访问指令重排序 。需要，出现的几率很小，但是还是需要 对象在内存中的存储布局 普通对象 new xx() 对象头markword 类型指针classpointer：这个类型是什么类型？指向xx.class 实例数据instance data 比如说m=1，对象的数据 对齐padding ，比如最后算出来是30个字节？不是8的倍数怎么办？长成32 数组 T[] a = new T[5] 对象头 类型指针:数组是什么类型？int？T？ 数组长度（length 4字节） 实例数据 对齐 对象头具体包括什么 锁的信息 gc的信息：被回收多少次了 hashCode 对象头占用8个字节（64位虚拟机） 什么时候回产生hashcode？当然是调用未重写的hashcode()方法以及System.identityHashCode的时候 对象怎么定位 直接指针是hotspot使用的方式 句柄方式： 优点：对象小，垃圾回收时不用频繁改动t 缺点：两次访问 直接指针 对象怎么分配（栈上-线程本地-eden-old） 该代码在内存中占用多少字节 要看压不压缩 一个object占多少字节？ 16 new int[]{} 是24 常用框架、技术springspring框架是一个轻量级的控制反转和面向切面的容器框架 轻量 从大小到开销来说都是轻量的，spring框架开源字啊一个只有1m大小的jar文件中发布，而且spring所处理的开销也是微不足道的 非侵入式 spring应用中的对象不依赖于spring的特定类 IOC（控制反转） 一个对象依赖的其他对象会通过被动的方式传递进来，而不是这个对象自己创建或者主动查找依赖对象 AOP（面向切面） 只完成业务逻辑，并不负责其他的系统级的关注点 容器 定义了bean是如何创建、配置、管理的 框架模块你可以不必将应用完全基于spring，可以自由的挑选适用你的模块，而忽略其余的模块 核心容器这是spring框架最基础的部分，它提供了依赖注入特征来实现容器对bean的管理。这里最基本的概念是BeanFactory，它是任何spring应用的核心。BeanFactory是工厂模式的一个实现，他使用ioc将应用配置和依赖说明从实际的应用代码中分离出来 应用上下文（context）模块核心模块的beanFactory使spring成为了一个容器，而上下文模块使他成为一个框架，这个模块扩展了BeanFactory的概念，增加了对国际化消息、事件传播以及验证的支持 另外，这个模块提供了许多企业服务，例如电子邮件、JNDI访问、EJB集成、远程以及时序调度（scheduling）服务。也包括了对模版框架例如Velocity和FreeMarker集成的支持。 AOP模块JDBC抽象和DAO模块使用jdbc经常导致大量的重复代码：连接、创建于巨，处理结果集，关闭链接。 这两个模块抽取了这些重复代码，因此可以保持数据库访问代码干净简洁。 这个模块还使用了aop模块为spring应用中的对象提供了事务管理服务 对象/关系映射集成orm模块，spring并不试图实现自己的orm解决方案，而是为集中流行orm框架提供了集成方案。 spring的事务管理支持这些orm框架中的每一个也包括jdbc。 WEB 模块web上下文模块建立于应用上下文模块之上，提供了一个合适于web应用的上下文。另外，这个模块还提供了一些面向服务支持。例如：实现文件上传的multipart请求，它也提供了spring 和其它web框架的集成，比如Struts、WebWork。 mvc框架spring为构建web应用提供了一个功能全面的mvc框架。虽然spring可以很容易的与其它mvc框架集成，例如struts，但spring的mvc框架使用ioc对控制逻辑和业务对象提供了完全的分离。 ioc使用到的设计模式1.简单工厂模式 应用场景：又叫静态工厂，不属于23中设计模式。实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类 BeanFactory就是简单工程模式的体现，根据传入一个唯一的标识来获取bean对象 2.工厂模式 应用场景：通常由应用程序直接使用new创建新的对象，为了将对象的创建和使用相分离，采用工厂模式，即应用程序将对象的创建及初始化职责交给工厂对象。 一般情况下，应用程序有自己的工厂对象来创建bena，如果将应用程序自己的工程对象交给spring管理，那么spring管理就不是普通bean，而是工程bean 3.单例模式 应用场景：保证一个类只有一个实例，并提供一个访问它的全局访问点 spring中的单例模式只完成了后半句，即提供了全局的访问点BeanFactory，但没有从构造器级别去空值单例，这是因为spring管理的是任意的java对象，spring下默认的bean均为单例 4.原型模式-Prototype 应用场景：原型模式就是从一个对象再创建另外一个可定制的对象，而且不需要知道任何创建的细节 所谓原型模式，就是java中的克隆技术，以某个对象为原型，复制出新的对象，显然新的对象具备原型对象的特点，效率噶（避免了重新执行构造过程步骤） 5.代理模式–Proxy 应用场景：为其他对象提供一种代理以控制对这个对象的访问。从结构上看和Decorator（装饰器）模式类似，但是proxy是控制，更像是一种对功能的闲置，而Decorator是增加职责。 spring中代理模式体现在aop中，比如cglibAopProxy，和jdkAopProxy 6.策略模式–Strategy 应用场景：定义一系列的算法，把它们一个个封装起来，并且使他们可互相替换，最终执行结果是固定的，执行过程和执行逻辑不一样 spring中在实例化对象的时候用到了Strategy模式 7.模板方法模式–TemplateMethod 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，TemplateMethod使得子类可以不改变一个算法的结构即可重新定义该算法的某些特定步骤 TemplateMethod模式一般是需要继承的。执行流程固定，但是中间实现步骤有细微差别 springorm数据类型 8.委派模式–Delegate 应用场景：不属于23中设计模式，是面向对象设计模式中常用的一种模式。这种模式的原理为类b和类a是两个没有任何关系的类，b具有和a一模一样的方法和属性；并且调用b中的方法，属性就是调用a中同名的方法和属性，b好像就是一个受a委托授权的终结。第三方的代码不需要指定a的存在，也不需要和a发生直接的联系，通过b就可以直接使用a的功能，这样既能够使用到a的各种功能，又能够很好的将a保护起来，一举两得 要和代理模式区分开来，持有被委托人的引用，不关心过程，只关心结果 DIspatcher 9.适配器模式–Adapter springAOP模块对BeforeAdvice、AfterAdvice、ThrowsAdvice三种通知类型的支持实际上是借助适配器模式来实现的，这样的好处是使得框架允许用户向框架中加入自己想要支持任何一种通知雷丁，这三种通知类型是springAOP模块定义的，他们是AOP联盟定义的Advice的子类型 10.装饰器模式–Decorator 应用场景：比如说项目需要多数据库连接，用户每次访问都会根据需要去访问不同的数据库 首先想到的是在spring的applicationContext中配置所有的DataSource。这些DataSource可能是各种不同类型的，比如不同的数据库oracle、mysql，也可能是不同的数据源：比如Apache提供的org.apache.commons.dbcp.BasicDataSource、Spring提供的org.springframework.jndi.JndiObjectFactoryBean等。然后SessionFactory根据客户的每次请求，将DataSource属性设置成不同的数据源，以到达切换数据源的目的。 spring中用的包装器模式在类名上有两种表现：一种是类名中含有Wrapper、另一种是类名中喊有Decorator。基本上都是动态的给一个对象添加一些额外的职责。 io流包装、数据源包装等 11.观察者模式–Observer 应用场景：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变是，所有依赖于它的对象都得到通知并被自动更新 Spring中Observer模式常用的地方是Listener的实现。如：ApplicationListener 一般由两个角色组成：发布者和订阅者（观察者），观察者通常有一个回调，也可以没有，监听器、日志收集 设计模式对比 设计模式 一句话归纳 工厂模式Factory 只对结果负责，不要三无产品 单例模式Singleton 保证独一无二 适配器模式Adapter 需要一个转换头（兼容） 装饰器模式 Decorator 需要包装，但不改变本质（同宗同源） 代理模式Proxy 办事要求人，所以找代理 观察者模式Observer 完成时通知我 策略模式Strategy 我行我素，达到目的就行 模板模式Template 流程标准化，原料自己加 委派模式Delegate 干活是你的（普通员工），功劳是我的（项目经理） 原型模式prototype 拔一根好，吹出千万个 编程思想总结 spring思想 应用场景（特点） 一句话归纳 aop 面向切面变成，找出多个类中中有一定规律的代码，开发时拆开，运行时再合并，例如aop日志 解耦，专人做专事 oop 面向对象变成，归纳总结生活中的一切事务 封装、集成、多态 bop 面向bean编程，面向bean（普通java类）设计程序 一切从bean开始 ioc 控制翻转，将new对象的动作交给spring管理，并由spring保存已创建的对象（ioc容器） 转交控制权（控制翻转） DI/DL 依赖注入或者依赖查找，spring不仅保存自己创建的对象，而保存对象与对象之间的关系注入即赋值，主要三种方式：构造方法、set方法、直接赋值 先理清关系再赋值 cglib与jdk的区别是： 创建代理的消耗 cglib不适合频繁创建，适合创建一次，长期使用 spring bean 的加载、注入过程 执行该对象的构造方法 执行set参数注入方法 执行BeanNameAware的实现方法获取bean的id 执行BeanFactoryAware的实现方法获取bean的工厂 执行BeanPostProcessor的postProcessBeforeInitalization处理方法 执行In 说一下对spring的理解，ioc和aop在项目里怎么用的spring 是一个开源框架，处于mvc的控制层，能应对需求的快速变化，主要原因是它有一种面向切面编程（aop）的优势 其次它提升了系统性能，是因为通过依赖倒置机制（ioc），系统中用到的对象不是在系统加载时就全部实例化，而是在调用到这个类时才会实例化该对象 优点 降低了组件之间的耦合性，实现了软件各层之间的解耦 可以使用容易提供的众多服务，事务管理、消息服务、日志记录等 容器提供了aop，利用它很容易实现如权限拦截、运行期监控等功能 Spring中的aop技术是设计模式中的动态代理模式 AOP的两种实现方式？哪个效率更高？为什么？jdk动态代理、cglib JDK动态代理具体实现原理 通过实现InvocationHandle接口创建自己的调用处理器 通过Proxy类指定ClassLoader对象和一组interface来创建动态代理 通过反射机制获取动态代理类的构造函数，其唯一参数类型就是调用处理器接口类型 通过构造函数创建动态代理实例，构造时调用处理器对象作为参数传入； jdk动态代理是面向接口的代理模式，如果被代理目标没有接口那么spring也无能为力，Spring通过java的 反射机制生产被代理接口的新的匿名实现类，重写了其中AOP的增强方法。 CGLib动态代理 强大的、高性能的Code生产类库，可以实现运行期动态扩展java类，Spring在运行期间通过cglib集成要被动态代理的类，重写父类的方法，实现Aop切面变成 两者的对比 jdk是面向接口的 cglib是通过字节码底层集成要代理类来实现（如果被代理类被final修饰，那么会失败） 性能 主要体现在如下的两个指标中 cglib所创建的动态搭理对象在实际运行时候的性能要比jdk高，大概10倍 cglib在创建对象的时候所花费的时间比jdk要高，大概8倍 因此，对于Singleton的代理对象或者具有实例池的代理，因为无需频繁的创建代理对象，所以比较适合采用cglib动态代理，反之使用jdk spring事务的传播机制有如下几种 PROPAGATION_REQUIRED：如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS：支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY：使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 常用的主要由三个：Required、RequresNew、Nested Required：简单理解就是事务方法会判断是否存在事务，有事务就用已有的，没有就重新开启一个 RequiresNew：简单理解就是开启新事务，若当前已有事务，挂起当前事务。新开启的事务和之前的事务无关，拥有自己的锁和隔离级别，可以独立提交和回滚，内层事务执行期间，外层事务挂起。内层事务执行完毕，外层事务恢复执行 Nested：简单理解就是：嵌套事务，如果外部事务回滚，则嵌套事务也回滚！！外部事务提交的时候，嵌套事务才会被提交。嵌套事务回滚不会影响外部事务 如果想事务一起执行可以用Required满足大部分场景，如果不想让执行的子事务的结果影响到父事务的提交，可以将子事务设置为RequiresNew 简单说一下IOC、DIInversion on Control，控制翻转，对象的创建交给外部容器完成，这个就叫做控制翻转 Dependency injection，依赖注入、处理对象的依赖关系 区别： 控制反转，解决对象创建的问题 依赖注入，在创建完对象后，对象的关系的处理就是依赖注入 springboot 核心配置文件是哪几个？他们的区别是啥？ applicaion和boostrap配置文件 application配置文件主要用于springboot项目的自动化配置 boostrap配置文件主要用于 ​ 一些固定的不能被覆盖的属性，一些加密解密的场景 配置文件有哪几种格式？有什么区别？ properties和yml 区别就是书写格式不同 另外 yml 格式不支持@propertySource注解导入配置 事务是怎么实现的？ 基于@Transactional注解 整体事务控制流程 当@Transactional注解的方法被外部的代码调用时，spring在运行时为方法所在类生成一个aop代理对象。 代理对象根据@transactional的属性，决定是否由事务拦截器TransactionInterceptor对此方法进行事务拦截。 在进行事务拦截时，会先开启事务，然后执行业务代码，根据执行是否出现异常，通过抽象事务管理来进行rollback或者commit。 数据库引擎是否支持事务？ mysql的mylsam不支持事务 如果事务生效，库和表的引擎必须是InnoDB 当事务方法被本类内部方法调用时，@Transactional 注解并不生效，因为，只有被当前类以外的调用时，才会由spring生成的代理对象来管理 一定要确保所使用的数据源加载了事务管理器（配置文件写一下就好） springboot的核心注解是哪个？他主要由哪几个注解组成？ 启动类上面的注解是@springbootApplication，它是核心注解，包含了以下三个注解 @springbootConfiguration：组合了@Configuration注解，实现配置文件的功能 @EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项 @ComponentScan：spring组件扫描 开启springboot 特性有哪几种方式? 继承spring-boot-starter-parent项目 导入spring-boot-dependencies项目依赖 springboot需要独立的容器运行吗？ 可以不需要，内置了tomcat/jetty等容器。 springboot 配置加载顺序 properties yaml文件 系统环境变量 命令行参数 springboot可以兼容老spring项目吗？如何做? 可以兼容，使用@ImportResource注解导入老spring项目配置文件 保护springboot应用有哪些方法？ 在生产中使用https 启用csrf保护 使用内容安全策略防止xss攻击 private不能事务，基于aop实现的，aspectj可以？？ springboot默认的代理是cglib？？ spring cloud 微服务之间是如何独立通讯的？ 同步：rpc、rest等 异步：消息队列 ribbon和feign的区别？ 都是客户端的负载均衡工具，feign的底层是通过ribbon实现的，是对riboon的封装 ribbon使用httpclient或者restTemplate模拟http请求，步骤繁琐。 feign采用接口+注解的方式，将需要调用的其他服务的方法定义成抽象方法即可，不需要自己构建http请求。就像调用自身工程的方法一样调用 注册中心用的什么？ 用的nacos= eureka+config nacos优点？ nacos自带配置中心，且提供了管理界面 动态刷新，eureka需要配合mq实现配置动态刷新，nacos采用netty保持tcp场链接实时推送 nacos可用根据业务和环境进行分组管理 默认提供权重设置功能，调整承载流量压力 nacos支持由客户端或服务端发起的健康检查，eureka是由客户端发起心跳 nacos支持对服务在线管理，eureka只是预览服务状态 选型建议？ 采用eureka防范的考虑 想用spring cloud 原生全家桶 想用本地文件和git作为配置管理的，将配置与服务分开管理 考虑短期的稳定性 采用Nacos方案的考虑 想在线对服务进行上下线和流量管理 不想采用MQ实现配置中心动态刷新 不想新增配置中心生产集群 考虑引入spring cloud alibaba生态 eureka 和zookeeper都可以提供服务注册和发现的功能，请说说两个的区别？ zookeeper保证的是cp，Eureka保证的ap zookeeper在选举期间注册服务谈话，虽然服务最终会回复，但是选举期间不可用的 eureka各个节点是平等关系，只要有一台eureka就可以保证服务可以用，查询到的数据并不是最新的 自我保护机制会导致： eureka不再从注册列表移除因长时间没有收到心跳而应该过期的服务 eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点（高可用） 当网络稳定是，当前实例新的注册信息会被同步到其他节点中（最终一致性） eureka可以很好的应对因为网络故障导致部分节点失去联系的情况，而不会像zookeeper一样使得整个注册系统瘫痪 eureka可以看做是一个工程，而zookeeper只是一个进程 springcloud是如何实现服务发现和注册的？ 服务在发布时指定对应的服务名（包括了ip地址和端口）将服务注册到注册中心（eureka或者zookeeper或者nacos） 在main方法添加@enableDiscoveryClient 同一个服务修改端口就可以启动多个实例 调用方的话：传递服务名称通过注册中心获取所有的可用实例，通过负载均衡策略调用（ribbon和feign）对用的服务 mybatis说一下mybatis与hibernate的区别共同点 都是通过orm对象关系映射框架，都是持久层数据框架 不同点 hibernate重量级框架，Mybatis是轻量级框架 Hibernate对jdbc的封装比较深，对开发者写sql的要求高，只要通过hql语句操作对象即可完成数据的持久化操作了 Mybatis也是对jdbc的封装，但是没有H那么深，他的sql语句都在配置里，也可以通过重新配置里sql，来实现数据优化 处理大数据的时候，建议使用Mybatis，它优化sql更方便 RocketMq核心模块 rocketmq-broker：接受生产者发来的消息并存储（通过调用rocketmq-stroe），消费者从这里取得消息 rocketmq-client：提供发送、接收消息的客户端API rocketmq-namesrv：NameServer，类似于Zookeeper，这里保存着消息的TopicName，队列运行时的元信息 rocketmq-common：通用的一些类、方法、数据结构等 rocketmq-remoting：基于Netty4的client/Server + fastjson序列化 + 自定义二进制协议 rocketmq-store：消息、索引存储等 rocketmq-filtersrv：消息过滤器（一般用tag就可以） rocketmq-tools：命令行工具 四大核心组成部分 他主要有四大核心：NameServer、Broker、Producer以及Consumer 可以看到，他啥都是可以集群的，这是他吞吐量大，高可用的原因之一 集群的模式也很花哨，可以支持多master模式、多master多slave异步复制模式、多master多slave同步双写模式 而且这个模式好像kafka啊，废话，rocketmq 本身就是阿里基于kafka的很多特性研发的 分别介绍一下各个集群组成部分NameServer 主要负责对数据源的管理，包括了对于topic和路由信息的管理。 类似于Dubbo中zookeeper，但NameServer与Zookeeper相比更轻量。主要是因为每个NameServer节点互相之间是独立的，没有任何信息交互。 NameServer压力不会太大，平时的开销主要是维持心跳和提供Topic-Broker的关系数据。 但是有一点需要注意，Brker想NameServer发心跳时，会带上当前自己所负责的所有Topic信息，如果Topic个数太多（万级别），会导致一次心跳中，光Topic的数据就几十m，网络情况差的话，网络传输失败，心跳失败，导致NameServer误认为Broker心跳失败 NameServer被设计成几乎无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是个伪集群。 每个Broker在启动的时候都会到NameServer注册， Producer在发送消息前会根据Topic到NameServer获取到Broker的路由信息，Consumer也会定时获取Topic的路由信息。 所有从功能上看NameServer应该是和Zookeeper差不多，据说RocketMq的早期版本确实使用的Zookeeper，后来改为了自己实现的NameServer Producer 生产者，负责产生消息，一般是由业务系统负责产生消息 Producer又用户进行分布式部署，消息由Producer通过多种负责均衡模式发送到Broker集群，发送延时低，支持快速失败。 RocketMq提供了三种方式发送消息：同步、异步、单向 同步发送：指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，重要通知邮件，营销短信等 异步发送：指发送方发出数据后，不等待接收方发回响应，就发送下个数据包，一般用于对响应时间不敏感的业务 单向发送：值负责发送消息而不等待服务器的回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集 Broker 消息中转角色，负责存储消息，转发消息 Broker是具体提供业务的服务器，单个broker节点与所有的NameServer节点保持长连接及心跳，并会定时将Topic信息注册到NameServer，顺带一提底层的通信和连接都是基于netty实现的 Broker负责消息存储，以Topic为维度支持轻量级的队列，单机可以支撑上完队列规模，支持消息推拉模型 官网上说：具有上亿级消息堆积能力，同事可严格保证消息的有序性 Consumer 消费者，负责消费消息，一般是由后台系统负责异步消费 Consumer也由用户部署，支持push和pull两种消费模式，支持集群消费和广播消费，提供实时的消息订阅机制 Pull：拉取，主动从消息服务器拉取消息，只要批量拉取到消息，用户应用就会启动消费过程 Push：推送，封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所有Push被称为被动消费；从实现上看还是从消费服务器中拉取消息，不同于pull的是 push首先要注册消费监听器，当监听器触发后才开始消费消息。 一次完成的通讯流程是什么样的？Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic陆游信息，并向Topic服务的Broker Master建立长连接，且定时向Broker发送心跳 Producer 只能将消息发送到Broker master，但是Consumer不一样，它同时和提供Topic的Master 和Slave建立长连接，既可以从Master订阅，也可以从Slave订阅消息 优点 单机吞吐量：十万级 可用性：非常高，分布式架构 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：mq功能较为完善，还是分布式的，扩展性好 支持10亿级别的消息堆积，不会因为堆积导致性能下降 源码是java，我们可以自己阅读源码，定制自己公司的mq，可以掌控 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况 稳定性更值得信赖，经历了多次双11 缺点 支持的客户端语言不多，java、c++(不成熟) 社区活跃度不是特别活跃的那种 没有在mq核心中去实现jms等接口，有些系统要迁移需要修改大量代码 消息去 陌陌面试题java多线程的实现？二叉树后序遍历网络io模型三次握手每次在干嘛？两个有序表的第n 和第n+1 大的数，不要额外空间，时间复杂度优化到nlogn？设计模式单例模式优点 只创建一个实例，节省内存开销 减少了系统的性能开销，创建、回收对象都对性能有影响 提供了对唯一实例的受控访问 允许可变数目的实例 缺点 没有抽象层，因此扩展有很大的困难 单例类的职责过重，一定程度上违背了“单一职责原则” 滥用单例将带来一些负面问题：比如实例化的对象长时间不被利用，系统会认为是垃圾而回收 使用场景 web中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来 要求生产唯一序列号 创建一个对象需要消耗的资源过多，比如I/O与数据库的连接等 关键代码 构造函数是私有的 注意事项 getInstance()方法中需要使用同步锁synchronized(Singleton.class)防止多线程同事进入造成instance被多次实例化。 懒汉 123456789101112131415161718/** * 静态内部类,在调用时才会初始化,因此是懒汉式 * 看似是饿汉式,但只有调用getLazySingleton时才会初始化,线程安全由ClassLoad保证,不用思考怎么加锁 * &lt;p&gt; * 缺点:仍然会被反射和序列化攻击 */private static class LazySingletonHolder &#123; private static LazySingleton lazySingleton = new LazySingleton(); private void LazySingleton() &#123; &#125; public static LazySingleton getLazySingleton() &#123; return LazySingletonHolder.lazySingleton; &#125;&#125; 饿汉 123456789101112131415161718192021public class HungrySingleton &#123; /** * HungrySingleton 对象已经创建完成[在类加载时创建] */ public static HungrySingleton hungrySingleton = new HungrySingleton(); /** * 私有化构造函数,不能被外部访问 * 创造对象的行为只能由这个类决定 */ private HungrySingleton() &#123; &#125; /** * 返回单例对象 */ public static HungrySingleton getHungrySingleton() &#123; return hungrySingleton; &#125;&#125; 创建线程安全的单例有哪些实现方法？ 123456789101112131415双检锁/双重校验锁public class Singleton&#123; private volatile static Singleton singleton; private Singleton()&#123;&#125;; public static Singleton getInstance()&#123; if(null==singleton)&#123; synchronized(Singleton.class)&#123; if( null == singleton)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 登记式/静态内部类 123456789public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举 1234public enum Singleton&#123; INSTANCE; public void whatEverMethod()&#123;&#125;&#125; ArrayListArrayList有用过吗？它是一个什么东西？可以用来做什么？ 就是一个数组列表，主要用来状态数据，如果装在的是基本数据类型（int、long、boolean、short、byte、double、char、float）的时候，只能存储他们对应的包装类,它的主要底层实现是数组 与它类似是LinkedList、和LinkedList相比，它的查找和访问元素的速度较快，但是增删慢 小结：底层是数组实现的存储 特点：查询效率高，增删效率低，线程不安全，使用频率高 线程不安全，为啥还使用它呢？ 因为正常使用的场景中，都是用来查询，不会涉及太频繁的增删，如果涉及频繁的增删，可以使用LinkedList，如果要线程安全就使用Vector，这就是三者的区别，实际开发中还是ArrayList使用的最多。 不存在一个集合工具查询效率高，增删效率也高，线程还是安全的。 做的也都是一些线下的系统，没啥并发 它的底层是数组，数组是定长的，如果我们不断的往里面添加数据的话，不会有问题吗？ ArrayList可以通过构造方法在初始化的时候指定底层数组的大小 如果是使用无参构造初始化，则赋值底层数据一个默认空数组，只有真正对数据进行添加是，才会分配默认的初始容量10 可以看下它的无参构造和有参构造，无参就是默认大小，有参会判断参数 数组是有长度限制的，而ArrayList是可以存放任意数量对象，长度不受限制，那么他是怎么实现的呢？ 实现比较简单，他就是通过数组扩容的方式去实现的。 比如说现在有一个长度为10的数组，需要新增第11个了，发现已经满了，那么会怎么做呢？ 第一步：他会重新定义一个10+10/2的数组也就是一个长度为15的数组 第二步：把原数组的数据，原封不动的复制到新数组中，这个时候再把指向原数组的地址切换到新地址，ArrayList就这样完成了一次扩容 能具体说下1.7和1.8初始化的时候的区别么？ 初始化的时候：1.7以前会调用this(10)的时候才是真正的容量为10，1.7开始就是默认走空数组了，只有第一次add的时候才会变成10 ArrayList的默认数组大小为什么是10？ 不清楚。。。 为什么增删慢？ 因为他的数组，是连续的内存空间，比如说删除一个的话，需要移动后面所有的 ArrayList（int initialCapacity）会不会初始化数组大小？ 会初始化数组大小！但是List没，那size就没变，set下标和size比较的那就报错了。 ArrayList插入删除一定慢么？ 取决于你删除的元素离数组末端有多远，ArrayList拿来作为堆栈来用还是挺合适的，push和pop操作完全不涉及数据移动操作。 它的删除是怎么实现的呢？ 删除跟新增是一样的，不过叫是叫删除，但是在代码里可以发现，他还是在copy一个数组，举个例子：要删除index5这个位置 那么代码就复制一个index5+1到最后的数组，然后把它放到index开始的位置 index5的位置就被成功“删除了”，起始就是被覆盖了 ArrayList是线程安全的么？ 当然不是，线程安全的数组容器是Vector Vector的实现很简单，就是把所有的方法统统加上Synchronized就完事了。 你也可以不使用vector，用Collections.synchronizedList把一个普通的ArrayList包装成一个线程安全版本的数组容器也可以，原理同Vector是一样的，就是给所有的方法套上一层synchronized ArrayList用来做队列合适么？ 队列一般是FIFO（先进先出）的，如果用ArrayList做队列，就需要在数组尾部追加数据，数组头部删除数组，或者反过来。 但是无论如何总会有一个操作涉及到数组数据的迁移，耗费性能 结论：不适合 那数组适合做队列吗？ 数组是非常适合的 比如ArrayBlockingQueue内部实现就是一个环形队列，它是一个定长队列，内部是用一个定长数组来实现的。 另外著名的Disruptor开源Library也是用环形数组来实现的超高性能队列，具体原理不做解释，比较复杂。 简单点说就是使用两个偏移量来标记数组的读位置和写位置，如果超过长度就折回到数组开头，前提是它们是定长数组。 ArrayList的遍历和LinkedList遍历性能比较如何？ ArrayList快得多，内存是连续的，cpu的内部缓存结构会缓存连续的内存片段，可以大幅度降低读取内存的性能开销。 总结： ArrayList就是动态数组，可以看成Array的复杂版本，提供了冬天的增删，实现了ICollection和IList接口，灵活的设置数组的大小等好处 面试频率不如HashMap和ConcurrentHashMap 秒杀系统设计场景要定点秒杀100件手机 问题高并发 时间短，瞬间用户量大 超卖 恶意请求 黄牛几十台机器脚本秒杀，模拟个十几万人的请求 链接暴露 前端暴露了地址，或者开发人员自己知道了，猛点 数据库 每秒上万甚至十几万的qps打到数据库，基本gg 解决办法服务单一职责 微服务设计思想，再用分布式的部署方式 给秒单独的服务，单独的库 好处：就算挂了， 也不会影响其他服务 秒杀连接加盐 把url动态化，就连写代码的人都不知道，通过md5之类的加密算法随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。 redis集群 单机redis顶不住，那就多找几个兄弟，秒杀本来就是读多写少 redis集群、主从同步、读写分离、还可以高点哨兵，开启持久化直接无敌高可用 nginx 高性能的web服务器，并发也是随便几万不是梦，但是tomcat只能顶几百的并发啊。那简单啊负载均衡嘛，一台服务器几百，那就多搞点，在秒杀的时候多租点流量机 恶意请求拦截也需要用它，一般单个用户请求次数太夸张，不像真人的请求在网关那一层就得拦截掉了 资源静态化 秒杀一般都是特定的商品还有页面模板，现在一般都是前后端分离的，所有页面一般是不会经过后端的，但是前段也要有自己的服务器啊，那就把能提前放到cdn服务器的东西都放进去，反正把能提升效率的步骤都做一下，减少真正秒杀时候服务器的压力 按钮控制 秒杀前按钮置灰，到点了才能点 这是防止在快到秒杀前的时间疯狂请求服务器，这个时候就需要前端的配合，定时去请求你的后端服务器，获取最新的北京时间，到时间点了再给按钮可以用 点击一次之后也得置灰几秒，防止一直点 限流 前端限流：跟按钮控制类似，防止一直点 后端限流：秒杀的时候肯定是涉及到了后续的订单生成和支付操作，一旦秒杀产品卖完了，return一个false，前端直接秒杀结束 真正的限流还会有限流组件，比如阿里的Sentinel、Hystrix等 库存预热 秒杀的本质，就是对库存的争夺，每个秒杀的用户来你都去数据库查询库存校验库存，然后扣减库存，对开发很不友好，而且数据库顶不住啊 提前把商品的库存加载到redis中去，让整个流程都在redis里做，然后等秒杀结束了，再异步的去修改库存就好了 但是用redis的话就有一个问题了，我们上面说了主从，然后回去读库然后再判断有库存才去减库存，正常情况没问题，但是高并发的情况问题就很大了：比如只剩下一个库存了，高并发，四个服务器一起查询大家发现都还剩一个，都觉得自己抢到了，都去扣库存了，结果变成-3了，这样就发生了超卖 Lua：lua脚本类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作，一个脚本=查库存+扣减库存，如果是0 了直接false 削峰填谷 说到这里就知道是说mq了，卖100个东西直接100个请求，我觉得没问题，但万一秒杀一万个，10万个呢，服务器挂了 把他放消息队列，然后一点点消费去改库存不就好了嘛 消息队列基础经典场景，需要熟烂于心：异步、削峰、解耦 异步 一个下单流程：本来需要100ms，后来产品说要加上积分，流程中加上积分扣减，200ms了 产品说要加上优惠券，300毫秒了 产品说要发短信，400毫秒了 再后来。。。 让产品加的这三点可以异步 面试官：异步，我用线程、线程池去做不一样吗？ 为什么不能用线程去做？ 用线程的话，扣积分、扣优惠券、发短信是不是都需要单独的接口？，每次加一个流程是不是代码都要改动？ 但是用了消息队列，问题迎刃而解啊： 你下单了，你就把你支付成功的消息告诉别的系统，他们收到了去处理就好了，来多少类似的需求，只需要对应的人员去监听该消息就行了 那你的流程走完了，别人没成功怎么办？ 起始不需要考虑，业务系统本身就是自己开发人员维护的，你扣积分失败和我下单有什么关系？ 削峰平时流量低，但是秒杀时流量猛增，你的服务器，redis，mysql各自的承受能力都不一样，全部流量赵丹全收肯定有问题啊，直接就挂了 怎么办 把请求放到队列里面，每秒消费多少请求，就看自己的服务器处理能力，你能处理5000qps，你就消费这么多人，可能会比正常的慢一点，但是不至于打挂服务器，等流量高峰下去了，你的服务器也就没压力了 分布式事务消息去重、重复消费原则：使用业务端逻辑保持幂等性 策略：保证每条消息都要唯一编号（比如唯一流水号），且保证消息处理成功与去重表的日志同时出现。 建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键或约束，就算出现重复消费的情况，也会导致主键冲突，以后就不再处理这条消息了 消息重复Qos：Quality of Service 服务质量 消息领域对投递的定义分为： 最多一次 至少一次 仅一次 几乎所有的mq产品都声称自己做到了 至少一次 既然是至少一次，那避免不来消息重复，尤其是在分布式网络环境下 消息可用性当我们选择好了集群模式之后，那么我们需要关系的就是怎么去存储和复制这个数据，RocketMq对消息的刷盘提供了同步和异步的策略来满足我们。 同步刷盘：如果刷盘超时则会返给FLUSH_DISK_TIMEOUT，如果是异步刷盘不会返回刷盘相关信息，选择同步刷盘可以尽最大程度满足我们的消息不会丢失。 除了存储有选择之后，我们的主从同步提供了同步和异步两种模式来进行复制，当然选择同步可以提升可用性，但是消息的发送RT时间会下降10%左右。 RocketMq采用的是混合型的存储结构，即为Broker单个实例下所有的队列公用一个日志数据文件（即为COmmitLog）来存储 Kafka采用的是独立型的存储结构，每个队列一个文件。 RocketMq采用混合型存储结构的缺点在于：会存在较多的随机读操作，因此读的效率偏低。同时消费消息需要依赖ConsumeQueue，构建该逻辑消费队列需要一定开销。 顺序消费生产者消费者一般需要保证顺序消费的话，可能就是一个业务场景下的，比如订单的创建、支付、发货、收货。 那么这些东西是不是一个订单号呢？一个订单的肯定是一个订单号啊 一个topic下游多个队列，为了保证发送有序，RocketMq提供了MessageQueueSelector队列选择机制，他有三种实现： 我们可以使用Hash取模法，让同一个订单发送到同一个队列中，再使用同步发送包，只有同个订单创建消息发送成功，再发送支付消息。这样就保证了发送有序 Rokcet的topic内的队列机制，可以保证存储满足FIFO（先进先出），剩下的只需要消费者顺序消费即可 分布式事务Half Message(半消息）是指暂时不能倍Consumer消费的消息。Producer已经把消息成功发送到了Broker端，但此消息被标记为暂不能投递状态，处于该状态下的消息成为半消息，需要Producer对消息的二次确认后，Consumer才能去消费它。 消息回查由于网络闪断，生产者重启等原因，导致Producer端一直没有对半消息进行二次确认，这时Brocker服务器会定时扫描长期处于半消息的消息，会主动询问Producer端，该消息的最终状态（Commit 或者 Rollback），该消息即为消息回查。 A服务先发送个Half Message给Brock端，消息中携带 B服务 即将要+100元的信息。 当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。 执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应) 如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。 如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。 如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。 消息过滤Broker端消息过滤在broker中，按照Consumer 的要求做过滤，优点是减少了对于 Consumer 无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。 Consumer 端消息过滤这种过滤完全可由应用完全自定义实现，但是缺点是很多无用的消息要传到Consumer端 Broker的Buffer问题Broker的buffer通常指的是Broker中一个队列的内存Buffer大小，这类Buffer通常大小有限。 另外，RokcetMq没有内存Buffer概念，RocketMq的队列都是持久化磁盘，数据定时清除。 RockertMq同其他mq有个非常显著的区别，RocketMq的内存Buffer抽象成一个无线长度的队列，不管有多少数据进来都能装得下，这个无线是有前提的，Broker会定期删除过期的数据。 例如Broker只保存三天的消息，那么Buffer长度虽然无线，但是3天前的数据会被从队尾删除。 回溯消费回溯消息是只Concumer已经消费成功的消息，由于业务上的需求需要重新消费，要支持此功能，Broker在向Consumer投递消息成功后，消息仍然需要保留。并且重新消费一般是按时间维度。 RocketMq支持按照时间回溯消费，可以精确到秒，可以向前，向后 消息堆积消息中间件的主要功能就是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性 消息堆积有两种 堆积在内存Buffer，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息，这种情况堆积能力主要在于内存Buffer大小，而且消息堆积后，性能下降不大 堆积在持久化存储系统中，例如db，kv存储，文件记录形式。当消息不能再内存命cache命中时，要不可避免的访问磁盘，会产生大量读io，读io的吞吐量直接决定了消息堆积后的访问能力。 评估消息堆积能力主要有以下四点： 消息能堆积多少条，多少字节？即消息的堆积容量 消息堆积后，发消息的吞吐量大小，是否会受堆积影响？ 正常消费的Consumer是否受影响 访问堆积在磁盘的消息是，吞吐量有多大？ 定时消息定时消息是指消息发到Broker后，不能立刻被Consumer消费，要到特定的时间点或者等待特定的时间后才能被消费。 RocketMq支持定时消息，但是不支持任意时间精度，支持特定的level，例如5s,10s,1m等 如果要支持任意的时间精度，需要在Broker做，必须要做消息排序，再涉及到持久化，那么消息排序要不可避免的产生巨大性能开销]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 面试]]></title>
    <url>%2F2020%2F02%2F01%2Fjava-%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[摘自 基础与语法1 jdk jre 区别JRE：Java Runtime Environment（ java 运行时环境）。即java程序的运行时环境，包含了 java 虚拟机，java基础类库。 JDK：Java Development Kit（ java 开发工具包）。即java语言编写的程序所需的开发工具包。JDK 包含了 JRE，同时还包括 java 源码的编译器 javac、监控工具 jconsole、分析工具 jvisualvm等。 2 ==和equals的区别是什么? == 的作用： 基本类型：比较值是否相等 引用类型：比较内存地址值是否相等 equals() 的作用:引用类型：默认情况下比较的是内存地址是否相等。可以按照需求逻辑，重写对象的equals（）方法（重写 equals() 方法，一般须重写 hashCode() 方法）。 3 基本类型和包装类对象使用 == 和 equals进行比较的结果？1、值不同，使用 ＝＝ 和 equals() 比较都返回 false 2、值相同 使用 ＝＝ 比较： 基本类型 － 基本类型、基本类型 － 包装对象返回 true 包装对象 － 包装对象返回 false 缓存中取的包装对象比较返回 true（原因是 JVM 缓存部分基本类型常用的包装类对象，如 Integer -128 ~ 127 是被缓存的） Integer i1 = 100; Integer i2 = 100; Integer i3 = 200; Integer i4 = 200; System.out.println(i1==i2); //打印true System.out.println(i3==i4); //打印false 使用 equals() 比较 包装对象－基本类型返回 true 包装对象－包装对象返回 true 3、不同类型的对象对比，返回 false JDK1.8，实验代码 byte b1 = 127; Byte b2 = new Byte(&quot;127&quot;); Byte b3 = new Byte(&quot;127&quot;); System.out.println(&quot;Byte 基本类型和包装对象使用 == 比较 : &quot; + (b1 == b2)); System.out.println(&quot;Byte 基本类型和包装对象使用 equals 比较 : &quot; + b2.equals(b1)); System.out.println(&quot;Byte 包装对象和包装对象使用 == 比较 : &quot; + (b2 == b3)); System.out.println(&quot;Byte 包装对象和包装对象使用 equals 比较 : &quot; + b2.equals(b3)); System.out.println(); short s1 = 12; Short s2 = new Short(&quot;12&quot;); Short s3 = new Short(&quot;12&quot;); System.out.println(&quot;Short 基本类型和包装对象使用 == 比较 : &quot; + (s1 == s2)); System.out.println(&quot;Short 基本类型和包装对象使用 equals 比较 : &quot; + s2.equals(s1)); System.out.println(&quot;Short 包装对象和包装对象使用 == 比较 : &quot; + (s2 == s3)); System.out.println(&quot;Short 包装对象和包装对象使用 equals 比较 : &quot; + s2.equals(s3)); System.out.println(); char c1 = &apos;A&apos;; Character c2 = new Character(&apos;A&apos;); Character c3 = new Character(&apos;A&apos;); System.out.println(&quot;Character 基本类型和包装对象使用 == 比较 : &quot; + (c1 == c2)); System.out.println(&quot;Character 基本类型和包装对象使用 equals 比较 : &quot; + c2.equals(c1)); System.out.println(&quot;Character 包装对象和包装对象使用 == 比较 : &quot; + (c2 == c3)); System.out.println(&quot;Character 包装对象和包装对象使用 equals 比较 : &quot; + c2.equals(c3)); System.out.println(); int i1 = 10000; Integer i2 = new Integer(10000); Integer i3 = new Integer(10000); System.out.println(&quot;Integer 基本类型和包装对象使用 == 比较 : &quot; + (i1 == i2)); System.out.println(&quot;Integer 基本类型和包装对象使用 equals 比较 : &quot; + i2.equals(i1)); System.out.println(&quot;Integer 包装对象和包装对象使用 == 比较 : &quot; + (i2 == i3)); System.out.println(&quot;Integer 包装对象和包装对象使用 equals 比较 : &quot; + i2.equals(i3)); System.out.println(); long l1 = 1000000000000000L; Long l2 = new Long(&quot;1000000000000000&quot;); Long l3 = new Long(&quot;1000000000000000&quot;); System.out.println(&quot;Long 基本类型和包装对象使用 == 比较 : &quot; + (l1 == l2)); System.out.println(&quot;Long 基本类型和包装对象使用 equals 比较 : &quot; + l2.equals(l1)); System.out.println(&quot;Long 包装对象和包装对象使用 == 比较 : &quot; + (l2 == l3)); System.out.println(&quot;Long 包装对象和包装对象使用 equals 比较 : &quot; + l2.equals(l3)); System.out.println(); float f1 = 10000.111F; Float f2 = new Float(&quot;10000.111&quot;); Float f3 = new Float(&quot;10000.111&quot;); System.out.println(&quot;Float 基本类型和包装对象使用 == 比较 : &quot; + (f1 == f2)); System.out.println(&quot;Float 基本类型和包装对象使用 equals 比较 : &quot; + f2.equals(f1)); System.out.println(&quot;Float 包装对象和包装对象使用 == 比较 : &quot; + (f2 == f3)); System.out.println(&quot;Float 包装对象和包装对象使用 equals 比较 : &quot; + f2.equals(f3)); System.out.println(); double d1 = 10000.111; Double d2 = new Double(&quot;10000.111&quot;); Double d3 = new Double(&quot;10000.111&quot;); System.out.println(&quot;Double 基本类型和包装对象使用 == 比较 : &quot; + (d1 == d2)); System.out.println(&quot;Double 基本类型和包装对象使用 equals 比较 : &quot; + d2.equals(d1)); System.out.println(&quot;Double 包装对象和包装对象使用 == 比较 : &quot; + (d2 == d3)); System.out.println(&quot;Double 包装对象和包装对象使用 equals 比较 : &quot; + d2.equals(d3)); System.out.println(); boolean bl1 = true; Boolean bl2 = new Boolean(&quot;true&quot;); Boolean bl3 = new Boolean(&quot;true&quot;); System.out.println(&quot;Boolean 基本类型和包装对象使用 == 比较 : &quot; + (bl1 == bl2)); System.out.println(&quot;Boolean 基本类型和包装对象使用 equals 比较 : &quot; + bl2.equals(bl1)); System.out.println(&quot;Boolean 包装对象和包装对象使用 == 比较 : &quot; + (bl2 == bl3)); System.out.println(&quot;Boolean 包装对象和包装对象使用 equals 比较 : &quot; + bl2.equals(bl3));运行结果 Byte 基本类型和包装对象使用 == 比较 : true Byte 基本类型和包装对象使用 equals 比较 : true Byte 包装对象和包装对象使用 == 比较 : false Byte 包装对象和包装对象使用 equals 比较 : true Short 基本类型和包装对象使用 == 比较 : true Short 基本类型和包装对象使用 equals 比较 : true Short 包装对象和包装对象使用 == 比较 : false Short 包装对象和包装对象使用 equals 比较 : true Character 基本类型和包装对象使用 == 比较 : true Character 基本类型和包装对象使用 equals 比较 : true Character 包装对象和包装对象使用 == 比较 : false Character 包装对象和包装对象使用 equals 比较 : true Integer 基本类型和包装对象使用 == 比较 : true Integer 基本类型和包装对象使用 equals 比较 : true Integer 包装对象和包装对象使用 == 比较 : false Integer 包装对象和包装对象使用 equals 比较 : true Long 基本类型和包装对象使用 == 比较 : true Long 基本类型和包装对象使用 equals 比较 : true Long 包装对象和包装对象使用 == 比较 : false Long 包装对象和包装对象使用 equals 比较 : true Float 基本类型和包装对象使用 == 比较 : true Float 基本类型和包装对象使用 equals 比较 : true Float 包装对象和包装对象使用 == 比较 : false Float 包装对象和包装对象使用 equals 比较 : true Double 基本类型和包装对象使用 == 比较 : true Double 基本类型和包装对象使用 equals 比较 : true Double 包装对象和包装对象使用 == 比较 : false Double 包装对象和包装对象使用 equals 比较 : true Boolean 基本类型和包装对象使用 == 比较 : true Boolean 基本类型和包装对象使用 equals 比较 : true Boolean 包装对象和包装对象使用 == 比较 : false Boolean 包装对象和包装对象使用 equals 比较 : trueps：可以延伸一个问题，基本类型与包装对象的拆/装箱的过程 4 什么是装箱？什么是拆箱？装箱和拆箱的执行过程？常见问题？1、什么是装箱？什么是拆箱？装箱：基本类型转变为包装器类型的过程。拆箱：包装器类型转变为基本类型的过程。 //JDK1.5之前是不支持自动装箱和自动拆箱的，定义Integer对象，必须 Integer i = new Integer(8); //JDK1.5开始，提供了自动装箱的功能，定义Integer对象可以这样 Integer i = 8; int n = i;//自动拆箱2、装箱和拆箱的执行过程？ 装箱是通过调用包装器类的 valueOf 方法实现的 拆箱是通过调用包装器类的 xxxValue 方法实现的，xxx代表对应的基本数据类型。 如int装箱的时候自动调用Integer的valueOf(int)方法；Integer拆箱的时候自动调用Integer的intValue方法。 3、常见问题？ 整型的包装类 valueOf 方法返回对象时，在常用的取值范围内，会返回缓存对象。 浮点型的包装类 valueOf 方法返回新的对象。 布尔型的包装类 valueOf 方法 Boolean类的静态常量 TRUE | FALSE。 实验代码 Integer i1 = 100; Integer i2 = 100; Integer i3 = 200; Integer i4 = 200; System.out.println(i1 == i2);//true System.out.println(i3 == i4);//false Double d1 = 100.0; Double d2 = 100.0; Double d3 = 200.0; Double d4 = 200.0; System.out.println(d1 == d2);//false System.out.println(d3 == d4);//false Boolean b1 = false; Boolean b2 = false; Boolean b3 = true; Boolean b4 = true; System.out.println(b1 == b2);//true System.out.println(b3 == b4);//true 包含算术运算会触发自动拆箱。 存在大量自动装箱的过程，如果装箱返回的包装对象不是从缓存中获取，会创建很多新的对象，比较消耗内存。 Integer s1 = 0; long t1 = System.currentTimeMillis(); for(int i = 0; i &lt;1000 * 10000; i++){ s1 += i; } long t2 = System.currentTimeMillis(); System.out.println(&quot;使用Integer，递增相加耗时：&quot; + (t2 - t1));//使用Integer，递增相加耗时：68 int s2 = 0; long t3 = System.currentTimeMillis(); for(int i = 0; i &lt;1000 * 10000; i++){ s2 += i; } long t4 = System.currentTimeMillis(); System.out.println(&quot;使用int&quot; + (t4 - t3));//使用int，递增相加耗时：6ps：可深入研究一下 javap 命令，看下自动拆箱、装箱后的class文件组成。 看一下 JDK 中 Byte、Short、Character、Integer、Long、Boolean、Float、Double的 valueOf 和 xxxValue 方法的源码（xxx代表基本类型如intValue）。 hashCode()相同，equals()也一定为true吗？首先，答案肯定是不一定。同时反过来 equals() 为true，hashCode() 也不一定相同。 类的 hashCode() 方法和 equals() 方法都可以重写，返回的值完全在于自己定义。 hashCode() 返回该对象的哈希码值；equals() 返回两个对象是否相等。 关于 hashCode() 和 equals() 是方法是有一些 常规协定 ： 1、两个对象用 equals() 比较返回true，那么两个对象的hashCode()方法必须返回相同的结果。 2、两个对象用 equals() 比较返回false，不要求hashCode()方法也一定返回不同的值，但是最好返回不同值，以提搞哈希表性能。 3、重写 equals() 方法，必须重写 hashCode() 方法，以保证 equals() 方法相等时两个对象 hashcode() 返回相同的值。 final在java中的作用final 语义是不可改变的。 被 final 修饰的类，不能够被继承。 被 final 修饰的成员变量必须要初始化，赋初值后不能再重新赋值(可以调用对象方法修改属性值)。对基本类型来说是其值不可变；对引用变量来说其引用不可变，即不能再指向其他的对象。 被 final 修饰的方法代表不能重写。 final finally finalize()区别 final 表示最终的、不可改变的。用于修饰类、方法和变量。final 变量必须在声明时给定初值，只能读取，不可修改。final 方法也同样只能使用，不能重写，但能够重载。final 修饰的对象，对象的引用地址不能变，但对象的属性值可以改变 finally 异常处理的一部分，它只能用在 try/catch 语句中，表示希望 finally 语句块中的代码最后一定被执行（存在一些情况导致 finally 语句块不会被执行，如 jvm 结束） finalize() 是在 java.lang.Object 里定义的，Object 的 finalize() 方法什么都不做，对象被回收时 finalize() 方法会被调用。Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要清理工作，在垃圾收集器删除对象之前被调用的。一般情况下，此方法由JVM调用。特殊情况下，可重写 finalize() 方法，当对象被回收的时候释放一些资源，须调用 super.finalize() 。 集合网络编程并发web安全设计模式框架数据结构与算法异常文件解析与生成linuxmysqlOracleRedisDubbo]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试，Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读与时间做朋友有感]]></title>
    <url>%2F2019%2F12%2F22%2F%E8%AF%BB%E4%B8%8E%E6%97%B6%E9%97%B4%E5%81%9A%E6%9C%8B%E5%8F%8B%E6%9C%89%E6%84%9F%2F</url>
    <content type="text"><![CDATA[近日读完了李笑来写的《与时间做朋友》收货一下观点 1 20分钟学习命令行下的批处理方法 2 Google通配符学习 3 概率统计学（买彩票这种行为在学过概率统计的人看来是对自己智商的侮辱） 4 千万不要拒绝学习 5 《今春的两种感想》对体验、试错、和观察进行补充的就是阅读。 6 伯纳姆与杰.费伦著《本能》 7 电影《新基督山伯爵》 8 达尔文《物种起源》 1859年11月24日 9 愚人网 10猴子吃香蕉被打（经验主义害猴子被打） 11 亚里士多德《论问题》”强光喷嚏反射” 12 美国前第一夫人罗莎琳.卡特就观察到了这样一个现象：”优秀的领导，能够把人们带到他们想去的地方，而卓越的领导，能够把人们带到他们应该去但是没想过要去的地方。A leader takes people where they want to go .A grate leader takes people where they don’t necessarily want to go ,but ought to be. 13 人在学生时期应该认真阅读至少3本关于科学史和科学方法的书籍 14 在人们探索未知、寻求真理的时候，困难几乎都来自于如何正确的理解”与现有经验相悖的知识” 15 自学能力的基础是阅读理解能力 16 写作能力在自学能力中占据重要位置。（这里提到的”写作能力”不是写小说的能力，不是写诗歌的能力，不是写剧本的能力，也不是写散文的能力，只是写作能力中最基本的一种——写出简洁、有效、准确、朴素、具体的说明性文章的能力。 17 对抗选择性输入：把目前无法理解的、支持的、反对的、无所谓的论点和观点记录下来。对无法理解的，写下自己当时的疑惑何在，对支持的，记录下几个理由或者实例；对反对的，同样记录几个理由或者实例；甚至对那些无所谓的，也记录其原因。一个有着这样良好记录习惯的人会获得他人无法拥有的处理信息和知识的能力——反刍chu 18 读教科书，要先把所有概念都记下来，暂时不懂的就死记硬背。把概念牢记于心，就可以通过以后的学习和实践反复审视它，并形成透彻理解。 19 学习任何一门学科，都最好先去读一下该学科的发展历史，这是最好的起点。 20 《围城》钱钟书著]]></content>
      <tags>
        <tag>读后感，李笑来</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps简介]]></title>
    <url>%2F2019%2F12%2F02%2FDevOps%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[摘抄自 DevOps简介DevOps是一个完整的面向IT运维的工作流，以IT自动化以及持续集成（CI）、持续部署（CD）为基础，来优化开发、测试、系统运维等多有环节。 DevOps的概念DevOps一词的来自于Development和Operations的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps是为了填补开发端和运维端之间的信息鸿沟，改善团队之间的协作关系。不过需要澄清的一点是，从开发到运维，中间还有测试环节。DevOps其实包含了三个部分：开发、测试和运维。 换句话说，DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。专家们总结出了下面这个DevOps能力图，良好的闭环可以大大增加整体的产出。 历史变革由上所述，相信大家对DevOps有了一定的了解。但是除了触及工具链之外，作为文化和技术的方法论，DevOps还需要公司在组织文化上的变革。回顾软件行业的研发模式，可以发现大致有三个阶段：瀑布式开发、敏捷开发、DevOps。 DevOps早在九年前就有人提出来，但是，为什么这两年才开始受到越来越多的企业重视和实践呢？因为DevOps的发展是独木不成林的，现在有越来越多的技术支撑。微服务架构理念、容器技术使得DevOps的实施变得更加容易，计算能力提升和云环境的发展使得快速开发的产品可以立刻获得更广泛的使用。 好处是什么？ DevOps的一个巨大好处就是可以高效交付，这也正好是它的初衷。Puppet和DevOps Research and Assessment (DORA) 主办了2016年DevOps调查报告，根据全球4600位各IT公司的技术工作者的提交数据统计，得出高效公司平均每年可以完成1460次部署。 与低效组织相比，高效组织的部署频繁200倍，产品投入使用速度快2555倍，服务恢复速度快24倍。在工作内容的时间分配上，低效者要多花22%的时间用在为规划好或者重复工作上，而高效者却可以多花29%的时间用在新的工作上。所以这里的高效不仅仅指公司产出的效率提高，还指员工的工作质量得到提升。 DevOps另外一个好处就是会改善公司组织文化、提高员工的参与感。员工们变得更高效，也更有满足和成就感；调查显示高效员工的雇员净推荐值（eNPS:employee Net Promoter Score）更高，即对公司更加认同。 快速部署同时提高IT稳定性。这难道不矛盾吗？ 快速的部署其实可以帮助更快地发现问题，产品被更快地交付到用户手中，团队可以更快地得到用户的反馈，从而进行更快地响应。而且，DevOps小步快跑的形式带来的变化是比较小的，出现问题的偏差每次都不会太大，修复起来也会相对容易一些。 因此，认为速度就意味着危险是一种偏见。此外，滞后软件服务的发布也并不一定会完全地避免问题，在竞争日益激烈的IT行业，这反而可能错失了软件的发布时机 为什么DevOps会兴起？条件成熟：技术配套发展技术的发展使得DevOps有了更多的配合。早期时，大家虽然意识到了这个问题的，但是苦于当时没有完善丰富的技术工具，是一种“理想很丰满，但是现实很骨感”的情况。DevOps的实现可以基于新兴的容器技术；也可以在自动化运维工具Puppet、SaltStack、Ansible之后的延伸；还可以构建在传统的Cloud Foundry、OpenShift等PaaS厂商之上。 来自市场的外部需求：这世界变化太快IT行业已经越来越与市场的经济发展紧密挂钩，专家们认为IT将会有支持中心变成利润驱动中心。事实上，这个变化已经开始了，这不仅体现在Google、苹果这些大企业中，而且也发生在传统行业中，比如出租车业务中的Uber、酒店连锁行业中的Airbnb、图书经销商Amazon等等。能否让公司的IT配套方案及时跟上市场需求的步伐，在今天显得至关重要。 DevOps 2016年度报告给出了一个运维成本的计算公式：停机费用成本 = 部署频率 * 版本迭代失败概率 * 平均修复时间 * 断电的金钱损失 来自团队的内在动力：工程师也需要 对于工程师而言，他们也是DevOps的受益者。微软资深工程师Scott Hanselman说过“对于开发者而言，最有力的工具就是自动化工具”（The most powerful tool we have as developers is automation）。 工具链的打通使得开发者们在交付软件时可以完成生产环境的构建、测试和运行；正如Amazon的VP兼CTO Werner Vogels那句让人印象深刻的话：“谁开发谁运行”。（You build it, you run it） 实现DevOps需要什么？硬性要求：工具上的准备上文提到了工具链的打通，那么工具自然就需要做好准备。现将工具类型及对应的不完全列举整理如下： 代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion 构建工具：Ant、Gradle、maven 自动部署：Capistrano、CodeDeploy 持续集成（CI）：Bamboo、Hudson、Jenkins 配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail 容器：Docker、LXC、第三方厂商如AWS 编排：Kubernetes、Core、Apache Mesos、DC/OS 服务注册与发现：Zookeeper、etcd、Consul 脚本语言：python、ruby、shell 日志管理：ELK、Logentries 系统监控：Datadog、Graphite、Icinga、Nagios 性能监控：AppDynamics、New Relic、Splunk 压力测试：JMeter、Blaze Meter、loader.io 预警：PagerDuty、pingdom、厂商自带如AWS SNS HTTP加速器：Varnish 消息总线：ActiveMQ、SQS 应用服务器：Tomcat、JBoss Web服务器：Apache、Nginx、IIS 数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库 项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker在工具的选择上，需要结合公司业务需求和技术团队情况而定。（注：更多关于工具的详细介绍可以参见此文：51 Best DevOps Tools for #DevOps Engineers） 软性需求：文化和人DevOps成功与否，公司组织是否利于协作是关键。开发人员和运维人员可以良好沟通互相学习，从而拥有高生产力。并且协作也存在于业务人员与开发人员之间。 出席了2016年伦敦企业级DevOps峰会的ITV公司在2012年就开始落地DevOps，其通用平台主管Clark在接受了InfoQ的采访，在谈及成功时表示，业务人员非常清楚他们希望在最小化可行产品中实现什么，工程师们就按需交付，不做多余工作。 这样，工程师们使用通用的平台（即打通的工具链）得到更好的一致性和更高的质量。此外，DevOps对工程师个人的要求也提高了，很多专家也认为招募到优秀的人才也是一个挑战。 DevOps的采用现状哪些公司在用？DevOps正在增长，尤其是在大企业中：调查发现，DevOps的接受度有了显著提高。74%的受访者已经接受了DevOps，而去年这一比例为66%。目前，在81%的大企业开始接受DevOps，中小企业的接受度仅为70%。那么具体而言都有些公司在采用DevOps呢？Adobe、Amazon、Apple、Airbnb、Ebay、Etsy、Facebook、LinkedIn、Netflix、NASA、Starbucks、Target（泛欧实时全额自动清算系统）、Walmart、Sony等等。 他们怎么实施的？首先，大企业正在自下而上接受DevOps，其中业务单位或部门（31%）以及项目和团队（29%）已经实施DevOps。不过，只有21%的大企业在整个公司范围内采用了DevOps。 其次，在工具层面上，DevOps工具的用量大幅激增。Chef和Puppet依然是最常用的DevOps工具，使用率均为32%。Docker是年增长率最快的工具，用量增长一倍以上。Ansible的用量也有显著增加，使用率从10%翻倍至20%。]]></content>
      <categories>
        <category>开发模式</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>开发模式，摘抄</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读别让自己墙了自己有感]]></title>
    <url>%2F2019%2F12%2F02%2F%E8%AF%BB%E5%88%AB%E8%AE%A9%E8%87%AA%E5%B7%B1%E5%A2%99%E4%BA%86%E8%87%AA%E5%B7%B1%E6%9C%89%E6%84%9F%2F</url>
    <content type="text"><![CDATA[文章链接 收获的主题 只专注于一种技术其他都是垃圾（不要将自己的技术栈封闭起来） 关注负面的东西不要胜过正面的东西 离开Java的世界就基本上做不了架构了 把自己最宝贵的时间用在了很烂的项目上，就算能用一些新技术也只能是自娱自乐，在实验室中玩玩罢了 把自己的技术栈封闭起来，直接放弃了这个时代最具有工业化的技术Java，对于一个好的程序员来说同时掌握几种语言和技术是完全没有问题的，不要自己封闭了自己的视野 视野、环境和舞台对一个人的限制是非常大的。井蛙不知大海，被空间维度所限制；夏虫不知冬天，被时间维度所限制；圈养的动物没有斗志，是被自己意志所限制。 偏见和不开放，对一个人限制是真正有毁灭性的。主动让自己成为一个瞎子和聋子，主动把自己能力阉割掉是多么让人痛心的一件事。 不限制自己的人会穷举各种方法来解决问题，限制自己的人，会找各式各样的问题或借口。 不限制自己的人，会努力改变自己的问题和缺陷，限制自己的人会放任自己。 先把软件设计好再写代码。 技术方向 Docker、go、k8s 翻找Youtube的各种大会，GitHub的各种issue和pull request 成为一个技术牛人的条件：基础知识过硬，细节扎得深，面很广，学习能力强，有英文能力，逻辑思维能力不错，非常的自律，执行力也很强，抓得住重点,最重要的一点：在大公司历练过。 总结 做高价值的事。所谓高价值，就是：别人愿付高价的，高技术门槛的，有创造力的，颠覆性的…… 扩大自己的眼界，开放自己的内心。你的英文语言能力对你能不能融入世界是起决定性的作用。你的视野决定了你知不知道要去哪，你的开放决定了你想不想去。 站在更高的维度.面的维度会超过点的维度，空间的维度会超过面的维度，在更高维度上思考和学习，你会收货更多。整天在焦虑那些低维度的事（比如自己的薪水、工作的地点、稳不稳定、有没有户口……)，只会让你变得越来越平庸，只要你站在更高的维度（比如：眼界有没有扩大、可能性是不是更多、竞争力是不是更强、能不能解决更大更难的问题、能创造多大的价值……)，时间会让你明白那些低维度的东西全都不是事儿。技术学习上也一样，站在学习编程语法特性的维度和站在学习编程范式、设计模式的维度是两种完全不一样的学习方式。 精于计算得失。很多人其实不是很懂计算。绝大多数人都是在计算自己会失去多少，而不会算得到多少。而一般的人也总是在算短期内会失去什么，优秀的则总是会算我投入后未来会有什么样的回报，前者在算计今天，目光短浅，而后者则是舍在今天，得在明天，计算的是未来。精于计算得失的，就懂得什么是投资，不懂的只会投机。对于赚钱，你可以投机，但是对于自己最好还是投资。 勇于跳出传统的束缚。做”鸡”的比”二奶”好多了 别自己墙了自己，人最可悲的就是自己限制自己，想都不敢想！ 庄子曰过： 井蛙不可以语于海者，拘于虚也；//空间局限 夏虫不可以语于冰者，笃于时也；//时间局限 曲士不可以语于道者，束于教也。//认识局限]]></content>
      <categories>
        <category>读后感</category>
      </categories>
      <tags>
        <tag>读后感，左耳</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杀威棍]]></title>
    <url>%2F2019%2F10%2F06%2F%E6%9D%80%E5%A8%81%E6%A3%8D%2F</url>
    <content type="text"><![CDATA[《说唐》里秦叔宝进牢房时,衙役喊得一句话来解释:“进的牢来先打你一百杀威棍,看你老不老实!”]]></content>
      <tags>
        <tag>传统文化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gpg是什么]]></title>
    <url>%2F2019%2F09%2F28%2Fgpg%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[GPG简介 GPG是GNU Privacy Guard的缩写，它是一种基于密钥的加密方式，使用了一对密钥对消息进行加密和解密，来保证消息的安全传输。 GPG有许多用途，主要用于文件加密。yum安装软件包的时候会使用gpg来验证。 1、大多数的linux发行版都默认包含了gpg# gpg --version2、gpg常用命令创建密钥 $ gpg --gen-key 查看公钥 $ gpg --list-key 查看私钥 $ gpg --list-secret-key 公钥删除 $ gpg --delete-keys 标识名 私钥删除 $ gpg --delete-secret-keys 标识名 公钥导出 $ gpg --export 标识名 &gt; 导出文件名（多以gpg,asc为文件后缀） 私钥导出 $ gpg --export-secret-key 标识名 &gt; 导出文件名（多以asc为文件后缀） 密钥导入 $ gpg --import 密钥文件 加密文件 $ gpg --recipient 标识名 --encrypt 文件名 解密文件 $ gpg --output 新文件名 --decrypt 加密文件名 修改密钥 $ gpg --edit-key 标识名3、gpg加密和ssh加密的区别ssh加密是专们为远程登录和其他网络服务，如ftp 提供安全的一个软件gpg是用来加密文件的]]></content>
      <categories>
        <category>gpg</category>
      </categories>
      <tags>
        <tag>gpg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论语学习]]></title>
    <url>%2F2019%2F09%2F28%2F%E8%AE%BA%E8%AF%AD%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[学习地址超星尔雅 第一讲孔子思想的特色温和的理性主义 深刻的人道情怀 乐观的人生理想 第二讲学儿篇学而时习之(从学习中发现快乐) 时:适当的时候 学了做人处事的道理适当的时候加以练习运用 人同此心,心同此理 学习的内容: 五经与六艺 学习的方法: 学思并用 学习的目的: 培养德行 不迁怒 不贰过 朋友由来同门曰朋同志曰友 儒家:不反对情绪,但需要做情绪管理]]></content>
      <categories>
        <category>传统文化</category>
      </categories>
      <tags>
        <tag>传统文化</tag>
        <tag>论语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续集成服务 Travis CI]]></title>
    <url>%2F2019%2F09%2F27%2F%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%9C%8D%E5%8A%A1-Travis-CI%2F</url>
    <content type="text"><![CDATA[官网参考参考]]></content>
      <categories>
        <category>TravisCI</category>
      </categories>
      <tags>
        <tag>TravisCI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springmvc在controller方法里面跳转外网的方法]]></title>
    <url>%2F2019%2F09%2F27%2Fspringmvc%E5%9C%A8controller%E6%96%B9%E6%B3%95%E9%87%8C%E9%9D%A2%E8%B7%B3%E8%BD%AC%E5%A4%96%E7%BD%91%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.return new ModelAndView(new RedirectView(“https://www.baidu.com&quot;)); 2.return “redirect:https://www.baidu.com/&quot;;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何培养孩子的逻辑思维]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%A6%82%E4%BD%95%E5%9F%B9%E5%85%BB%E5%AD%A9%E5%AD%90%E7%9A%84%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[逻辑思维能力重要吗？答案必然是肯定的，因为它不仅是学好数学必须具备的能力，同时也是学好其他学科，处理日常生活问题所必须具备的能力。 换句话说就是：逻辑思维，其可以成为“做好任何事情”的必要条件. what它是一种人类思维的高级形式，即我们所说的“抽象思维”。而一个人想具备很强的逻辑思维能力，往往需要从小开始培养。 why肥宅以为:逻辑思维就是智商最重要的方面之一,甚至之一也可以去掉. how背景美国的很多学校，他们从学前班开始就有关于训练孩子逻辑思维能力的数学内容 但在国内，我们对孩子逻辑思维的培养还存在一定的误区，学校往往喜欢让学生做题，找到考试的捷径，却忽视了对数学本质的讲解。 所以当我们没有将数学应用在生活中，这些定理和公式也会随着时间的流逝慢慢被淡忘。 所以将数学应用在生活中也就是锻炼逻辑思维的必要过程 那如何从小正确地培养孩子的逻辑思维能力呢？这就需要先了解一下孩子的逻辑思维的形成过程。动作思维阶段（0-3岁）不到3岁的孩子以动作思维为主，思维在动作中进行。比如桌上放着一个苹果，宝宝矮小够不着，怎么办呢?这时候宝宝发现他旁边有凳子，于是把凳子搬过来，自己爬上去，成功地把苹果拿到手。孩子学会借助别的东西来达到自己的目的，是从不断的操作过程中理解的。 孩子最初的动作往往是杂乱无章、漫无目的的，以后在不断的操作过程中了解了动作与结果之间的关系。 具体形象思维阶段（3-6岁）3-6岁的孩子具体形象思维占优势，他们缺少立体感和空间感。这也是为什么用数字加减，孩子反应不过来，但是用实物举例子，就容易理解。在这个阶段，家长要注意增加孩子的经验，丰富孩子的词汇，多给孩子动手的机会。有些家长和老师片面地、刻板地教孩子多识字、写字、计算等，对孩子的思维发展并没有好处。 抽象逻辑思维能力（6-11岁）6-11岁是培养孩子抽象逻辑思维能力的关键时期。在这一时期要培养孩子正确的思维程序和科学的思维方法。 比如，一只狗有4条腿，两只狗有8条腿，三只狗有多少条腿?像这些问题，就是属于抽象逻辑思维能力题。家长要注意让孩子学会独立思考，不要给孩子现成的答案。 那家长如何去培养孩子的逻辑思维能力呢？事实上，在日常与孩子相处的细节中，下面这三种方式，效果是最为明显的。一、丰富孩子的词汇，教孩子说话用词达意语言是思维的外壳，尽早教孩子准确用词，不但能防止别人曲解、误解他的意思，而且促使他思维活跃、思路清晰。家长对孩子的话要多问几个为什么，对他的表达要多作分析，这可以使孩子用词准确、鲜明、生动。 二、有意识地对孩子设疑，给孩子留下思考的时间孩子回答问题往往是凭直觉，如果家长满足于孩子的这点“小聪明”，那么，他们会习惯对问题不假思索地做出回答，没有足够的时间让大脑启动思维“程序”。 所以，当孩子遇到问题的时候，家长最好不要急于让他说答案，而是让他多问几个为什么，多想几种解决的方案，多几次对自己的否定，然后在否定中寻找最佳答案。 三、利用游戏促进孩子思维能力的发展在日常生活中，可以进行分类和归类的游戏。也可以进行比较动、植物或其他事物、训练理解力和创造力的游戏等。 比如收衣服时，让孩子将不同的袜子分类卷起来；去动物园时，告诉孩子如何通过牙齿区别食草和食肉的动物，并让他分辨；给孩子一些零钱，让孩子去买东西…… 对孩子而言，说过的话，玩过的游戏或许会忘记，但日复一日默默培养起来的逻辑思维能力会伴随他们终身，使他们在生活和工作中表现得更为优秀出色。]]></content>
      <categories>
        <category>育儿</category>
      </categories>
      <tags>
        <tag>育儿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 核心注解]]></title>
    <url>%2F2019%2F09%2F25%2FSpring-Boot-%E6%A0%B8%E5%BF%83%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[问题：我看你上面写了熟悉 Spring Boot，那你能讲下为什么我们要用 Spring Boot 吗？ 下面我列几个最常见的三个回答：A：Spring Boot 最主要是不用 XML 配置，可以用 Java 来配置 bean，省去了许多配置文件。我又问：Spring 本身就可以用 Java 配置代替 XML 配置，和 Spring Boot 有什么关系呢？ 然后对方就吱吱唔唔了…… B：Spring Boot 我们用来做 Spring Cloud 微服务。我又问：微服务和 Spring Boot 有什么关系？不用 Spring Boot 行不行？ 然后对方就吱吱唔唔了…… C：Spring Boot 可以打 jar 包部署，内部集成了Tomcat。这个确实是 Spring Boot 的特色，但是我还是觉得没有答到关键点上。 然后我继续问，如果不考虑打 jar 包部署呢，然后就没然后了…… 为什么我们要用 Spring Boot，显然上面三个求职者没有答到关键点上，Spring Boot 最重要的功能是：自动配置。为什么说是自动配置？Spring Boot 的开启注解是：@SpringBootApplication，其实它就是由下面三个注解组成的： @Configuration @ComponentScan @EnableAutoConfiguration上面三个注解，前面两个都是 Spring 自带的，和 Spring Boot 无关，所以说上面的回答的不是在点上。 所以说 Spring Boot 最最核心的就是这个 @EnableAutoConfiguration 注解了，它能根据类路径下的 jar 包和配置动态加载配置和注入bean。 举个例子，比如我在 lib 下放一个 druid 连接池的 jar 包，然后在 application.yml 文件配置 druid 相关的参数，Spring Boot 就能够自动配置所有我们需要的东西，如果我把 jar 包拿掉或者把参数去掉，那 Spring Boot 就不会自动配置。 这样我们就能把许多功能做成公共的自动配置的启动器（starters），其实 druid 连接池就是这么做的，它提供了针对 Spring Boot 的启动器：druid-spring-boot-starter。 有了这个自动配置的启动器，我们就能非常简单的使用它， 先添加 jar 包依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; 再添加相关参数： spring.datasource.url= spring.datasource.username= spring.datasource.password= ……如果是传统的项目，我们要自己手动写一大堆的配置，而且还不灵活，有了这个启动器，我们就可以做到简单集成。具体大家可以看 druid-spring-boot-starter 是怎么实现的。 所以，这才是 Spring Boot 的核心，这才是我们为什么使用 Spring Boot 的原因。如果答不到这个关键点，那真没有掌握到 Spring Boot 的核心所在。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javac原理]]></title>
    <url>%2F2019%2F09%2F25%2FJavac%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[从Sun Javac的代码来看，编译过程大致可以分为3个过程: 解析与填充符号表过程。 插入式注解处理器的注解处理过程。 分析与字节码生成过程。Javac编译动作的入口是com.sun.tools.javac.main.JavaCompiler类，上述3个过程的代码逻辑集中在这个类的compile()和compile2()方法中，整个编译最关键的处理就由图中标注的8个方法来完成，下面我们具体看一下这8个方法实现了什么功能。 解析与填充符号表解析步骤由上图中的parseFiles（）方法（过程1.1）完成，解析步骤包括了经典程序编译原理中的词法分析和语法分析两个过程。 词法、语法分析词法分析是将源代码的字符流转变为标记（Token）集合，单个字符是程序编写过程的最小元素，而标记则是编译过程的最小元素，关键字、变量名、字面量、运算符都可以成为标记，如“int a=b+2”这句代码包含了6个标记，分别是int、a、=、b、+、2，虽然关键字int由3个字符构成，但是它只是一个Token，不可再拆分。在Javac的源码中，词法分析过程由com.sun.tools.javac.parser.Scanner类来实现。 语法分析是根据Token序列构造抽象语法树的过程，抽象语法树（Abstract Syntax Tree,AST）是一种用来描述程序代码语法结构的树形表示方式，语法树的每一个节点都代表着程序代码中的一个语法结构（Construct），例如包、类型、修饰符、运算符、接口、返回值甚至代码注释等都可以是一个语法结构。 在Javac的源码中，语法分析过程由com.sun.tools.javac.parser.Parser类实现，这个阶段产出的抽象语法树由com.sun.tools.javac.tree.JCTree类表示，经过这个步骤之后，编译器就基本不会再对源码文件进行操作了，后续的操作都建立在抽象语法树之上。 填充符号表完成了语法分析和词法分析之后，下一步就是填充符号表的过程，也就是enterTrees（）方法（过程1.2）所做的事情。符号表（Symbol Table）是由一组符号地址和符号信息构成的表格，可以把它想象成哈希表中K-V值对的形式（实际上符号表不一定是哈希表实现，可以是有序符号表、树状符号表、栈结构符号表等）。符号表中所登记的信息在编译的不同阶段都要用到。在语义分析中，符号表所登记的内容将用于语义检查（如检查一个名字的使用和原先的说明是否一致）和产生中间代码。在目标代码生成阶段，当对符号名进行地址分配时，符号表是地址分配的依据。 在Javac源代码中，填充符号表的过程由com.sun.tools.javac.comp.Enter类实现，此过程的出口是一个待处理列表（To Do List），包含了每一个编译单元的抽象语法树的顶级节点，以及package-info.java（如果存在的话）的顶级节点。 注解处理器在Javac源码中，插入式注解处理器的初始化过程是在initPorcessAnnotations（）方法中完成的，而它的执行过程则是在processAnnotations（）方法中完成的，这个方法判断是否还有新的注解处理器需要执行，如果有的话，通过com.sun.tools.javac.processing.JavacProcessingEnvironment类的doProcessing（）方法生成一个新的JavaCompiler对象对编译的后续步骤进行处理。 在JDK 1.5之后，Java语言提供了对注解（Annotation）的支持，这些注解与普通的Java代码一样，是在运行期间发挥作用的。在JDK 1.6中实现了JSR-269规范JSR-269：Pluggable Annotations Processing API（插入式注解处理API）。提供了一组插入式注解处理器的标准API在编译期间对注解进行处理，我们可以把它看做是一组编译器的插件，在这些插件里面，可以读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行了修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次循环称为一个Round，也就是第一张图中的回环过程。 有了编译器注解处理的标准API后，我们的代码才有可能干涉编译器的行为，由于语法树中的任意元素，甚至包括代码注释都可以在插件之中访问到，所以通过插入式注解处理器实现的插件在功能上有很大的发挥空间。只要有足够的创意，程序员可以使用插入式注解处理器来实现许多原本只能在编码中完成的事情。 我们知道编译器在把Java程序源码编译为字节码的时候，会对Java程序源码做各方面的检查校验。这些校验主要以程序“写得对不对”为出发点，虽然也有各种WARNING的信息，但总体来讲还是较少去校验程序“写得好不好”。有鉴于此，业界出现了许多针对程序“写得好不好”的辅助校验工具，如CheckStyle、FindBug、Klocwork等。这些代码校验工具有一些是基于Java的源码进行校验，还有一些是通过扫描字节码来完成。我们将会使用注解处理器API来编写一款拥有自己编码风格的校验工具：NameCheckProcessor。 代码实现要通过注解处理器API实现一个编译器插件，首先需要了解这组API的一些基本知识。我们实现注解处理器的代码需要继承抽象类javax.annotation.processing.AbstractProcessor，这个抽象类中只有一个必须覆盖的abstract方法：“process（）”，它是Javac编译器在执行注解处理器代码时要调用的过程，我们可以从这个方法的第一个参数“annotations”中获取到此注解处理器所要处理的注解集合，从第二个参数“roundEnv”中访问到当前这个Round中的语法树节点，每个语法树节点在这里表示为一个Element。在JDK 1.6新增的javax.lang.model包中定义了16类Element，包括了Java代码中最常用的元素，如：“包（PACKAGE）、枚举（ENUM）、类（CLASS）、注解（ANNOTATION_TYPE）、接口（INTERFACE）、枚举值（ENUM_CONSTANT）、字段（FIELD）、参数（PARAMETER）、本地变量（LOCAL_VARIABLE）、异常（EXCEPTION_PARAMETER）、方法（METHOD）、构造函数（CONSTRUCTOR）、静态语句块（STATIC_INIT，即static{}块）、实例语句块（INSTANCE_INIT，即{}块）、参数化类型（TYPE_PARAMETER，既泛型尖括号内的类型）和未定义的其他语法树节点（OTHER）”。除了process（）方法的传入参数之外，还有一个很常用的实例变量“processingEnv”，它是AbstractProcessor中的一个protected变量，在注解处理器初始化的时候（init（）方法执行的时候）创建，继承了AbstractProcessor的注解处理器代码可以直接访问到它。它代表了注解处理器框架提供的一个上下文环境，要创建新的代码、向编译器输出信息、获取其他工具类等都需要用到这个实例变量。注解处理器除了process（）方法及其参数之外，还有两个可以配合使用的Annotations：@SupportedAnnotationTypes和@SupportedSourceVersion，前者代表了这个注解处理器对哪些注解感兴趣，可以使用星号“*”作为通配符代表对所有的注解都感兴趣，后者指出这个注解处理器可以处理哪些版本的Java代码。 每一个注解处理器在运行的时候都是单例的，如果不需要改变或生成语法树的内容，process（）方法就可以返回一个值为false的布尔值，通知编译器这个Round中的代码未发生变化，无须构造新的JavaCompiler实例，在这次实战的注解处理器中只对程序命名进行检查，不需要改变语法树的内容，因此process（）方法的返回值都是false。 import javax.annotation.processing.*; import javax.lang.model.SourceVersion; import javax.lang.model.element.Element; import javax.lang.model.element.TypeElement; import java.util.Set; //可以用&quot;*&quot;表示支持所有Annotations @SupportedAnnotationTypes(&quot;*&quot;) //只支持JDK 1.6的Java代码 @SupportedSourceVersion(SourceVersion.RELEASE_6) public class NameCheckProcessor extends AbstractProcessor { private NameChecker nameChecker; /** * 初始化名称检查插件 */ @Override public void init(ProcessingEnvironment processingEnv){ super.init(processingEnv); nameChecker = new NameChecker(processingEnv); } /** * 对输入的语法树的各个节点进行名称检查 */ @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations,RoundEnvironment roundEnv){ if (!roundEnv.processingOver()) { for (Element element:roundEnv.getRootElements()) nameChecker.checkNames(element); } return false; } } import javax.annotation.processing.Messager; import javax.annotation.processing.ProcessingEnvironment; import javax.lang.model.element.*; import javax.lang.model.util.ElementScanner6; import javax.tools.Diagnostic; import java.util.EnumSet; public class NameChecker { private final Messager messager; NameCheckScanner nameCheckScanner = new NameCheckScanner(); NameChecker(ProcessingEnvironment processsingEnv) { this.messager = processsingEnv.getMessager(); } /** * 对Java程序命名进行检查,根据《Java语言规范(第3版)》第6.8节的要求,Java程序命名应当符合下列格式： * &lt;p/&gt; * &lt;ul&gt; * &lt;li&gt;类或接口：符合驼式命名法,首字母大写。 * &lt;li&gt;方法：符合驼式命名法,首字母小写。 * &lt;li&gt;字段： * &lt;ul&gt; * &lt;li&gt;类、实例变量：符合驼式命名法,首字母小写。 * &lt;li&gt;常量：要求全部大写。 * &lt;/ul&gt; * &lt;/ul&gt; */ public void checkNames(Element element) { nameCheckScanner.scan(element); } /** * 名称检查器实现类,继承了JDK 1.6中新提供的ElementScanner6&lt;br&gt; * 将会以Visitor模式访问抽象语法树中的元素 */ private class NameCheckScanner extends ElementScanner6&lt;Void, Void&gt; { /** * 此方法用于检查Java类 */ @Override public Void visitType(TypeElement e, Void p) { scan(e.getTypeParameters(), p); checkCamelCase(e, true); super.visitType(e, p); return null; } /** * 检查方法命名是否合法 */ @Override public Void visitExecutable(ExecutableElement e, Void p) { if (e.getKind() == ElementKind.METHOD) { Name name = e.getSimpleName(); if (name.contentEquals(e.getEnclosingElement().getSimpleName())) messager.printMessage(Diagnostic.Kind.WARNING, &quot;一个普通方法&apos;&quot; + name + &quot;&apos;不应当与类名重复,避免与构造函数产生混淆&quot;, e); checkCamelCase(e, false); } super.visitExecutable(e, p); return null; } /** * 检查变量命名是否合法 */ @Override public Void visitVariable(VariableElement e, Void p) { //如果这个Variable是枚举或常量,则按大写命名检查,否则按照驼式命名法规则检查 if (e.getKind() == ElementKind.ENUM_CONSTANT || e.getConstantValue() != null || heuristicallyConstant(e)) checkAllCaps(e); else checkCamelCase(e, false); return null; } /** * 判断一个变量是否是常量 */ private boolean heuristicallyConstant(VariableElement e) { if (e.getEnclosingElement().getKind() == ElementKind.INTERFACE) return true; else if (e.getKind() == ElementKind.FIELD &amp;&amp; e.getModifiers().containsAll(EnumSet.of(Modifier.PUBLIC, Modifier.STATIC, Modifier.FINAL))) return true; else { return false; } } /** * 检查传入的Element是否符合驼式命名法,如果不符合,则输出警告信息 */ private void checkCamelCase(Element e, boolean initialCaps) { String name = e.getSimpleName().toString(); boolean previousUpper = false; boolean conventional = true; int firstCodePoint = name.codePointAt(0); if (Character.isUpperCase(firstCodePoint)) { previousUpper = true; if (!initialCaps) { messager.printMessage(Diagnostic.Kind.WARNING, &quot;名称&apos;&quot; + name + &quot;&apos;应当以小写字母开头&quot;, e); return; } } else if (Character.isLowerCase(firstCodePoint)) { if (initialCaps) { messager.printMessage(Diagnostic.Kind.WARNING, &quot;名称&apos;&quot; + name + &quot;&apos;应当以大写字母开头&quot;, e); return; } } else conventional = false; if (conventional) { int cp = firstCodePoint; for (int i = Character.charCount(cp); i &lt; name.length(); i += Character.charCount(cp)) { cp = name.codePointAt(i); if (Character.isUpperCase(cp)) { if (previousUpper) { conventional = false; break; } previousUpper = true; } else previousUpper = false; } } if (!conventional) messager.printMessage(Diagnostic.Kind.WARNING, &quot;名称&apos;&quot; + name + &quot;&apos;应当符合驼式命名法(Camel Case Names)&quot;, e); } /** * 大写命名检查,要求第一个字母必须是大写的英文字母,其余部分可以是下划线或大写字母 */ private void checkAllCaps(Element e) { String name = e.getSimpleName().toString(); boolean conventional = true; int firstCodePoint = name.codePointAt(0); if (!Character.isUpperCase(firstCodePoint)) conventional = false; else { boolean previousUnderscore = false; int cp = firstCodePoint; for (int i = Character.charCount(cp); i &lt; name.length(); i += Character.charCount(cp)) { cp = name.codePointAt(i); if (cp == (int) &apos;_&apos;) { if (previousUnderscore) { conventional = false; break; } previousUnderscore = true; } else { previousUnderscore = false; if (!Character.isUpperCase(cp) &amp;&amp; !Character.isDigit(cp)) { conventional = false; break; } } } } if (!conventional) messager.printMessage(Diagnostic.Kind.WARNING, &quot;常量&apos;&quot; + name + &quot;&apos;应当全部以大写字母或下划线命名,并且以字母开头&quot;, e); } } }我们可以通过Javac命令的“-processor”参数来执行编译时需要附带的注解处理器，如果有多个注解处理器的话，用逗号分隔。还可以使用-XprintRounds和-XprintProcessorInfo参数来查看注解处理器运作的详细信息，javac -processor *.NameCheckProcessor */test.java test.java：3：警告：名称&quot;test&quot;应当符合驼式命名法（Camel Case Names） public class test{ ^ test.java：5：警告：名称&quot;colors&quot;应当以大写字母开头 enum colors{ ^ test.java：6：警告：常量&quot;red&quot;应当全部以大写字母或下划线命名，并且以字母开头 red,blue,green； ^ test.java：6：警告：常量&quot;blue&quot;应当全部以大写字母或下划线命名，并且以字母开头 red,blue,green； ^ test.java：6：警告：常量&quot;green&quot;应当全部以大写字母或下划线命名，并且以字母开头 red,blue,green； ^ test.java：9：警告：常量&quot;_FORTY_TWO&quot;应当全部以大写字母或下划线命名，并且以字母开头 static final int_FORTY_TWO=42； ^ test.java：11：警告：名称&quot;NOT_A_CONSTANT&quot;应当以小写字母开头 public static int NOT_A_CONSTANT=_FORTY_TWO； ^ test.java：13：警告：名称&quot;Test&quot;应当以小写字母开头 protected void Test（）{ ^ test.java：17：警告：名称&quot;NOTcamelCASEmethodNAME&quot;应当以小写字母开头 public void NOTcamelCASEmethodNAME（）{ ^NameCheckProcessor的例子只演示了JSR-269嵌入式注解处理器API中的一部分功能，基于这组API支持的项目还有用于校验Hibernate标签使用正确性的Hibernate Validator Annotation Processorm自动为字段生成getter和setter方法的Project Lombok. 语义分析语法分析之后，编译器获得了程序代码的抽象语法树表示，语法树能表示一个结构正确的源程序的抽象，但无法保证源程序是符合逻辑的。而语义分析的主要任务是对结构上正确的源程序进行上下文有关性质的审查，如进行类型审查。Javac的编译过程中，语义分析过程分为标注检查以及数据及控制流分析两个步骤，分别由上图中所示的attribute（）和flow（）方法（分别对应过程3.1和过程3.2）完成。 标注检查标注检查步骤检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配等。在标注检查步骤中，还有一个重要的动作称为常量折叠，如果我们在代码中写了如下定义：int a=1+2；那么在语法树上仍然能看到字面量“1”、“2”以及操作符“+”，但是在经过常量折叠之后，它们将会被折叠为字面量“3”，由于编译期间进行了常量折叠，所以在代码里面定义“a=1+2”比起直接定义“a=3”，并不会增加程序运行期哪怕仅仅一个CPU指令的运算量。 数据及控制流分析在Javac的源码中，数据及控制流分析的入口是图中的flow（）方法（对应过程3.2），具体操作由com.sun.tools.javac.comp.Flow类来完成。 数据及控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。编译时期的数据及控制流分析与类加载时的数据及控制流分析的目的基本上是一致的，但校验范围有所区别，有一些校验项只有在编译期或运行期才能进行。 //方法一带有final修饰 public void foo（final int arg）{ final int var=0； //do something } //方法二没有final修饰 public void foo（int arg）{ int var=0； //do something }在这两个foo（）方法中，第一种方法的参数和局部变量定义使用了final修饰符，而第二种方法则没有，在代码编写时程序肯定会受到final修饰符的影响，不能再改变arg和var变量的值，但是这两段代码编译出来的Class文件是没有任何一点区别的，局部变量与字段（实例变量、类变量）是有区别的，它在常量池中没有CONSTANT_Fieldref_info的符号引用，自然就没有访问标志（Access_Flags）的信息，甚至可能连名称都不会保留下来（取决于编译时的选项），自然在Class文件中不可能知道一个局部变量是不是声明为final了。因此，将局部变量声明为final，对运行期是没有影响的，变量的不变性仅仅由编译器在编译期间保障。 解语法糖在Javac的源码中，解语法糖的过程由desugar（）方法触发，在com.sun.tools.javac.comp.TransTypes类和com.sun.tools.javac.comp.Lower类中完成。 语法糖（Syntactic Sugar），也称糖衣语法，指在计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。通常来说，使用语法糖能够增加程序的可读性，从而减少程序代码出错的机会。 Java中最常用的语法糖主要是的泛型擦除（泛型并不一定都是语法糖实现，如C#的泛型就是直接由CLR支持的）、变长参数、自动装箱/拆箱,条件编译等，虚拟机运行时不支持这些语法，它们在编译阶段还原回简单的基础语法结构，这个过程称为解语法糖。 字节码生成字节码生成是Javac编译过程的最后一个阶段，在Javac源码里面由com.sun.tools.javac.jvm.Gen类来完成。字节码生成阶段不仅仅是把前面各个步骤所生成的信息（语法树、符号表）转化成字节码写到磁盘中，编译器还进行了少量的代码添加和转换工作。 例如，实例构造器＜init＞（）方法和类构造器＜clinit＞（）方法就是在这个阶段添加到语法树之中的（注意，这里的实例构造器并不是指默认构造函数，如果用户代码中没有提供任何构造函数，那编译器将会添加一个没有参数的、访问性（public、protected或private）与当前类一致的默认构造函数，这个工作在填充符号表阶段就已经完成），这两个构造器的产生过程实际上是一个代码收敛的过程，编译器会把语句块（对于实例构造器而言是“{}”块，对于类构造器而言是“static{}”块）、变量初始化（实例变量和类变量）、调用父类的实例构造器等操作收敛到＜init＞（）和＜clinit＞（）方法之中，并且保证一定是按先执行父类的实例构造器，然后初始化变量，最后执行语句块的顺序进行，上面所述的动作由Gen.normalizeDefs（）方法来实现。除了生成构造器以外，还有其他的一些代码替换工作用于优化程序的实现逻辑，如把字符串的加操作替换为StringBuffer或StringBuilder的append（）操作等。 完成了对语法树的遍历和调整之后，就会把填充了所有所需信息的符号表交给com.sun.tools.javac.jvm.ClassWriter类，由这个类的writeClass（）方法输出字节码，生成最终的Class文件，到此为止整个编译过程宣告结束。 摘自]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 lombok 简化 Java 代码]]></title>
    <url>%2F2019%2F09%2F25%2F%E4%BD%BF%E7%94%A8-lombok-%E7%AE%80%E5%8C%96-Java-%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[一个典型的 Java 类public class A { private int a; private String b; public int getA() { return a; } public String getB() { return b; } public void setA(int a) { this.a = a; } public void setB(String b) { this.b = b; } }对于这样一个简单的 Java 类，我们通常需要给每个属性写getter和setter，而这种实际上没有什么太大的意义。当然，如果有的公司或团队使用代码行数评估工作量，还是多写几行吧；同时，可以考虑一下我们团队。 使用 lombok，简化代码为了简化getter与setter，lombok 提供了一种机制，帮助我们自动生成这些样板代码。以上的代码，如果使用lombok的话，将变得很简单： @lombok.Getter @lombok.Setter public class A { private int a; private String b; }顾名思义，lombok.Getter就是生成getter，lombok.Setter就是生成setter。但是，这样真的就可以了么？编译下，让我们看看生成的二进制代码。(请自行下载lombok.jar) 命令行&gt; javac -cp lombok.jar A.java 命令行&gt; javap -c A.class输出结果略。可以看到完全一样。 更进一步，如果在编译的时候，加入-g:none选项，甚至可以看到生成的文件完全一样。 简单使用虽然我们可以在编译的时候，加入classpath，但是，一般来说，在各类IDE中使用，还是需要特殊处理一下。 Maven加上依赖就好。同时，由于lombok只在编译期才处理，所以并不需要在运行时有这个依赖，可以把scope定义为provided。 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.8&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;值得注意的是，maven的maven-compiler-plugin低版本和lombok高版本不兼容，目前已知maven-compiler-plugin的2.3.X与lombok的1.6.X不兼容。这个需要了解lombok的原理才能进一步说明。 Eclipse由于eclipse的默认编译器并不是javac，所以，需要额外安装，基本就是改下引导参数，可以直接运行jar包，或者手动在eclipse.ini里加上参数-Xbootclasspath/a:lombok.jar -javaagent:lombok.jar。 IDEA IntelliJ虽然IDEA IntelliJ默认使用javac作为编译器，理论上可以不装插件。可是，跳转等特性也随之没了。所以，还是安装个插件吧，直接去仓库里搜索lombok就成。 如果项目中使用高级配置，需要额外注意一下。虽然在编译的时候，lombok配置文件可以在任何能找到的目录，但是，lombok-intellij插件默认并不支持在任何目录，如果有配置文件，建议放在java的源代码根目录中。 更多 lombok 注解 注解 解释 @val 如果你要定义一个final的变量，并且不想写类型，这个可以帮到你。但是，在实际项目中，完全没有使用到。 @NonNull 这个在参数中使用，如果调用时传了null，就直接抛空指针。 @Data @ToString、@EqualsAndHashCode、@Getter、@Setter和@RequiredArgsConstructor注解的集合。 @Getter与@Setter 作用于属性和类上，自动生成属性的getXXX()和setXXX()方法。若在类上，则对所有属性有效。并可通过AccessLevel参数控制方法的访问级别。 @ToString 作用于类，自动重写类的ToString()方法。常用的参数有exclude（指定方法中不包含的属性）、callSuper（方法中是否包含父类ToString()方法返回的值） @EqualsAndHashCode 作用于类，自动重写类的equals()、hashCode()方法。常用的参数有exclude（指定方法中不包含的属性）、callSuper（方法中是否包含父类ToString()方法返回的值） @NoArgsConstructor, @RequiredArgsConstructor和@AllArgsConstructor 作用于类，@NoArgsConstructor自动生成不带参数的构造方法；@RequiredArgsConstructor自动生成带参数的构造方法，主要针对一些需要特殊处理的属性，比如未初始化的final属性；@AllArgsConstructor自动生成包含所有属性的构造方法。 @Synchronized 作用于方法，可锁定指定的对象，如果不指定，则默认创建创建一个对象锁定。 @Log，或者直接@Slf4j 作用于类，具体包含@CommonsLog、@Log、@Log4j、@Log4j2、@Slf4j和@XSlf4j，分别对用不同的日志系统。利用此类注解，可为类创建一个log属性。 sonar源码审查sonar是一个源码审查工具。最新版5.X已经支持lombok的全部注解，不再认为是没有使用的变量。但是，旧的4.X还是认为没有使用这些变量。可以后向移植这些包，或者应用单独的补丁。 摘自 sonar]]></content>
      <categories>
        <category>Lombok</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之Builder模式]]></title>
    <url>%2F2019%2F09%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BBuilder%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL创建用户与授权]]></title>
    <url>%2F2019%2F09%2F12%2FMySQL%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E4%B8%8E%E6%8E%88%E6%9D%83%2F</url>
    <content type="text"><![CDATA[一. 创建用户命令CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;;说明： username：你将创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符% password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 例子：CREATE USER &apos;dog&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;; CREATE USER &apos;pig&apos;@&apos;192.168.1.101_&apos; IDENDIFIED BY &apos;123456&apos;; CREATE USER &apos;pig&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; CREATE USER &apos;pig&apos;@&apos;%&apos; IDENTIFIED BY &apos;&apos;; CREATE USER &apos;pig&apos;@&apos;%&apos;;二. 授权:命令:GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos;说明: privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如.* 例子:GRANT SELECT, INSERT ON test.user TO &apos;pig&apos;@&apos;%&apos;; GRANT ALL ON *.* TO &apos;pig&apos;@&apos;%&apos;;注意:用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令: GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos; WITH GRANT OPTION;三.设置与更改用户密码 命令: SET PASSWORD FOR &apos;username&apos;@&apos;host&apos; = PASSWORD(&apos;newpassword&apos;); 如果是当前登陆用户用: SET PASSWORD = PASSWORD(&quot;newpassword&quot;);例子: SET PASSWORD FOR &apos;pig&apos;@&apos;%&apos; = PASSWORD(&quot;123456&quot;);四. 撤销用户权限命令: REVOKE privilege ON databasename.tablename FROM &apos;username&apos;@&apos;host&apos;;说明:privilege, databasename, tablename：同授权部分 例子: REVOKE SELECT ON *.* FROM &apos;pig&apos;@&apos;%&apos;;注意: 假如你在给用户‘pig’@’%’授权的时候是这样的（或类似的）：GRANT SELECT ON test.user TO ‘pig’@’%’，则在使用REVOKE SELECT ON . FROM ‘pig’@’%’;命令并不能撤销该用户对test数据库中user表的SELECT 操作。相反，如果授权使用的是GRANT SELECT ON . TO ‘pig’@’%’;则REVOKE SELECT ON test.user FROM ‘pig’@’%’;命令也不能撤销该用户对test数据库中user表的Select权限。 具体信息可以用命令SHOW GRANTS FOR ‘pig’@’%’; 查看。 五.删除用户DROP USER &apos;username&apos;@&apos;host&apos;;摘抄自]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok 看这篇就够了]]></title>
    <url>%2F2019%2F09%2F12%2FLombok-%E7%9C%8B%E8%BF%99%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86%2F</url>
    <content type="text"><![CDATA[what官网官网解释: Project Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again, with one annotation your class has a fully featured builder, Automate your logging variables, and much more. why减少代码量,省去写geter,setter等 when添加下依赖:&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.8&lt;/version&gt; &lt;/dependency&gt;那么Lombok是做什么的呢？其实很简单，一个最简单的例子就是它能够实现通过添加注解，能够自动生成一些方法。比如这样的类: @Getter class Test{ private String value; }我们用Lombok提供的@Getter来注解这个类，这个类在编译的时候就会变成: class Test{ private String value; public String getValue(){ return this.value; } }当然Lombok也提供了很多其他的注解，这只是其中一个最典型的例子。其他的用法网上的资料已经很多了，这里就不啰嗦。看上去是很方便的一个功能，尤其是在很多项目里有很多bean，每次都要手写或自动生成setter getter方法，搞得代码很长而且没有啥意义，因此这个对简化代码的强迫症们还是很有吸引力的。但是，我们发现这个包跟一般的包有很大区别，绝大多数java包都工作在运行时，比如spring提供的那种注解，通过在运行时用反射来实现业务逻辑。Lombok这个东西工作却在编译期，在运行时是无法通过反射获取到这个注解的。而且由于他相当于是在编译期对代码进行了修改，因此从直观上看，源代码甚至是语法有问题的。一个更直接的体现就是，普通的包在引用之后一般的IDE都能够自动识别语法，但是Lombok的这些注解，一般的IDE都无法自动识别，比如我们上面的Test类，如果我们在其他地方这么调用了一下: Test test=new Test(); test.getValue();IDE的自动语法检查就会报错，说找不到这个getValue方法。因此如果要使用Lombok的话还需要配合安装相应的插件，防止IDE的自动检查报错。因此，可以说这个东西的设计初衷比较美好，但是用起来比较麻烦，而且破坏了代码的完整性，很多项目组(包括我自己)都不高兴用。但是他的实现原理却还是比较好玩的，随便搜了搜发现网上最多也只提到了他修改了抽象语法树，虽说从感性上可以理解，但是还是想自己手敲一敲真正去实现一下。 原理翻了翻现有的资料，再加上自己的一些猜想，Lombok的基本流程应该基本是这样： 定义编译期的注解 利用JSR269 api(Pluggable Annotation Processing API )创建编译期的注解处理器 利用tools.jar的javac api处理AST(抽象语法树) 将功能注册进jar包 手撸Getter由于比较习惯用maven，我这里就用maven构建一下项目，修改下当前的pom.xml文件如下： &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mythsman.test&lt;/groupId&gt; &lt;artifactId&gt;getter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;test&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun&lt;/groupId&gt; &lt;artifactId&gt;tools&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${java.home}/../lib/tools.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;主要定义了下项目名，除了默认依赖的junit之外(其实并没有用)，这里添加了tools.jar包。这个包实在jdk的lib下面，因此scope是system，由于${java.home}变量表示的是jre的位置，因此还要根据这个位置找到实际的tools.jar的路径并写在systemPath里。由于防止在写代码的时候用到java8的一些语法，这里配置了下编译插件使其支持java8。 创建Getter注解定义注解Getter.java: package com.mythsman.test; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target({ElementType.TYPE}) @Retention(RetentionPolicy.SOURCE) public @interface Getter { }这里的Target我选择了ElementType.TYPE表示是对类的注解，Retention选择了RententionPolicy.SOURCE，表示这个注解只在编译期起作用，在运行时将不存在。这个比较简单，稍微复杂点的是对这个注解的处理机制。像spring那种注解是通过反射来获得注解对应的元素并实现业务逻辑，但是我们显然不希望在使用Lombok这种功能的时候还要编写其他的调用代码，况且用反射也获取不到编译期才存在的注解。幸运的是Java早已支持了JSR269的规范，允许在编译时指定一个processor类来对编译阶段的注解进行干预，下面就来解决下这个处理器。 创建Getter注解的处理器基本框架 自定义的处理器需要继承AbstractProcessor这个类，基本的框架大体应当如下: package com.mythsman.test; import javax.annotation.processing.*; import javax.lang.model.SourceVersion; import javax.lang.model.element.TypeElement; import java.util.Set; @SupportedAnnotationTypes(&quot;com.mythsman.test.Getter&quot;) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class GetterProcessor extends AbstractProcessor { @Override public synchronized void init(ProcessingEnvironment processingEnv) { super.init(processingEnv); } @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) { return true; } }需要定义两个注解，一个表示该处理器需要处理的注解，另外一个表示该处理器支持的源码版本。然后需要着重实现两个方法，init跟process。init的主要用途是通过ProcessingEnvironment来获取编译阶段的一些环境信息;process主要是实现具体逻辑的地方，也就是对AST进行处理的地方。 具体怎么做呢？ init方法首先我们要重写下init方法，从环境里提取一些关键的类: private Messager messager; private JavacTrees trees; private TreeMaker treeMaker; private Names names; @Override public synchronized void init(ProcessingEnvironment processingEnv) { super.init(processingEnv); this.messager = processingEnv.getMessager(); this.trees = JavacTrees.instance(processingEnv); Context context = ((JavacProcessingEnvironment) processingEnv).getContext(); this.treeMaker = TreeMaker.instance(context); this.names = Names.instance(context); }我们提取了四个主要的类: Messager主要是用来在编译期打log用的 JavacTrees提供了待处理的抽象语法树 TreeMaker封装了创建AST节点的一些方法 Names提供了创建标识符的方法 process方法process方法的逻辑比较简单，但是由于这里的api对于我们来说比较陌生，因此写起来还是费了不少劲的： @Override public synchronized boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) { Set&lt;? extends Element&gt; set = roundEnv.getElementsAnnotatedWith(Getter.class); set.forEach(element -&gt; { JCTree jcTree = trees.getTree(element); jcTree.accept(new TreeTranslator() { @Override public void visitClassDef(JCTree.JCClassDecl jcClassDecl) { List&lt;JCTree.JCVariableDecl&gt; jcVariableDeclList = List.nil(); for (JCTree tree : jcClassDecl.defs) { if (tree.getKind().equals(Tree.Kind.VARIABLE)) { JCTree.JCVariableDecl jcVariableDecl = (JCTree.JCVariableDecl) tree; jcVariableDeclList = jcVariableDeclList.append(jcVariableDecl); } } jcVariableDeclList.forEach(jcVariableDecl -&gt; { messager.printMessage(Diagnostic.Kind.NOTE, jcVariableDecl.getName() + &quot; has been processed&quot;); jcClassDecl.defs = jcClassDecl.defs.prepend(makeGetterMethodDecl(jcVariableDecl)); }); super.visitClassDef(jcClassDecl); } }); }); return true; }步骤大概是下面这样： 利用roundEnv的getElementsAnnotatedWith方法过滤出被Getter这个注解标记的类，并存入set 遍历这个set里的每一个元素，并生成jCTree这个语法树 创建一个TreeTranslator，并重写其中的visitClassDef方法，这个方法处理遍历语法树得到的类定义部分jcClassDecl 创建一个jcVariableDeclList保存类的成员变量 遍历jcTree的所有成员(包括成员变量和成员函数和构造函数)，过滤出其中的成员变量，并添加进jcVariableDeclList 将jcVariableDeclList的所有变量转换成需要添加的getter方法，并添加进jcClassDecl的成员中 调用默认的遍历方法遍历处理后的jcClassDecl 利用上面的TreeTranslator去处理jcTree 接下来再实现makeGetterMethodDecl方法: private JCTree.JCMethodDecl makeGetterMethodDecl(JCTree.JCVariableDecl jcVariableDecl) { ListBuffer&lt;JCTree.JCStatement&gt; statements = new ListBuffer&lt;&gt;(); statements.append(treeMaker.Return(treeMaker.Select(treeMaker.Ident(names.fromString(&quot;this&quot;)), jcVariableDecl.getName()))); JCTree.JCBlock body = treeMaker.Block(0, statements.toList()); return treeMaker.MethodDef(treeMaker.Modifiers(Flags.PUBLIC), getNewMethodName(jcVariableDecl.getName()), jcVariableDecl.vartype, List.nil(), List.nil(), List.nil(), body, null); } private Name getNewMethodName(Name name) { String s = name.toString(); return names.fromString(&quot;get&quot; + s.substring(0, 1).toUpperCase() + s.substring(1, name.length())); }逻辑就是读取变量的定义，并创建对应的Getter方法，并试图用驼峰命名法。 整体上难点还是集中在api的使用上，还有一些细微的注意点:首先，messager的printMessage方法在打印log的时候会自动过滤重复的log信息。其次，这里的list并不是java.util里面的list，而是一个自定义的list，这个list的用法比较坑爹，他采用的是这样的方式: package com.sun.tools.javac.util; public class List&lt;A&gt; extends AbstractCollection&lt;A&gt; implements java.util.List&lt;A&gt; { public A head; public List&lt;A&gt; tail; //... List(A var1, List&lt;A&gt; var2) { this.tail = var2; this.head = var1; } public List&lt;A&gt; prepend(A var1) { return new List(var1, this); } public static &lt;A&gt; List&lt;A&gt; of(A var0) { return new List(var0, nil()); } public List&lt;A&gt; append(A var1) { return of(var1).prependList(this); } public static &lt;A&gt; List&lt;A&gt; nil() { return EMPTY_LIST; } //... }挺有趣的，用这种叫cons而不是list的数据结构，添加元素的时候就把自己赋给自己的tail,新来的元素放进head。不过需要注意的是这个东西不支持链式调用，prepend之后还要将新值赋给自己。而且这里在创建getter方法的时候还要把参数写全写对了，尤其是添加this指针的这种用法。 测试类上面基本就是所有功能代码了，接下来我们要写一个类来测试一下(App.java)： package com.mythsman.test; @Getter public class App { private String value; private String value2; public App(String value) { this.value = value; } public static void main(String[] args) { App app = new App(&quot;it works&quot;); System.out.println(app.getValue()); } }不过，先不要急着构建，构建了肯定会失败，因为这原则上应该是两个项目。Getter.java是注解类没问题，但是GetterProcessor.java是处理器，App.java需要在编译期调用这个处理器，因此这两个东西是不能一起编译的，正确的编译方法应该是类似下面这样，写成compile.sh脚本就是： #!/usr/bin/env bash if [ -d classes ]; then rm -rf classes; fi mkdir classes javac -cp $JAVA_HOME/lib/tools.jar com/mythsman/test/Getter* -d classes/ javac -cp classes -d classes -processor com.mythsman.test.GetterProcessor com/mythsman/test/App.java javap -p classes com/mythsman/test/App.class java -cp classes com.mythsman.test.App其实是五个步骤: 创建保存class文件的文件夹 导入tools.jar，编译processor并输出 编译App.java，并使用javac的-processor参数指定编译阶段的处理器GetterProcessor 用javap显示编译后的App.class文件(非必须，方便看结果) 执行测试类 好了，进入项目的根目录，当前的目录结构应该是这样的: .├── pom.xml├── src│ ├── main│ │ ├── java│ │ │ ├── com│ │ │ │ └── mythsman│ │ │ │ └── test│ │ │ │ ├── App.java│ │ │ │ ├── Getter.java│ │ │ │ └── GetterProcessor.java│ │ │ └── compile.sh 调用compile.sh，输出如下: Note: value has been processed Note: value2 has been processed Compiled from &quot;App.java&quot; public class com.mythsman.test.App { private java.lang.String value; private java.lang.String value2; public java.lang.String getValue2(); public java.lang.String getValue(); public com.mythsman.test.App(java.lang.String); public static void main(java.lang.String[]); } it worksNote行就是在GetterProcessor类里通过messager打印的log，中间的是javap反编译的结果，最后一行表示测试调用成功。 Maven构建并打包上面的测试部分其实是为了测试而测试，其实这应当是两个项目，一个是processor项目，这个项目应当被打成一个jar包，供调用者使用；另一个项目是app项目，这个项目是专门使用jar包的，他并不希望添加任何额外编译参数，就跟lombok的用法一样。简单来说，就是我们希望把processor打成一个包，并且在使用时不需要添加额外参数。那么如何在调用的时候不用加参数呢，其实我们知道java在编译的时候会去资源文件夹下读一个META-INF文件夹，这个文件夹下面除了MANIFEST.MF文件之外，还可以添加一个services文件夹，我们可以在这个文件夹下创建一个文件，文件名是javax.annotation.processing.Processor，文件内容是com.mythsman.test.GetterProcessor。我们知道maven在编译前会先拷贝资源文件夹，然后当他在编译时候发现了资源文件夹下的META-INF/serivces文件夹时，他就会读取里面的文件，并将文件名所代表的接口用文件内容表示的类来实现。这就相当于做了-processor参数该做的事了。当然这个文件我们并不希望调用者去写，而是希望在processor项目里集成，调用的时候能直接继承META-INF。 好了，我们先删除App.java和compile.sh，添加下META-INF文件夹，当前目录结构应该是这样的： .├── pom.xml├── src│ └── main│ ├── java│ │ └── com│ │ └── mythsman│ │ └── test│ │ ├── Getter.java│ │ └── GetterProcessor.java│ └── resources│ └── META-INF│ └── services│ └── javax.annotation.processing.Processor 当然，我们还不能编译，因为processor项目并不需要把自己添加为processor(况且自己还没编译呢怎么调用自己)。。。完了，好像死循环了，自己在编译的时候不能添加services文件夹，但是又需要打的包里有services文件夹，这该怎么搞呢？其实很简单，配置一下maven的插件就行，打开pom.xml,在project/build/标签里添加下面的配置: &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/**/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;process-META&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;target/classes&lt;/outputDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;${basedir}/src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ... &lt;/plugins&gt; &lt;/build&gt;我们知道maven构建的第一步就是调用maven-resources-plugin插件的resources命令，将resources文件夹复制到target/classes中，那么我们配置一下resources标签，过滤掉META-INF文件夹，这样在编译的时候就不会找到services的配置了。然后我们在打包前(prepare-package生命周期)再利用maven-resources-plugin插件的copy-resources命令把services文件夹重新拷贝过来不就好了么。这样配置好了，就可以直接执行mvn clean install打包提交到本地私服: myths@pc:~/Desktop/test$ mvn clean install [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building test 1.0-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ getter --- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ getter --- [INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources. [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ getter --- [INFO] Changes detected - recompiling the module! [INFO] Compiling 2 source files to /home/myths/Desktop/test/target/classes [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ getter --- [INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources. [INFO] skip non existing resourceDirectory /home/myths/Desktop/test/src/test/resources [INFO] [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ getter --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ getter --- [INFO] No tests to run. [INFO] [INFO] --- maven-resources-plugin:2.6:copy-resources (process-META) @ getter --- [INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources. [INFO] Copying 1 resource [INFO] [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ getter --- [INFO] Building jar: /home/myths/Desktop/test/target/getter-1.0-SNAPSHOT.jar [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ getter --- [INFO] Installing /home/myths/Desktop/test/target/getter-1.0-SNAPSHOT.jar to /home/myths/.m2/repository/com/mythsman/test/getter/1.0-SNAPSHOT/getter-1.0-SNAPSHOT.jar [INFO] Installing /home/myths/Desktop/test/pom.xml to /home/myths/.m2/repository/com/mythsman/test/getter/1.0-SNAPSHOT/getter-1.0-SNAPSHOT.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 3.017 s [INFO] Finished at: 2017-12-19T19:57:04+08:00 [INFO] Final Memory: 16M/201M [INFO] ------------------------------------------------------------------------可以看到这里的process-META作用生效。 调用jar包测试 重新创建一个测试项目app： .├── pom.xml└── src └── main └── java └── com └── mythsman └── test └── App.java pom.xml: &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mythsman.test&lt;/groupId&gt; &lt;artifactId&gt;app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;main&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.mythsman.test&lt;/groupId&gt; &lt;artifactId&gt;getter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;App.java: package com.mythsman.test; @Getter public class App { private String value; private String value2; public App(String value) { this.value = value; } public static void main(String[] args) { App app = new App(&quot;it works&quot;); System.out.println(app.getValue()); } }编译并执行: mvn clean compile &amp;&amp; java -cp target/classes com.mythsman.test.App 最后就会在构建成功后打印”it works”。 参考参考参考]]></content>
      <categories>
        <category>Lombok</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>idea</tag>
        <tag>lombok</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识Shiro]]></title>
    <url>%2F2019%2F09%2F12%2F%E5%88%9D%E8%AF%86Shiro%2F</url>
    <content type="text"><![CDATA[what官网 whyhow]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 下locate命令使用问题WARNING: The locate database (/var/db/locate.database) does not exist]]></title>
    <url>%2F2019%2F09%2F11%2FMac-%E4%B8%8Blocate%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98WARNING-The-locate-database-var-db-locate-database-does-not-exist%2F</url>
    <content type="text"><![CDATA[问题 根据提示使用 sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.locate.plist 并没有生效。 需要执行 sudo /usr/libexec/locate.updatedb 进行库更新。 参考]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac上解决java.rmi.server.ExportException- Port already in use- 1099; nested exception is- java.net.Bi]]></title>
    <url>%2F2019%2F09%2F09%2Fmac%E4%B8%8A%E8%A7%A3%E5%86%B3java-rmi-server-ExportException-Port-already-in-use-1099-nested-exception-is-java-net-Bi%2F</url>
    <content type="text"><![CDATA[tomcat启动报如下的错误： java.rmi.server.ExportException: Port already in use: 1099; nested exception is: java.net.BindException: Address already in use (Bind failed) 解决方法有两种 第一种：换其他的端口再次启动，例如：换1098端口，如果你不想换其他端口，则见第二种方法第二种第一步：使用lsof -i tcp:1099 查看时那个应用占用了此端口 第二部：使用kill pid 即可，这里的pid是第一步所查询到结果 原文链接]]></content>
      <categories>
        <category>exception</category>
      </categories>
      <tags>
        <tag>exception</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 getWriter() has already been called for this response 的错误解决办法]]></title>
    <url>%2F2019%2F09%2F09%2F%E5%85%B3%E4%BA%8E-getWriter-has-already-been-called-for-this-response-%E7%9A%84%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[上篇Filter、FilterChain、FilterConfig 介绍文中的代码若在多个filter中执行则会报错” getWriter() has already been called for this response “ 解决方案为在doFilter() 之前将流关闭. public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(&quot;begin headers-------------------&quot;); Enumeration&lt;?&gt; headerNames = ((HttpServletRequest)request).getHeaderNames(); while(headerNames.hasMoreElements()) { String headerName = (String)headerNames.nextElement(); System.out.println(headerName + &quot;: &quot; + ((HttpServletRequest)request).getHeader(headerName)); } System.out.println(&quot;end headers-------------------&quot;); //在调用目标前写入响应内容 response.setContentType(&quot;text/html; charset=utf-8&quot;); PrintWriter out = response.getWriter(); out.println(&quot;IP地址为：&quot; + request.getRemoteHost() + &quot;&lt;br&gt;&quot;); //在目标返回后写入响应内容 out.println(&quot;&lt;br&gt;名称为encoding的初始化参数的值为：&quot; + paramValue); out.println(&quot;&lt;br&gt;当前Web程序的真实路径为：&quot; + filterConfig.getServletContext().getRealPath(&quot;/&quot;)); out.close(); // 不关闭则会报错 getWriter() has already been called for this response chain.doFilter(request, response); }]]></content>
      <categories>
        <category>exception</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java.io.EOFException]]></title>
    <url>%2F2019%2F09%2F06%2Fjava-io-EOFException%2F</url>
    <content type="text"><![CDATA[Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost. 启动ssm项目报上述错误,查了一堆答案 有说改 jdbc配置的,有说改数据库的顺便还改了下数据库 show variables like &apos;wait_timeout&apos;; show global variables like &apos;%wait%&apos;; set wait_timeout=86400;问题都没有解决 最终解决方案: 可能是防火墙,翻墙软件等造成的]]></content>
      <categories>
        <category>exception</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo插入图片]]></title>
    <url>%2F2019%2F09%2F06%2Fhexo%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。 图片除了可以放在统一的images文件夹中，还可以放在文章自己的目录中。文章的目录可以通过配置_config.yml来生成。 post_asset_folder: true将_config.yml文件中的配置项post_asset_folder设为true后，执行命令$ hexo new post_name，在source/_posts中会生成文章post_name.md和同名文件夹post_name。将图片资源放在post_name中，文章就可以使用相对路径引用图片资源了。 _posts/post_name/image.jpg 1 ![](image.jpg)[参考] (https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/)]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读《活着》有感]]></title>
    <url>%2F2019%2F09%2F06%2F%E8%AF%BB-%E6%B4%BB%E7%9D%80-%E6%9C%89%E6%84%9F%2F</url>
    <content type="text"><![CDATA[余华文笔真好,很有代入感 富贵就是那个时代的缩影 选择比努力重要 人首先要尊重自己! 凡事多替自己想想,富贵儿子死的真冤! 珍惜今天吧]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读后感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Filter、FilterChain、FilterConfig 介绍]]></title>
    <url>%2F2019%2F09%2F06%2FFilter%E3%80%81FilterChain%E3%80%81FilterConfig-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、Filter 的基本工作原理 1、Filter 程序是一个实现了特殊接口的 Java 类，与 Servlet 类似，也是由 Servlet 容器进行调用和执行的。 2、当在 web.xml 注册了一个 Filter 来对某个 Servlet 程序进行拦截处理时，它可以决定是否将请求继续传递给 Servlet 程序，以及对请求和响应消息是否进行修改。 3、当 Servlet 容器开始调用某个 Servlet 程序时，如果发现已经注册了一个 Filter 程序来对该 Servlet 进行拦截，那么容器不再直接调用 Servlet 的 service 方法，而是调用 Filter 的 doFilter 方法，再由 doFilter 方法决定是否去激活 service 方法。 4、但在 Filter.doFilter 方法中不能直接调用 Servlet 的 service 方法，而是调用 FilterChain.doFilter 方法来激活目标 Servlet 的 service 方法，FilterChain 对象是通过 Filter.doFilter 方法的参数传递进来的。 5、只要在 Filter.doFilter 方法中调用 FilterChain.doFilter 方法的语句前后增加某些程序代码，这样就可以在 Servlet 进行响应前后实现某些特殊功能。 6、如果在 Filter.doFilter 方法中没有调用 FilterChain.doFilter 方法，则目标 Servlet 的 service 方法不会被执行，这样通过 Filter 就可以阻止某些非法的访问请求。 二、Filter 链 1、在一个 Web 应用程序中可以注册多个 Filter 程序，每个 Filter 程序都可以对一个或一组 Servlet 程序进行拦截。如果有多个 Filter 程序都可以对某个 Servlet 程序的访问过程进行拦截，当针对该 Servlet 的访问请求到达时，Web 容器将把这多个 Filter 程序组合成一个 Filter 链（也叫过滤器链）。 2、Filter 链中的各个 Filter 的拦截顺序与它们在 web.xml 文件中的映射顺序一致，上一个 Filter.doFilter 方法中调用 FilterChain.doFilter 方法将激活下一个 Filter的doFilter 方法，最后一个 Filter.doFilter 方法中调用的 FilterChain.doFilter 方法将激活目标 Servlet的service 方法。 3、只要 Filter 链中任意一个 Filter 没有调用 FilterChain.doFilter 方法，则目标 Servlet 的 service 方法都不会被执行。 三、Filter 接口一个 Filter 程序就是一个 Java 类，这个类必须实现 Filter 接口。javax.servlet.Filter 接口中定义了三个方法：init、doFilter、destory。 1、init 方法 在 Web 应用程序启动时，Web 服务器（Web 容器）将根据其 web.xml 文件的配置信息来创建每个注册的 Filter 的实例对象，并将其保存在内存中。 Web 容器创建 Filter 的实例对象后，将立即调用该 Filter 对象的 init 方法。init 方法在 Filter 生命周期中仅被执行一次，Web 容器在调用 init 方法时，会传递一个包含 Filter 的配置和运行环境信息的 FilterConfig 对象。 public voic init(FilterConfig filterConfig) throws ServletException 开发人员可以在 init 方法中完成与构造方法类似的初始化功能，要注意的是：如果初始化代码要使用到 FilterConfig 对象，这些代码只能在 init 方法中编写，而不能在构造方法中编写（尚未调用 init 方法，即并没有创建 FilterConfig 对象，要使用它则必然出错）。 2、doFilter 方法当一个 Filter 对象能够拦截访问请求时，Servlet 容器将调用 Filter 对象的 doFilter 方法。 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws java.io.IOException.ServletException其中，参数 request 和 response 为 Web 容器或 Filter 链中上一个 Filter 传递过来的请求和响应对象；参数 chain 为代表当前 Filter 链的对象。 3、destroy 方法该方法在 Web 容器卸载 Filter 对象之前被调用，也仅执行一次。可以完成与 init 方法相反的功能，释放被该 Filter 对象打开的资源，例如：关闭数据库连接和 IO 流。 四、FilterChain 接口该接口用于定义一个 Filter 链的对象应该对外提供的方法，这个接口只定义了一个 doFilter 方法。 public void doFilter(ServletRequest request, ServletResponse response) throws java.io.IOException.ServletException FilterChain 接口的 doFilter 方法用于通知 Web 容器把请求交给 Filter 链中的下一个 Filter 去处理，如果当前调用此方法的 Filter 对象是Filter 链中的最后一个 Filter，那么将把请求交给目标 Servlet 程序去处理。 五、FilterConfig 接口1、与普通的 Servlet 程序一样，Filter 程序也很可能需要访问 Servlet 容器。Servlet 规范将代表 ServletContext 对象和 Filter 的配置参数信息都封装到一个称为 FilterConfig 的对象中。2、FilterConfig 接口则用于定义 FilterConfig 对象应该对外提供的方法，以便在 Filter 程序中可以调用这些方法来获取 ServletContext 对象，以及获取在 web.xml 文件中为 Filter 设置的友好名称和初始化参数。3、FilterConfig接口定义的各个方法： getFilterName 方法，返回 元素的设置值。 getServletContext 方法，返回 FilterConfig 对象中所包装的 ServletContext 对象的引用。 getInitParameter 方法，用于返回在 web.xml 文件中为 Filter 所设置的某个名称的初始化的参数值。 getInitParameterNames 方法，返回一个 Enumeration 集合对象。 六、Filter 的注册与映射1、注册 Filter一个 元素用于注册一个 Filter。其中， 元素是必需的， 元素也是必需的， 元素是可选的，可以有多个 &lt; init-param&gt; 元素。 &lt;filter&gt; &lt;filter-name&gt;FirstFilter&lt;/filter-name&gt; &lt;filter-class&gt;FirstFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;GB2312&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt;2、映射 Filter&lt;filter-mapping&gt; 元素用于设置一个 Filter 所负责拦截的资源。一个 Filter 拦截的资源可以通过两种方式来指定：资源的访问请求路径和 Servlet 名称。第一种：指定资源的访问路径&lt;filter-mapping&gt; &lt;filter-name&gt;FirstFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 元素中的访问路径的设置方式遵循 Servlet 的 URL 映射规范。 /*：表示拦截所有的访问请求。 /filter/*：表示拦截 filter 目录下的所有访问请求，如：http://localhost:8888/testFilter_001/filter/xxxxxx 。 /test.html：表示拦截根目录下以 test.html 为资源名的访问请求，访问链接只会是：http://localhost:8888/test.html。 第二种：指定 Servlet 的名称&lt;filter-mapping&gt; &lt;filter-name&gt;FirstFilter&lt;/filter-name&gt; &lt;servlet-name&gt;default&gt;&lt;/servlet-name&gt; &lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;/filter-mapping&gt;（1）、 元素与 元素是二选一的关系，其值是某个 Servlet 在 web.xml 文件中的注册名称。（2）、 元素的设置值有 4 种：REQUEST、INCLUDE、FORWARD、ERROR，分别对应 Servlet 容器调用资源的 4 种方式： 通过正常的访问请求调用； 通过 RequestDispatcher.include 方法调用； 通过 RequestDispatcher.forward 方法调用； 作为错误响应资源调用。如果没有设置 子元素，则等效于 REQUEST 的情况。也可以设置多个 子元素，用于指定 Filter 对资源的多种调用方式都进行拦截。 七、Filter 程序示例FitstFilter.java import java.io.IOException; import java.io.PrintWriter; import java.util.Enumeration; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; public class FirstFilter implements Filter { private FilterConfig filterConfig = null; String paramValue = null; @Override public void init(FilterConfig filterConfig) throws ServletException { this.filterConfig = filterConfig; paramValue = filterConfig.getInitParameter(&quot;encoding&quot;); } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(&quot;begin headers-------------------&quot;); Enumeration&lt;?&gt; headerNames = ((HttpServletRequest)request).getHeaderNames(); while(headerNames.hasMoreElements()) { String headerName = (String)headerNames.nextElement(); System.out.println(headerName + &quot;: &quot; + ((HttpServletRequest)request).getHeader(headerName)); } System.out.println(&quot;end headers-------------------&quot;); //在调用目标前写入响应内容 response.setContentType(&quot;text/html; charset=gb2312&quot;); PrintWriter out = response.getWriter(); out.println(&quot;IP地址为：&quot; + request.getRemoteHost() + &quot;&lt;br&gt;&quot;); chain.doFilter(request, response); //在目标返回后写入响应内容 out.println(&quot;&lt;br&gt;名称为encoding的初始化参数的值为：&quot; + paramValue); out.println(&quot;&lt;br&gt;当前Web程序的真实路径为：&quot; + filterConfig.getServletContext().getRealPath(&quot;/&quot;)); //out.println(&quot;&lt;br&gt;修改了test.html文件！&quot;); } @Override public void destroy() { this.filterConfig = null; } }web.xml &lt;filter&gt; &lt;filter-name&gt;FirstFilter&lt;/filter-name&gt; &lt;filter-class&gt;FirstFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;GB2312&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;FirstFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;test.html（位于WebContent路径的filter目录中） &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; 这就是test.html页面的原始内容！ &lt;/body&gt; &lt;/html&gt;参考]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个bug的旅程]]></title>
    <url>%2F2019%2F09%2F04%2F%E4%B8%80%E4%B8%AAbug%E7%9A%84%E6%97%85%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[大家好我叫bug,我爸叫后台,我妈叫大前端(H5,安卓,IOS)听说有一个叫天堂的地方特美,我的目标就是天堂. 一天我懒洋洋的躺在海边,沐浴着和煦得阳光.吃着习惯,吹着海风.意淫着隔壁的漂亮妹子…… 突然一个叫测试的家伙发现了我!追着我就跑,非说要超度我到天堂! 天堂有个规矩:不收无名之辈 两条路摆在了我面前 1: 测试拿问题页面 -&gt; 前端 -&gt; 前端提供接口名 参数 返回值 -&gt; 后台 2: 测试拿问题页面 -&gt; 后端 -&gt; 前端 -&gt; 前端提供接口名 参数 返回值 -&gt; 后台好吧测试是个傻子一会儿走路线1 一会儿走路线2 我走路线1,很快到了天堂,天堂有好多妹子……]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSP与JavaScript]]></title>
    <url>%2F2019%2F09%2F04%2FJSP%E4%B8%8EJavaScript%2F</url>
    <content type="text"><![CDATA[某日在洗手间偶遇某大牛,聊起JSP,大牛曰:”JSP 哦知道,JavaScript”我竟无言以对!在此记录一下JSP与JavaScript的区别 首先下结论 雷锋与雷锋塔的区别JSP是什么SUN首先发展出SERVLET，其功能比较强劲，体系设计也很先进，只是，它输出HTML语句还是采用了老的CGI方式，是一句一句输出，所以，编写和修改HTML非常不方便。 后来SUN推出了类似于ASP的镶嵌型的JSP，把JSP TAG镶嵌到HTML语句中，这样，就大大简化和方便了网页的设计和修改。 JSP全名为Java Server Pages，其根本是一个简化的Servlet设计，他实现了Html语法中的java扩张（以 &lt;%, %&gt;形式）。JSP与Servlet一样，是在服务器端执行的。通常返回给客户端的就是一个HTML文本，因此客户端只要有浏览器就能浏览。Web服务器在遇到访问JSP网页的请求时，首先执行其中的程序段，然后将执行结果连同JSP文件中的HTML代码一起返回给客户端。插入的Java程序段可以操作数据库、重新定向网页等，以实现建立动态网页所需要的功能。 JSP页面由HTML代码和嵌入其中的Java代码所组成。服务器在页面被客户端请求以后对这些Java代码进行处理，然后将生成的HTML页面返回给客户端的浏览器。Java Servlet是JSP的技术基础，而且大型的Web应用程序的开发需要Java Servlet和JSP配合才能完成。JSP具备了Java技术的简单易用，完全的面向对象，具有平台无关性且安全可靠，主要面向因特网的所有特点。 jsp 要先翻译，注意是翻译成servlet才能执行：比如 test.jsp 要变成 test_jsp.java 然后编译成 test_jsp.class而 test_jsp.java 本身就是一个servlet.所以 jsp只是servlet的一个变种，方便书写html内容才出现的。 servlet的运行机制和Applet类似，只不过它运行在服务器端。一个servlet是javax.servlet包中HttpServlet类的子类，由支持servlet的服务器完成该子类的对象，即servlet的初始化。 扩展阅读0：jsp转化为servlet的过程： http://www.w3cschool.cc/jsp/jsp-architecture.html 扩展阅读1：servlet版的Helloworld（需要装tomcat,我通常使用XAMPP集成的tomcat） http://blog.163.com/adoom_2010/blog/static/1820326362011710102719527/ 扩展阅读2：servlet程序中的各部分的作用、调用顺序 http://wenku.baidu.com/link?url=U2B6Gx_C1X702ppIFJdXR23MyY85lZzJeneIDZSFCuA3bZ-ynwDFx9oYm4pNcpa4ZjmlUPnkrtwkHg0skxdo3mqOY-IAvXzzYqaCOc7DVmWJavaScript是什么Java Script 是一种基于对象的客户端脚本语言。主要目的是为了解决服务器端语言，比如Perl，遗留的速度问题，为客户提供更流畅的浏览效果。JS可以直接嵌入到html代码中进行解析执行，非常简单易学，可以产生很多动态的效果。 二者区别简单地说——JS是在客户端执行的，需要浏览器支持Javascript。JSP是在服务器端执行的，需要服务器上部署支持Servlet的服务器程序。JS代码是能够直接从服务器上download得到，对外是可见的，jsp(和翻译后的servlet)代码是对外不可见的。 JS与JavaScript相比：虽然JavaScript可以在客户端动态生成HTML，但是很难与服务器交互，因此不能提供复杂的服务，比如访问数据库和图像处理等等。JSP在HTML中用&lt;%%&gt;里面实现。JS在html中用实现 参考1参考2参考3]]></content>
      <categories>
        <category>笑话</category>
      </categories>
      <tags>
        <tag>JSP</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea将普通Java项目改为Maven项目]]></title>
    <url>%2F2019%2F09%2F04%2Fidea%E5%B0%86%E6%99%AE%E9%80%9AJava%E9%A1%B9%E7%9B%AE%E6%94%B9%E4%B8%BAMaven%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[方式 11 在项目右键 Add Framework Support 2 选择maven 方式21.右键工程文件，新建文件pom.xml，并填写好内容。 2.在pom.xml 文件上右键 Add as Maven Project。 3.idea自己导入maven。 怎么在pom.xml中添加项目中libs下的jar呢，而不是从本地仓库中添加？1、首先将要添加的jar包复制到项目中的libs文件夹下 2、然后在pom.xml中添加如下代码： &lt;dependency&gt; &lt;groupId&gt;htmlunit&lt;/groupId&gt; &lt;artifactId&gt;htmlunit&lt;/artifactId&gt; &lt;version&gt;2.21-OSGi&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/libs/htmlunit-2.21-OSGi.jar&lt;/systemPath&gt; &lt;/dependency&gt;注意scope元素和systemPath元素，其中systemPath元素指定的就是jar包在项目中的路径。注意libs文件夹下的这个jar包不需要Add to Build Path 参考1参考2]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>idea</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea突然有些字母不显示]]></title>
    <url>%2F2019%2F09%2F03%2Fidea%E7%AA%81%E7%84%B6%E6%9C%89%E4%BA%9B%E5%AD%97%E6%AF%8D%E4%B8%8D%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[问题 解决方案解决方案：更换idea字体，点击apply按钮即可正常显示 参考1 参考2]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring mvc 控制台输出乱码]]></title>
    <url>%2F2019%2F09%2F03%2Fspring-mvc-%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%BE%93%E5%87%BA%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1、运行环境：操作系统系统：Mac OS X10.12.6，语言：英文开发工具：IntelliJ IDEA 2017.2.2，默认编码：UTF-8Tomcat:9.0.0.M262、问题：运行Web项目时，控制台输出乱码。3、解决方法：设置Servlet的VM options(虚拟机选项)为：-Dfile.encoding=UTF-8 来源]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring基础知识]]></title>
    <url>%2F2019%2F09%2F02%2FSpring%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Spring简介Spring框架由Rod Johnson开发，2004年发布了Spring框架的第一版。Spring是一个从实际开发中抽取出来的框架，因此它完成了大量开发中的通用步骤，留给开发者的仅仅是与特定应用相关的部分，从而大大提高了企业应用的开发效率。 优点 低侵入式设计，代码的污染极低 独立于各种应用服务器，基于Spring框架的应用，可以真正实现Write Once，Run Anywhere的承诺。 Spring的IoC容器降低了业务对象替换的复杂性，提高了组件之间的解耦。 Spring的AOP支持允许将一些通用任务如安全、事务、日志等进行集中式管理，从而提供了更好的复用。 Spring的ORM和DAO提供了与第三方持久层框架的良好整合，并简化了底层的数据库访问。 Spring的高度开放性，并不强制应用完全依赖于Spring，开发者可自由选用Spring框架的部分或全部。 结构图 Spring的核心机制管理Bean程序主要是通过Spring容器来访问容器中的Bean，ApplicationContext是Spring容器最常用的接口，该接口有如下两个实现类： ClassPathXmlApplicationContext: 从类加载路径下搜索配置文件，并根据配置文件来创建Spring容器。 FileSystemXmlApplicationContext: 从文件系统的相对路径或绝对路径下去搜索配置文件，并根据配置文件来创建Spring容器。 public class BeanTest{ public static void main(String args[]) throws Exception{ ApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;); Person p = ctx.getBean(&quot;person&quot;, Person.class); p.say(); } }依赖注入Spring框架的核心功能有两个： Spring容器作为超级大工厂，负责创建、管理所有的Java对象，这些Java对象被称为Bean。 Spring容器管理容器中Bean之间的依赖关系，Spring使用一种被称为”依赖注入”的方式来管理Bean之间的依赖关系。 使用依赖注入，不仅可以为Bean注入普通的属性值，还可以注入其他Bean的引用。依赖注入是一种优秀的解耦方式，其可以让Bean以配置文件组织在一起，而不是以硬编码的方式耦合在一起。 理解依赖注入Rod Johnson是第一个高度重视以配置文件来管理Java实例的协作关系的人，他给这种方式起了一个名字：控制反转（Inverse of Control，IoC）。后来Martine Fowler为这种方式起了另一个名称：依赖注入（Dependency Injection），因此不管是依赖注入，还是控制反转，其含义完全相同。当某个Java对象（调用者）需要调用另一个Java对象（被依赖对象）的方法时，在传统模式下通常有两种做法： 原始做法: 调用者主动创建被依赖对象，然后再调用被依赖对象的方法。 简单工厂模式: 调用者先找到被依赖对象的工厂，然后主动通过工厂去获取被依赖对象，最后再调用被依赖对象的方法。 注意上面的主动二字，这必然会导致调用者与被依赖对象实现类的硬编码耦合，非常不利于项目升级的维护。使用Spring框架之后，调用者无需主动获取被依赖对象，调用者只要被动接受Spring容器为调用者的成员变量赋值即可，由此可见，使用Spring后，调用者获取被依赖对象的方式由原来的主动获取，变成了被动接受——所以Rod Johnson称之为控制反转。 另外从Spring容器的角度来看，Spring容器负责将被依赖对象赋值给调用者的成员变量——相当于为调用者注入它依赖的实例，因此Martine Fowler称之为依赖注入。 设值注入设值注入是指IoC容器通过成员变量的setter方法来注入被依赖对象。这种注入方式简单、直观，因而在Spring的依赖注入里大量使用。 构造注入利用构造器来设置依赖关系的方式，被称为构造注入。通俗来说，就是驱动Spring在底层以反射方式执行带指定参数的构造器，当执行带参数的构造器时，就可利用构造器参数对成员变量执行初始化——这就是构造注入的本质。 两种注入方式的对比设值注入有如下优点： 与传统的JavaBean的写法更相似，程序开发人员更容易理解、接受。通过setter方法设定依赖关系显得更加直观、自然。 对于复杂的依赖关系，如果采用构造注入，会导致构造器过于臃肿，难以阅读。Spring在创建Bean实例时，需要同时实例化其依赖的全部实例，因而导致性能下降。而使用设值注入，则能避免这些问题。 尤其在某些成员变量可选的情况下，多参数的构造器更加笨重。 构造注入优势如下： 构造注入可以在构造器中决定依赖关系的注入顺序，优先依赖的优先注入。 对于依赖关系无需变化的Bean，构造注入更有用处。因为没有setter方法，所有的依赖关系全部在构造器内设定，无须担心后续的代码对依赖关系产生破坏。 依赖关系只能在构造器中设定，则只有组件的创建者才能改变组件的依赖关系，对组件的调用者而言，组件内部的依赖关系完全透明，更符合高内聚的原则。 注意：建议采用设值注入为主，构造注入为辅的注入策略。对于依赖关系无须变化的注入，尽量采用构造注入；而其他依赖关系的注入，则考虑采用设值注入。 Spring容器中的BeanIoC的本质对于开发者来说，开发者使用Spring框架主要是做两件事：①开发Bean；②配置Bean。对于Spring框架来说，它要做的就是根据配置文件来创建Bean实例，并调用Bean实例的方法完成”依赖注入”——这就是所谓IoC的本质。 容器中Bean的作用域当通过Spring容器创建一个Bean实例时，不仅可以完成Bean实例的实例化，还可以为Bean指定特定的作用域。Spring支持如下五种作用域： singleton: 单例模式，在整个Spring IoC容器中，singleton作用域的Bean将只生成一个实例。 prototype: 每次通过容器的getBean()方法获取prototype作用域的Bean时，都将产生一个新的Bean实例。 request: 对于一次HTTP请求，request作用域的Bean将只生成一个实例，这意味着，在同一次HTTP请求内，程序每次请求该Bean，得到的总是同一个实例。只有在Web应用中使用Spring时，该作用域才真正有效。 session：该作用域将 bean 的定义限制为 HTTP 会话。 只在web-aware Spring ApplicationContext的上下文中有效。 global session: 每个全局的HTTP Session对应一个Bean实例。在典型的情况下，仅在使用portlet context的时候有效，同样只在Web应用中有效。 注意如果不指定Bean的作用域，Spring默认使用singleton作用域。prototype作用域的Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成果，就可以重复使用。因此，应该尽量避免将Bean设置成prototype作用域。 使用自动装配注入合作者Bean Spring能自动装配Bean与Bean之间的依赖关系，即无须使用ref显式指定依赖Bean，而是由Spring容器检查XML配置文件内容，根据某种规则，为调用者Bean注入被依赖的Bean。 Spring自动装配可通过元素的default-autowire属性指定，该属性对配置文件中所有的Bean起作用；也可通过对元素的autowire属性指定，该属性只对该Bean起作用。 autowire和default-autowire可以接受如下值： no: 不使用自动装配。Bean依赖必须通过ref元素定义。这是默认配置，在较大的部署环境中不鼓励改变这个配置，显式配置合作者能够得到更清晰的依赖关系。 byName: 根据setter方法名进行自动装配。Spring容器查找容器中全部Bean，找出其id与setter方法名去掉set前缀，并小写首字母后同名的Bean来完成注入。如果没有找到匹配的Bean实例，则Spring不会进行任何注入。 byType 根据setter方法的形参类型来自动装配。Spring容器查找容器中的全部Bean，如果正好有一个Bean类型与setter方法的形参类型匹配，就自动注入这个Bean；如果找到多个这样的Bean，就抛出一个异常；如果没有找到这样的Bean，则什么都不会发生，setter方法不会被调用 constructor: 与byType类似，区别是用于自动匹配构造器的参数。如果容器不能恰好找到一个与构造器参数类型匹配的Bean，则会抛出一个异常。 autodetect: Spring容器根据Bean内部结构，自行决定使用constructor或byType策略。如果找到一个默认的构造函数，那么就会应用byType策略。 当一个Bean既使用自动装配依赖，又使用ref显式指定依赖时，则显式指定的依赖覆盖自动装配依赖；对于大型的应用，不鼓励使用自动装配。虽然使用自动装配可减少配置文件的工作量，但大大将死了依赖关系的清晰性和透明性。依赖关系的装配依赖于源文件的属性名和属性类型，导致Bean与Bean之间的耦合降低到代码层次，不利于高层次解耦。 &lt;!--通过设置可以将Bean排除在自动装配之外--&gt; &lt;bean id=&quot;&quot; autowire-candidate=&quot;false&quot;/&gt; &lt;!--除此之外，还可以在beans元素中指定，支持模式字符串，如下所有以abc结尾的Bean都被排除在自动装配之外--&gt; &lt;beans default-autowire-candidates=&quot;*abc&quot;/&gt;创建Bean的3种方式使用构造器创建Bean实例使用构造器来创建Bean实例是最常见的情况，如果不采用构造注入，Spring底层会调用Bean类的无参数构造器来创建实例，因此要求该Bean类提供无参数的构造器。 采用默认的构造器创建Bean实例，Spring对Bean实例的所有属性执行默认初始化，即所有的基本类型的值初始化为0或false；所有的引用类型的值初始化为null。 使用静态工厂方法创建Bean使用静态工厂方法创建Bean实例时，class属性也必须指定，但此时class属性并不是指定Bean实例的实现类，而是静态工厂类，Spring通过该属性知道由哪个工厂类来创建Bean实例。 除此之外，还需要使用factory-method属性来指定静态工厂方法，Spring将调用静态工厂方法返回一个Bean实例，一旦获得了指定Bean实例，Spring后面的处理步骤与采用普通方法创建Bean实例完全一样。如果静态工厂方法需要参数，则使用&lt;constructor-arg…/&gt;元素指定静态工厂方法的参数。 调用实例工厂方法创建Bean实例工厂方法与静态工厂方法只有一个不同：调用静态工厂方法只需使用工厂类即可，而调用实例工厂方法则需要工厂实例。使用实例工厂方法时，配置Bean实例的&lt;bean…/&gt;元素无须class属性，配置实例工厂方法使用factory-bean指定工厂实例。采用实例工厂方法创建Bean的&lt;bean…/&gt;元素时需要指定如下两个属性： factory-bean: 该属性的值为工厂Bean的id。 factory-method: 该属性指定实例工厂的工厂方法。 若调用实例工厂方法时需要传入参数，则使用&lt;constructor-arg…/&gt;元素确定参数值。 协调作用域不同步的Bean当singleton作用域的Bean依赖于prototype作用域的Bean时，会产生不同步的现象，原因是因为当Spring容器初始化时，容器会预初始化容器中所有的singleton Bean，由于singleton Bean依赖于prototype Bean，因此Spring在初始化singleton Bean之前，会先创建prototypeBean——然后才创建singleton Bean，接下里将prototype Bean注入singleton Bean。解决不同步的方法有两种： 放弃依赖注入: singleton作用域的Bean每次需要prototype作用域的Bean时，主动向容器请求新的Bean实例，即可保证每次注入的prototype Bean实例都是最新的实例。 利用方法注入: 方法注入通常使用lookup方法注入，使用lookup方法注入可以让Spring容器重写容器中Bean的抽象或具体方法，返回查找容器中其他Bean的结果，被查找的Bean通常是一个non-singleton Bean。Spring通过使用JDK动态代理或cglib库修改客户端的二进制码，从而实现上述要求。 注意 Spring会采用运行时动态增强的方式来实现&lt;lookup-method…/&gt;元素所指定的抽象方法，如果目标抽象类实现过接口，Spring会采用JDK动态代理来实现该抽象类，并为之实现抽象方法；如果目标抽象类没有实现过接口，Spring会采用cglib实现该抽象类，并为之实现抽象方法。Spring4.0的spring-core-xxx.jar包中已经集成了cglib类库。 两种后处理器Spring提供了两种常用的后处理器： Bean后处理器: 这种后处理器会对容器中Bean进行后处理，对Bean进行额外加强。 容器后处理器: 这种后处理器会对IoC容器进行后处理，用于增强容器功能。 Bean后处理器Bean后处理器是一种特殊的Bean，这种特殊的Bean并不对外提供服务，它甚至可以无须id属性，它主要负责对容器中的其他Bean执行后处理，例如为容器中的目标Bean生成代理等，这种Bean称为Bean后处理器。Bean后处理器会在Bean实例创建成功之后，对Bean实例进行进一步的增强处理。Bean后处理器必须实现BeanPostProcessor接口，同时必须实现该接口的两个方法。 Object postProcessBeforeInitialization(Object bean, String name) throws BeansException: 该方法的第一个参数是系统即将进行后处理的Bean实例，第二个参数是该Bean的配置id Object postProcessAfternitialization(Object bean, String name) throws BeansException: 该方法的第一个参数是系统即将进行后处理的Bean实例，第二个参数是该Bean的配置id 容器中一旦注册了Bean后处理器，Bean后处理器就会自动启动，在容器中每个Bean创建时自动工作，Bean后处理器两个方法的回调时机如下图： 注意一点，如果使用BeanFactory作为Spring容器，则必须手动注册Bean后处理器，程序必须获取Bean后处理器实例，然后手动注册。 BeanPostProcessor bp = (BeanPostProcessor)beanFactory.getBean(&quot;bp&quot;); beanFactory.addBeanPostProcessor(bp); Person p = (Person)beanFactory.getBean(&quot;person&quot;);容器后处理器Bean后处理器负责处理容器中的所有Bean实例，而容器后处理器则负责处理容器本身。容器后处理器必须实现BeanFactoryPostProcessor接口，并实现该接口的一个方法postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory)实现该方法的方法体就是对Spring容器进行的处理，这种处理可以对Spring容器进行自定义扩展，当然也可以对Spring容器不进行任何处理。 类似于BeanPostProcessor，ApplicationContext可自动检测到容器中的容器后处理器，并且自动注册容器后处理器。但若使用BeanFactory作为Spring容器，则必须手动调用该容器后处理器来处理BeanFactory容器。 Spring的”零配置”支持搜索Bean类Spring提供如下几个Annotation来标注Spring Bean： @Component: 标注一个普通的Spring Bean类 @Controller: 标注一个控制器组件类 @Service: 标注一个业务逻辑组件类 @Repository: 标注一个DAO组件类 在Spring配置文件中做如下配置，指定自动扫描的包： &lt;context:component-scan base-package=”edu.shu.spring.domain”/&gt; 使用@Resource配置依赖@Resource位于javax.annotation包下，是来自JavaEE规范的一个Annotation，Spring直接借鉴了该Annotation，通过使用该Annotation为目标Bean指定协作者Bean。使用@Resource与&lt;property…/&gt;元素的ref属性有相同的效果。@Resource不仅可以修饰setter方法，也可以直接修饰实例变量，如果使用@Resource修饰实例变量将会更加简单，此时Spring将会直接使用JavaEE规范的Field注入，此时连setter方法都可以不要。 使用@PostConstruct和@PreDestroy定制生命周期行为@PostConstruct和@PreDestroy同样位于javax.annotation包下，也是来自JavaEE规范的两个Annotation，Spring直接借鉴了它们，用于定制Spring容器中Bean的生命周期行为。它们都用于修饰方法，无须任何属性。其中前者修饰的方法时Bean的初始化方法；而后者修饰的方法时Bean销毁之前的方法。 Spring4.0增强的自动装配和精确装配Spring提供了@Autowired注解来指定自动装配，@Autowired可以修饰setter方法、普通方法、实例变量和构造器等。当使用@Autowired标注setter方法时，默认采用byType自动装配策略。在这种策略下，符合自动装配类型的候选Bean实例常常有多个，这个时候就可能引起异常，为了实现精确的自动装配，Spring提供了@Qualifier注解，通过使用@Qualifier，允许根据Bean的id来执行自动装配。 Spring的AOP为什么需要AOPAOP（Aspect Orient Programming）也就是面向切面编程，作为面向对象编程的一种补充，已经成为一种比较成熟的编程方式。其实AOP问世的时间并不太长，AOP和OOP互为补充，面向切面编程将程序运行过程分解成各个切面。 AOP专门用于处理系统中分布于各个模块（不同方法）中的交叉关注点的问题，在JavaEE应用中，常常通过AOP来处理一些具有横切性质的系统级服务，如事务管理、安全检查、缓存、对象池管理等，AOP已经成为一种非常常用的解决方案。 使用AspectJ实现AOPAspectJ是一个基于Java语言的AOP框架，提供了强大的AOP功能，其他很多AOP框架都借鉴或采纳其中的一些思想。其主要包括两个部分：一个部分定义了如何表达、定义AOP编程中的语法规范，通过这套语法规范，可以方便地用AOP来解决Java语言中存在的交叉关注点的问题；另一个部分是工具部分，包括编译、调试工具等。 AOP分类AOP实现可分为两类： 静态AOP实现: AOP框架在编译阶段对程序进行修改，即实现对目标类的增强，生成静态的AOP代理类，以AspectJ为代表。动态AOP实现: AOP框架在运行阶段动态生成AOP代理，以实现对目标对象的增强，以Spring AOP为代表。一般来说，静态AOP实现具有较好的性能，但需要使用特殊的编译器。动态AOP实现是纯Java实现，因此无须特殊的编译器，但是通常性能略差。 AOP的基本概念关于面向切面编程的一些术语： 切面（Aspect）: 切面用于组织多个Advice，Advice放在切面中定义。 连接点（Joinpoint）: 程序执行过程中明确的点，如方法的调用，或者异常的抛出。在Spring AOP中，连接点总是方法的调用。 增强处理（Advice）: AOP框架在特定的切入点执行的增强处理。处理有”around”、”before”和”after”等类型 切入点（Pointcut）: 可以插入增强处理的连接点。简而言之，当某个连接点满足指定要求时，该连接点将被添加增强处理，该连接点也就变成了切入点。 Spring的AOP支持Spring中的AOP代理由Spring的IoC容器负责生成、管理，其依赖关系也由IoC容器负责管理。为了在应用中使用@AspectJ支持，Spring需要添加三个库： aspectjweaver.jar aspectjrt.jar aopalliance.jar 并在Spring配置文件中做如下配置： &lt;!--启动@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!--指定自动搜索Bean组件、自动搜索切面类--&gt; &lt;context:component-scan base-package=&quot;edu.shu.sprint.service&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.aspectj.lang.annotation.Aspect&quot;/&gt; &lt;/context:component-scan&gt;来源]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git配置多个SSH-Key]]></title>
    <url>%2F2019%2F09%2F02%2FGit%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AASSH-Key%2F</url>
    <content type="text"><![CDATA[背景当有多个git账号时，比如： a. 一个gitee，用于公司内部的工作开发；b. 一个github，用于自己进行一些开发活动； 解决方法 生成一个公司用的SSH-Key $ ssh-keygen -t rsa -C ‘xxxxx@company.com’ -f ~/.ssh/gitee_id_rsa 生成一个github用的SSH-Key $ ssh-keygen -t rsa -C ‘xxxxx@qq.com’ -f ~/.ssh/github_id_rsa 在 ~/.ssh 目录下新建一个config文件，添加如下内容（其中Host和HostName填写git服务器的域名，IdentityFile指定私钥的路径） giteeHost gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~/.ssh/gitee_id_rsa githubHost github.comHostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/github_id_rsa 4.用ssh命令分别测试 $ ssh -T git@gitee.com$ ssh -T git@github.com 参考]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泰拳要领]]></title>
    <url>%2F2019%2F09%2F02%2F%E6%B3%B0%E6%8B%B3%E8%A6%81%E9%A2%86%2F</url>
    <content type="text"><![CDATA[上周六送弟弟去学泰拳,偷师了几招.在此记录一下 收拳要收到脸上(护头) 鞭腿腿是直的 提膝打击支撑腿是直的 鞭腿支撑腿略微忘左上走一点 打沙袋一定带护具 拳套等 教练演示着实震撼,以后让儿子也学!]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>泰拳</tag>
        <tag>运动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat9因为在清除过期缓存条目后可用空间仍不足 - 请考虑增加缓存的最大空间。]]></title>
    <url>%2F2019%2F08%2F29%2Ftomcat9%E5%9B%A0%E4%B8%BA%E5%9C%A8%E6%B8%85%E9%99%A4%E8%BF%87%E6%9C%9F%E7%BC%93%E5%AD%98%E6%9D%A1%E7%9B%AE%E5%90%8E%E5%8F%AF%E7%94%A8%E7%A9%BA%E9%97%B4%E4%BB%8D%E4%B8%8D%E8%B6%B3-%E8%AF%B7%E8%80%83%E8%99%91%E5%A2%9E%E5%8A%A0%E7%BC%93%E5%AD%98%E7%9A%84%E6%9C%80%E5%A4%A7%E7%A9%BA%E9%97%B4%E3%80%82%2F</url>
    <content type="text"><![CDATA[问题因为在清除过期缓存条目后可用空间仍不足 - 请考虑增加缓存的最大空间。 # 进入Tomcat安装位置 $CATALINA_HOME/ $ vim ../libexec/conf/context.xml 将下面代码添加到 &lt;Context&gt; &lt;/Context&gt;中 &lt;Resources cachingAllowed=&quot;true&quot; cacheMaxSize=&quot;100000&quot; /&gt;]]></content>
      <tags>
        <tag>java tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA如何配置JDK]]></title>
    <url>%2F2019%2F08%2F28%2FIntellij-IDEA%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEJDK%2F</url>
    <content type="text"><![CDATA[command + ; // 快捷键打开配置 Configure –&gt; Project Defaults –&gt; Project Structure 点击Project选项卡，配置相应jdk]]></content>
      <tags>
        <tag>Intellij IDEA</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac配置多个Java版本]]></title>
    <url>%2F2019%2F08%2F28%2FMac%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAJava%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[一. 安装最新版的Java# 如何没有安装 brew cask。请执行 $ brew tap caskroom/versions $ brew cask install java二.安装其他版本的Java如果你需要安装其他的jdk(JDK 7 或者 JDK 6)，可以使用homebrew-cask-versions： $ brew search java $ brew cask install java6 # 使用cask安装其他的工具三.查看本地安装的Java Home$ /usr/libexec/java_home -V #查看本地安装的java版本四.切换java版本【手动修改环境变量】那问题来了，当你运行java或者 Java 程序时使用的是哪个 JDK 呢？在 OS X 下，java也就是/usr/bin/java在默认情况下指向的是已经安装的最新版本。但是你可以设置环境变量JAVA_HOME来更改其指向： # 查看当前的java版本 $ java -version java version &quot;1.8.0_60&quot; Java(TM) SE Runtime Environment (build 1.8.0_60-b27) Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode) # 切换版本，可切换为第三步的本地java home中的任意一个。 $ export JAVA_HOME=/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home java -version java version &quot;1.6.0_65&quot; Java(TM) SE Runtime Environment (build 1.6.0_65-b14-466.1-11M4716) Java HotSpot(TM) 64-Bit Server VM (build 20.65-b04-466.1, mixed mode)五.配置命令自动切换修改系统环境变量： 在/.bash_profile（如果是Zsh，修改/.zshrc）文件中添加如下内容： # JDK 6 export JAVA_6_HOME=&quot;/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home&quot; # JDK 8 export JAVA_8_HOME=&quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home&quot; export JAVA_HOME=$JAVA_8_HOME #默认JDK 8 #alias命令动态切换JDK版本 alias jdk6=&quot;export JAVA_HOME=$JAVA_6_HOME&quot; alias jdk8=&quot;export JAVA_HOME=$JAVA_8_HOME&quot; 更新配置： $ source ~/.bash_profile #Zsh应改为 source ~/.zshrc切换java版本： $ jdk6 #使用jdk6 $ java -version java version &quot;1.6.0_65&quot; Java(TM) SE Runtime Environment (build 1.6.0_65-b14-468) Java HotSpot(TM) 64-Bit Server VM (build 20.65-b04-468, mixed mode) $ jdk8 #使用jdk8 $ java -version java version &quot;1.8.0_101&quot; Java(TM) SE Runtime Environment (build 1.8.0_101-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 说明：Mac系统的环境变量，加载顺序为： /etc/profile /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc参考1参考2]]></content>
      <tags>
        <tag>java jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hex 编码]]></title>
    <url>%2F2019%2F08%2F27%2Fhex-%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"></content>
      <tags>
        <tag>编码</tag>
        <tag>hex</tag>
        <tag>16进制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写JVM]]></title>
    <url>%2F2019%2F08%2F26%2F%E6%89%8B%E5%86%99JVM%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[node.js教程]]></title>
    <url>%2F2019%2F08%2F26%2Fnode-js%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[简介 简单的说 Node.js 就是运行在服务端的 JavaScript。 Node.js 是一个基于Chrome JavaScript 运行时建立的一个平台。 Node.js是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。 查看版本node -v v12.9.0Hello World vim helloWorld.js console.log(“Hello World”); node helloWorld.js 交互模式$ node &gt; console.log(&apos;Hello World!&apos;); Hello World!Node.js 安装配置Mac安装 brew install nodeNode.js 创建第一个应用步骤一、引入 required 模块我们使用 require 指令来载入 http 模块，并将实例化的 HTTP 赋值给变量 http，实例如下: var http = require(&quot;http&quot;);步骤二、创建服务器接下来我们使用 http.createServer() 方法创建服务器，并使用 listen 方法绑定 8888 端口。 函数通过 request, response 参数来接收和响应数据。 实例如下，在你项目的根目录下创建一个叫 server.js 的文件，并写入以下代码： var http = require(&apos;http&apos;); http.createServer(function (request, response) { // 发送 HTTP 头部 // HTTP 状态值: 200 : OK // 内容类型: text/plain response.writeHead(200, {&apos;Content-Type&apos;: &apos;text/plain&apos;}); // 发送响应数据 &quot;Hello World&quot; response.end(&apos;Hello World\n&apos;); }).listen(8888); // 终端打印如下信息 console.log(&apos;Server running at http://127.0.0.1:8888/&apos;);以上代码我们完成了一个可以工作的 HTTP 服务器。 使用 node 命令执行以上的代码： node server.js Server running at http://127.0.0.1:8888/接下来，打开浏览器访问 http://127.0.0.1:8888/，你会看到一个写着 “Hello World”的网页。 分析Node.js 的 HTTP 服务器： 第一行请求（require）Node.js 自带的 http 模块，并且把它赋值给 http 变量。 接下来我们调用 http 模块提供的函数： createServer 。这个函数会返回 一个对象，这个对象有一个叫做 listen 的方法，这个方法有一个数值参数， 指定这个 HTTP 服务器监听的端口号。 NPM 使用介绍NPM是随同NodeJS一起安装的包管理工具，能解决NodeJS代码部署上的很多问题，常见的使用场景有以下几种： 允许用户从NPM服务器下载别人编写的第三方包到本地使用。 允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用。 允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。 查看版本$ npm -v 6.10.3升级$ sudo npm install npm -g如果是 Window 系统使用以下命令即可： npm install npm -g使用淘宝镜像的命令： npm install -g cnpm --registry=https://registry.npm.taobao.org使用 npm 命令安装模块npm 安装 Node.js 模块语法格式如下： $ npm install &lt;Module Name&gt;以下实例，我们使用 npm 命令安装常用的 Node.js web框架模块 express: $ npm install express安装好之后，express 包就放在了工程目录下的 node_modules 目录中，因此在代码中只需要通过 require(‘express’) 的方式就好，无需指定第三方包路径。 var express = require(&apos;express&apos;);全局安装与本地安装npm 的包安装分为本地安装（local）、全局安装（global）两种，从敲的命令行来看，差别只是有没有-g而已，比如 npm install express # 本地安装 npm install express -g # 全局安装如果出现以下错误： npm err! Error: connect ECONNREFUSED 127.0.0.1:8087 解决办法为： $ npm config set proxy null本地安装 1.将安装包放在 ./node_modules 下（运行 npm 命令时所在的目录），如果没有 node_modules 目录，会在当前执行 npm 命令的目录下生成 node_modules 目录。 2.可以通过 require() 来引入本地安装的包。 全局安装 1.将安装包放在 /usr/local 下或者你 node 的安装目录。 2.可以直接在命令行里使用。 如果你希望具备两者功能，则需要在两个地方安装它或使用 npm link。接下来我们使用全局方式安装 express $ npm install express -g查看安装信息你可以使用以下命令来查看所有全局安装的模块： $ npm list -g ├─┬ cnpm@4.3.2 │ ├── auto-correct@1.0.0 │ ├── bagpipe@0.3.5 │ ├── colors@1.1.2 │ ├─┬ commander@2.9.0 │ │ └── graceful-readlink@1.0.1 │ ├─┬ cross-spawn@0.2.9 │ │ └── lru-cache@2.7.3 ……如果要查看某个模块的版本号，可以使用命令如下： $ npm list grunt projectName@projectVersion /path/to/project/folder └── grunt@0.4.1使用 package.jsonpackage.json 位于模块的目录下，用于定义包的属性。接下来让我们来看下 express 包的 package.json 文件，位于 node_modules/express/package.json 内容： Package.json 属性说明name - 包名。 version - 包的版本号。 description - 包的描述。 homepage - 包的官网 url 。 author - 包的作者姓名。 contributors - 包的其他贡献者姓名。 dependencies - 依赖包列表。如果依赖包没有安装，npm 会自动将依赖包安装在 node_module 目录下。 repository - 包代码存放的地方的类型，可以是 git 或 svn，git 可在 Github 上。 main - main 字段指定了程序的主入口文件，require(&apos;moduleName&apos;) 就会加载这个文件。这个字段的默认值是模块根目录下面的 index.js。 keywords - 关键字卸载模块我们可以使用以下命令来卸载 Node.js 模块。 $ npm uninstall express卸载后，你可以到 /node_modules/ 目录下查看包是否还存在，或者使用以下命令查看： $ npm ls更新模块$ npm update express搜索模块$ npm search express创建模块创建模块，package.json 文件是必不可少的。我们可以使用 NPM 生成 package.json 文件，生成的文件包含了基本的结果。 $ npm init This utility will walk you through creating a package.json file. It only covers the most common items, and tries to guess sensible defaults. See `npm help json` for definitive documentation on these fields and exactly what they do. Use `npm install &lt;pkg&gt; --save` afterwards to install a package and save it as a dependency in the package.json file. Press ^C at any time to quit. name: (node_modules) runoob # 模块名 version: (1.0.0) description: Node.js 测试模块(www.runoob.com) # 描述 entry point: (index.js) test command: make test git repository: https://github.com/runoob/runoob.git # Github 地址 keywords: author: license: (ISC) About to write to ……/node_modules/package.json: # 生成地址 { &quot;name&quot;: &quot;runoob&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;Node.js 测试模块(www.runoob.com)&quot;, …… } Is this ok? (yes) yes以上的信息，你需要根据你自己的情况输入。在最后输入 “yes” 后会生成 package.json 文件。 接下来我们可以使用以下命令在 npm 资源库中注册用户（使用邮箱注册）： $ npm adduser Username: mcmohd Password: Email: (this IS public) mcmohd@gmail.com接下来我们就用以下命令来发布模块： $ npm publish如果你以上的步骤都操作正确，你就可以跟其他模块一样使用 npm 来安装。 版本号使用NPM下载和发布代码时都会接触到版本号。NPM使用语义版本号来管理代码，这里简单介绍一下。 语义版本号分为X.Y.Z三位，分别代表主版本号、次版本号和补丁版本号。当代码变更时，版本号按以下原则更新。 如果只是修复bug，需要更新Z位。 如果是新增了功能，但是向下兼容，需要更新Y位。 如果有大变动，向下不兼容，需要更新X位。 版本号有了这个保证后，在申明第三方包依赖时，除了可依赖于一个固定版本号外，还可依赖于某个范围的版本号。例如”argv”: “0.0.x”表示依赖于0.0.x系列的最新版argv。 NPM支持的所有版本号范围指定方式可以查看官方文档。 NPM 常用命令使用npm help可查看所有命令。 NPM提供了很多命令，例如install和publish，使用npm help可查看所有命令。 使用npm help 可查看某条命令的详细帮助，例如npm help install。 在package.json所在目录下使用npm install . -g可先在本地安装当前命令行程序，可用于发布前的本地测试。 使用npm update 可以把当前目录下node_modules子目录里边的对应模块更新至最新版本。 使用npm update -g可以把全局安装的对应命令行程序更新至最新版。 使用npm cache clear可以清空NPM本地缓存，用于对付使用相同版本号发布新版本代码的人。 使用npm unpublish @可以撤销发布自己发布过的某个版本代码。 使用淘宝 NPM 镜像大家都知道国内直接使用 npm 的官方镜像是非常慢的，这里推荐使用淘宝 NPM 镜像。 淘宝 NPM 镜像是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步。 你可以使用淘宝定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: $ npm install -g cnpm --registry=https://registry.npm.taobao.org这样就可以使用 cnpm 命令来安装模块了： $ cnpm install [name]Node.js REPL(交互式解释器)Node.js REPL(Read Eval Print Loop:交互式解释器) 表示一个电脑的环境，类似 Window 系统的终端或 Unix/Linux shell，我们可以在终端中输入命令，并接收系统的响应。 Node 自带了交互式解释器，可以执行以下任务： 读取 - 读取用户输入，解析输入了Javascript 数据结构并存储在内存中。 执行 - 执行输入的数据结构 打印 - 输出结果 循环 - 循环操作以上步骤直到用户两次按下 ctrl-c 按钮退出。 Node 的交互式解释器可以很好的调试 Javascript 代码。 启动 Node 的终端：$ node Welcome to Node.js v12.9.0. Type &quot;.help&quot; for more information. &gt;简单的表达式运算这时我们就可以在 &gt; 后输入简单的表达式，并按下回车键来计算结果。 $ node &gt; 1 +4 5 &gt; 5 / 2 2.5 &gt; 3 * 6 18 &gt; 4 - 1 3 &gt; 1 + ( 2 * 3 ) - 4 3 &gt;使用变量你可以将数据存储在变量中，并在你需要的时候使用它。 变量声明需要使用 var 关键字，如果没有使用 var 关键字变量会直接打印出来。 使用 var 关键字的变量可以使用 console.log() 来输出变量。 $ node &gt; x = 10 10 &gt; var y = 10 undefined &gt; x + y 20 &gt; console.log(&quot;Hello World&quot;) Hello World undefined &gt; console.log(&quot;www.runoob.com&quot;) www.runoob.com undefined多行表达式Node REPL 支持输入多行表达式，这就有点类似 JavaScript。接下来让我们来执行一个 do-while 循环： $ node &gt; var x = 0 undefined &gt; do { ... x++; ... console.log(&quot;x: &quot; + x); ... } while ( x &lt; 5 ); x: 1 x: 2 x: 3 x: 4 x: 5 undefined &gt;… 三个点的符号是系统自动生成的，你回车换行后即可。Node 会自动检测是否为连续的表达式。 下划线(_)变量你可以使用下划线(_)获取上一个表达式的运算结果： $ node &gt; var x = 10 undefined &gt; var y = 20 undefined &gt; x + y 30 &gt; var sum = _ undefined &gt; console.log(sum) 30 undefined &gt;REPL 命令 ctrl + c - 退出当前终端。 ctrl + c 按下两次 - 退出 Node REPL。 ctrl + d - 退出 Node REPL. 向上/向下 键 - 查看输入的历史命令 tab 键 - 列出当前命令 .help - 列出使用命令 .break - 退出多行表达式 .clear - 退出多行表达式 .save filename - 保存当前的 Node REPL 会话到指定文件 .load filename - 载入当前 Node REPL 会话的文件内容。 停止 REPL前面我们已经提到按下两次 ctrl + c 键就能退出 REPL: $ node &gt; (^C again to quit) &gt; Node.js 回调函数Node.js 异步编程的直接体现就是回调。 异步编程依托于回调来实现，但不能说使用了回调后程序就异步化了。 回调函数在完成任务后就会被调用，Node 使用了大量的回调函数，Node 所有 API 都支持回调函数。 例如，我们可以一边读取文件，一边执行其他命令，在文件读取完成后，我们将文件内容作为回调函数的参数返回。这样在执行代码时就没有阻塞或等待文件 I/O 操作。这就大大提高了 Node.js 的性能，可以处理大量的并发请求。 回调函数一般作为函数的最后一个参数出现： function foo1(name, age, callback) { } function foo2(value, callback1, callback2) { }阻塞代码实例创建一个文件 input.txt ，内容如下： 菜鸟教程官网地址：www.runoob.com创建 main.js 文件, 代码如下： var fs = require(&quot;fs&quot;); var data = fs.readFileSync(&apos;input.txt&apos;); console.log(data.toString()); console.log(&quot;程序执行结束!&quot;);以上代码执行结果如下： $ node main.js 菜鸟教程官网地址：www.runoob.com 程序执行结束!非阻塞代码实例创建一个文件 input.txt ，内容如下： 菜鸟教程官网地址：www.runoob.com创建 main.js 文件, 代码如下： fs.readFile(&apos;input.txt&apos;, function (err, data) { if (err) return console.error(err); console.log(data.toString()); }); console.log(&quot;程序执行结束!&quot;);以上代码执行结果如下： $ node main.js 程序执行结束! 菜鸟教程官网地址：www.runoob.com以上两个实例我们了解了阻塞与非阻塞调用的不同。第一个实例在文件读取完后才执行完程序。 第二个实例我们不需要等待文件读取完，这样就可以在读取文件时同时执行接下来的代码，大大提高了程序的性能。 因此，阻塞是按顺序执行的，而非阻塞是不需要按顺序的，所以如果需要处理回调函数的参数，我们就需要写在回调函数内。 Node.js 事件循环 Node.js 是单进程单线程应用程序，但是因为 V8 引擎提供的异步执行回调接口，通过这些接口可以处理大量的并发，所以性能非常高。 Node.js 几乎每一个 API 都是支持回调函数的。 Node.js 基本上所有的事件机制都是用设计模式中观察者模式实现。 Node.js 单线程类似进入一个while(true)的事件循环，直到没有事件观察者退出，每个异步事件都生成一个事件观察者，如果有事件发生就调用该回调函数. 事件驱动程序Node.js 使用事件驱动模型，当web server接收到请求，就把它关闭然后进行处理，然后去服务下一个web请求。 当这个请求完成，它被放回处理队列，当到达队列开头，这个结果被返回给用户。 这个模型非常高效可扩展性非常强，因为webserver一直接受请求而不等待任何读写操作。（这也被称之为非阻塞式IO或者事件驱动IO） 在事件驱动模型中，会生成一个主循环来监听事件，当检测到事件时触发回调函数。 整个事件驱动的流程就是这么实现的，非常简洁。有点类似于观察者模式，事件相当于一个主题(Subject)，而所有注册到这个事件上的处理函数相当于观察者(Observer)。 Node.js 有多个内置的事件，我们可以通过引入 events 模块，并通过实例化 EventEmitter 类来绑定和监听事件，如下实例： // 引入 events 模块 var events = require(&apos;events&apos;); // 创建 eventEmitter 对象 var eventEmitter = new events.EventEmitter();以下程序绑定事件处理程序： // 绑定事件及事件的处理程序 eventEmitter.on(&apos;eventName&apos;, eventHandler);我们可以通过程序触发事件： // 触发事件 eventEmitter.emit(&apos;eventName&apos;);实例创建 main.js 文件，代码如下所示： // 引入 events 模块 var events = require(&apos;events&apos;); // 创建 eventEmitter 对象 var eventEmitter = new events.EventEmitter(); // 创建事件处理程序 var connectHandler = function connected() { console.log(&apos;连接成功。&apos;); // 触发 data_received 事件 eventEmitter.emit(&apos;data_received&apos;); } // 绑定 connection 事件处理程序 eventEmitter.on(&apos;connection&apos;, connectHandler); // 使用匿名函数绑定 data_received 事件 eventEmitter.on(&apos;data_received&apos;, function(){ console.log(&apos;数据接收成功。&apos;); }); // 触发 connection 事件 eventEmitter.emit(&apos;connection&apos;); console.log(&quot;程序执行完毕。&quot;);接下来让我们执行以上代码： $ node main.js 连接成功。 数据接收成功。 程序执行完毕。Node 应用程序是如何工作的？在 Node 应用程序中，执行异步操作的函数将回调函数作为最后一个参数， 回调函数接收错误对象作为第一个参数。 接下来让我们来重新看下前面的实例，创建一个 input.txt ,文件内容如下： 菜鸟教程官网地址：www.runoob.com创建 main.js 文件，代码如下： var fs = require(&quot;fs&quot;); fs.readFile(&apos;input.txt&apos;, function (err, data) { if (err){ console.log(err.stack); return; } console.log(data.toString()); }); console.log(&quot;程序执行完毕&quot;);以上程序中 fs.readFile() 是异步函数用于读取文件。 如果在读取文件过程中发生错误，错误 err 对象就会输出错误信息。 如果没发生错误，readFile 跳过 err 对象的输出，文件内容就通过回调函数输出。 执行以上代码，执行结果如下： 程序执行完毕 菜鸟教程官网地址：www.runoob.com 接下来我们删除 input.txt 文件，执行结果如下所示： 程序执行完毕 Error: ENOENT, open &apos;input.txt&apos;因为文件 input.txt 不存在，所以输出了错误信息。 Node.js EventEmitterNode.js 所有的异步 I/O 操作在完成时都会发送一个事件到事件队列。 Node.js 里面的许多对象都会分发事件：一个 net.Server 对象会在每次有新连接时触发一个事件， 一个 fs.readStream 对象会在文件被打开的时候触发一个事件。 所有这些产生事件的对象都是 events.EventEmitter 的实例。 EventEmitter 类events 模块只提供了一个对象： events.EventEmitter。EventEmitter 的核心就是事件触发与事件监听器功能的封装。 你可以通过require(“events”);来访问该模块。 // 引入 events 模块 var events = require(&apos;events&apos;); // 创建 eventEmitter 对象 var eventEmitter = new events.EventEmitter();EventEmitter 对象如果在实例化时发生错误，会触发 error 事件。当添加新的监听器时，newListener 事件会触发，当监听器被移除时，removeListener 事件被触发。 下面我们用一个简单的例子说明 EventEmitter 的用法：//event.js 文件 var EventEmitter = require(&apos;events&apos;).EventEmitter; var event = new EventEmitter(); event.on(&apos;some_event&apos;, function() { console.log(&apos;some_event 事件触发&apos;); }); setTimeout(function() { event.emit(&apos;some_event&apos;); }, 1000); 执行结果如下： 运行这段代码，1 秒后控制台输出了 ‘some_event 事件触发’。其原理是 event 对象注册了事件 some_event 的一个监听器，然后我们通过 setTimeout 在 1000 毫秒以后向 event 对象发送事件 some_event，此时会调用some_event 的监听器。 $ node event.js some_event 事件触发 EventEmitter 的每个事件由一个事件名和若干个参数组成，事件名是一个字符串，通常表达一定的语义。对于每个事件，EventEmitter 支持 若干个事件监听器。 当事件触发时，注册到这个事件的事件监听器被依次调用，事件参数作为回调函数参数传递。 让我们以下面的例子解释这个过程： //event.js 文件 var events = require(&apos;events&apos;); var emitter = new events.EventEmitter(); emitter.on(&apos;someEvent&apos;, function(arg1, arg2) { console.log(&apos;listener1&apos;, arg1, arg2); }); emitter.on(&apos;someEvent&apos;, function(arg1, arg2) { console.log(&apos;listener2&apos;, arg1, arg2); }); emitter.emit(&apos;someEvent&apos;, &apos;arg1 参数&apos;, &apos;arg2 参数&apos;); 执行以上代码，运行的结果如下： $ node event.js listener1 arg1 参数 arg2 参数 listener2 arg1 参数 arg2 参数 以上例子中，emitter 为事件 someEvent 注册了两个事件监听器，然后触发了 someEvent 事件。 运行结果中可以看到两个事件监听器回调函数被先后调用。 这就是EventEmitter最简单的用法。 EventEmitter 提供了多个属性，如 on 和 emit。on 函数用于绑定事件函数，emit 属性用于触发一个事件。接下来我们来具体看下 EventEmitter 的属性介绍。 方法1. addListener(event, listener)为指定事件添加一个监听器到监听器数组的尾部。 2. on(event, listener)为指定事件注册一个监听器，接受一个字符串 event 和一个回调函数。 server.on(&apos;connection&apos;, function (stream) { console.log(&apos;someone connected!&apos;); });3. once(event, listener)为指定事件注册一个单次监听器，即 监听器最多只会触发一次，触发后立刻解除该监听器。 server.once(&apos;connection&apos;, function (stream) { console.log(&apos;Ah, we have our first user!&apos;); });4. removeListener(event, listener)移除指定事件的某个监听器，监听器必须是该事件已经注册过的监听器。 它接受两个参数，第一个是事件名称，第二个是回调函数名称。 var callback = function(stream) { console.log(&apos;someone connected!&apos;); }; server.on(&apos;connection&apos;, callback); // ... server.removeListener(&apos;connection&apos;, callback);5. removeAllListeners([event])移除所有事件的所有监听器， 如果指定事件，则移除指定事件的所有监听器。 6. setMaxListeners(n)默认情况下， EventEmitters 如果你添加的监听器超过 10 个就会输出警告信息。 setMaxListeners 函数用于提高监听器的默认限制的数量。 7. listeners(event)返回指定事件的监听器数组。 8. emit(event, [arg1], [arg2], […])按监听器的顺序执行执行每个监听器，如果事件有注册监听返回 true，否则返回 false。 类方法listenerCount(emitter, event)返回指定事件的监听器数量。 events.EventEmitter.listenerCount(emitter, eventName) //已废弃，不推荐 events.emitter.listenerCount(eventName) //推荐事件newListener event - 字符串，事件名称 listener - 处理事件函数 该事件在添加新监听器时被触发。 removeListener event - 字符串，事件名称 listener - 处理事件函数 从指定监听器数组中删除一个监听器。需要注意的是，此操作将会改变处于被删监听器之后的那些监听器的索引。 实例以下实例通过 connection（连接）事件演示了 EventEmitter 类的应用。 创建 main.js 文件，代码如下： var events = require(&apos;events&apos;); var eventEmitter = new events.EventEmitter(); // 监听器 #1 var listener1 = function listener1() { console.log(&apos;监听器 listener1 执行。&apos;); } // 监听器 #2 var listener2 = function listener2() { console.log(&apos;监听器 listener2 执行。&apos;); } // 绑定 connection 事件，处理函数为 listener1 eventEmitter.addListener(&apos;connection&apos;, listener1); // 绑定 connection 事件，处理函数为 listener2 eventEmitter.on(&apos;connection&apos;, listener2); var eventListeners = eventEmitter.listenerCount(&apos;connection&apos;); console.log(eventListeners + &quot; 个监听器监听连接事件。&quot;); // 处理 connection 事件 eventEmitter.emit(&apos;connection&apos;); // 移除监绑定的 listener1 函数 eventEmitter.removeListener(&apos;connection&apos;, listener1); console.log(&quot;listener1 不再受监听。&quot;); // 触发连接事件 eventEmitter.emit(&apos;connection&apos;); eventListeners = eventEmitter.listenerCount(&apos;connection&apos;); console.log(eventListeners + &quot; 个监听器监听连接事件。&quot;); console.log(&quot;程序执行完毕。&quot;);以上代码，执行结果如下所示： $ node main.js 2 个监听器监听连接事件。 监听器 listener1 执行。 监听器 listener2 执行。 listener1 不再受监听。 监听器 listener2 执行。 1 个监听器监听连接事件。 程序执行完毕。error 事件EventEmitter 定义了一个特殊的事件 error，它包含了错误的语义，我们在遇到 异常的时候通常会触发 error 事件。 当 error 被触发时，EventEmitter 规定如果没有响 应的监听器，Node.js 会把它当作异常，退出程序并输出错误信息。 我们一般要为会触发 error 事件的对象设置监听器，避免遇到错误后整个程序崩溃。例如： var events = require(&apos;events&apos;); var emitter = new events.EventEmitter(); emitter.emit(&apos;error&apos;); 运行时会显示以下错误： node.js:201 throw e; // process.nextTick error, or &apos;error&apos; event on first tick ^ Error: Uncaught, unspecified &apos;error&apos; event. at EventEmitter.emit (events.js:50:15) at Object.&lt;anonymous&gt; (/home/byvoid/error.js:5:9) at Module._compile (module.js:441:26) at Object..js (module.js:459:10) at Module.load (module.js:348:31) at Function._load (module.js:308:12) at Array.0 (module.js:479:10) at EventEmitter._tickCallback (node.js:192:40) 继承 EventEmitter大多数时候我们不会直接使用 EventEmitter，而是在对象中继承它。包括 fs、net、 http 在内的，只要是支持事件响应的核心模块都是 EventEmitter 的子类。 为什么要这样做呢？原因有两点： 首先，具有某个实体功能的对象实现事件符合语义， 事件的监听和发生应该是一个对象的方法。 其次 JavaScript 的对象机制是基于原型的，支持 部分多重继承，继承 EventEmitter 不会打乱对象原有的继承关系。 Node.js Buffer(缓冲区)JavaScript 语言自身只有字符串数据类型，没有二进制数据类型。 但在处理像TCP流或文件流时，必须使用到二进制数据。因此在 Node.js中，定义了一个 Buffer 类，该类用来创建一个专门存放二进制数据的缓存区。 在 Node.js 中，Buffer 类是随 Node 内核一起发布的核心库。Buffer 库为 Node.js 带来了一种存储原始数据的方法，可以让 Node.js 处理二进制数据，每当需要在 Node.js 中处理I/O操作中移动的数据时，就有可能使用 Buffer 库。原始数据存储在 Buffer 类的实例中。一个 Buffer 类似于一个整数数组，但它对应于 V8 堆内存之外的一块原始内存。 在v6.0之前创建Buffer对象直接使用new Buffer()构造函数来创建对象实例，但是Buffer对内存的权限操作相比很大，可以直接捕获一些敏感信息，所以在v6.0以后，官方文档里面建议使用 Buffer.from() 接口去创建Buffer对象。 Buffer 与字符编码Buffer 实例一般用于表示编码字符的序列，比如 UTF-8 、 UCS2 、 Base64 、或十六进制编码的数据。 通过使用显式的字符编码，就可以在 Buffer 实例与普通的 JavaScript 字符串之间进行相互转换。 const buf = Buffer.from(&apos;runoob&apos;, &apos;ascii&apos;); // 输出 72756e6f6f62 console.log(buf.toString(&apos;hex&apos;)); // 输出 cnVub29i console.log(buf.toString(&apos;base64&apos;));Node.js 目前支持的字符编码包括： ascii - 仅支持 7 位 ASCII 数据。如果设置去掉高位的话，这种编码是非常快的。 utf8 - 多字节编码的 Unicode 字符。许多网页和其他文档格式都使用 UTF-8 。 utf16le - 2 或 4 个字节，小字节序编码的 Unicode 字符。支持代理对（U+10000 至 U+10FFFF）。 ucs2 - utf16le 的别名。 base64 - Base64 编码。 latin1 - 一种把 Buffer 编码成一字节编码的字符串的方式。 binary - latin1 的别名。 hex - 将每个字节编码为两个十六进制字符。 创建 Buffer 类Buffer 提供了以下 API 来创建 Buffer 类： Buffer.alloc(size[, fill[, encoding]])： 返回一个指定大小的 Buffer 实例，如果没有设置 fill，则默认填满 0 Buffer.allocUnsafe(size)： 返回一个指定大小的 Buffer 实例，但是它不会被初始化，所以它可能包含敏感的数据 Buffer.allocUnsafeSlow(size) Buffer.from(array)： 返回一个被 array 的值初始化的新的 Buffer 实例（传入的 array 的元素只能是数字，不然就会自动被 0 覆盖） Buffer.from(arrayBuffer[, byteOffset[, length]])： 返回一个新建的与给定的 ArrayBuffer 共享同一内存的 Buffer。 Buffer.from(buffer)： 复制传入的 Buffer 实例的数据，并返回一个新的 Buffer 实例 Buffer.from(string[, encoding])： 返回一个被 string 的值初始化的新的 Buffer 实例 / 创建一个长度为 10、且用 0 填充的 Buffer。 const buf1 = Buffer.alloc(10); // 创建一个长度为 10、且用 0x1 填充的 Buffer。 const buf2 = Buffer.alloc(10, 1); // 创建一个长度为 10、且未初始化的 Buffer。 // 这个方法比调用 Buffer.alloc() 更快， // 但返回的 Buffer 实例可能包含旧数据， // 因此需要使用 fill() 或 write() 重写。 const buf3 = Buffer.allocUnsafe(10); // 创建一个包含 [0x1, 0x2, 0x3] 的 Buffer。 const buf4 = Buffer.from([1, 2, 3]); // 创建一个包含 UTF-8 字节 [0x74, 0xc3, 0xa9, 0x73, 0x74] 的 Buffer。 const buf5 = Buffer.from(‘tést’); // 创建一个包含 Latin-1 字节 [0x74, 0xe9, 0x73, 0x74] 的 Buffer。 const buf6 = Buffer.from(‘tést’, ‘latin1’); 写入缓冲区语法buf.write(string[, offset[, length]][, encoding])参数参数描述如下： string - 写入缓冲区的字符串。 offset - 缓冲区开始写入的索引值，默认为 0 。 length - 写入的字节数，默认为 buffer.length encoding - 使用的编码。默认为 ‘utf8’ 。 根据 encoding 的字符编码写入 string 到 buf 中的 offset 位置。 length 参数是写入的字节数。 如果 buf 没有足够的空间保存整个字符串，则只会写入 string 的一部分。 只部分解码的字符不会被写入。 返回值返回实际写入的大小。如果 buffer 空间不足， 则只会写入部分字符串。 实例buf = Buffer.alloc(256); len = buf.write(&quot;www.runoob.com&quot;); console.log(&quot;写入字节数 : &quot;+ len);执行以上代码，输出结果为： $node main.js 写入字节数 : 14从缓冲区读取数据读取 Node 缓冲区数据的语法如下所示：buf.toString([encoding[, start[, end]]])参数参数描述如下： encoding - 使用的编码。默认为 ‘utf8’ 。 start - 指定开始读取的索引位置，默认为 0。 end - 结束位置，默认为缓冲区的末尾。 返回解码缓冲区数据并使用指定的编码返回字符串。 实例buf = Buffer.alloc(26); for (var i = 0 ; i &lt; 26 ; i++) { buf[i] = i + 97; } console.log( buf.toString(&apos;ascii&apos;)); // 输出: abcdefghijklmnopqrstuvwxyz console.log( buf.toString(&apos;ascii&apos;,0,5)); // 输出: abcde console.log( buf.toString(&apos;utf8&apos;,0,5)); // 输出: abcde console.log( buf.toString(undefined,0,5)); // 使用 &apos;utf8&apos; 编码, 并输出: abcde执行以上代码，输出结果为： $ node main.js abcdefghijklmnopqrstuvwxyz abcde abcde abcde将 Buffer 转换为 JSON 对象语法buf.toJSON()当字符串化一个 Buffer 实例时，JSON.stringify() 会隐式地调用该 toJSON()。 返回值返回 JSON 对象。 实例const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]); const json = JSON.stringify(buf); // 输出: {&quot;type&quot;:&quot;Buffer&quot;,&quot;data&quot;:[1,2,3,4,5]} console.log(json); const copy = JSON.parse(json, (key, value) =&gt; { return value &amp;&amp; value.type === &apos;Buffer&apos; ? Buffer.from(value.data) : value; }); // 输出: &lt;Buffer 01 02 03 04 05&gt; console.log(copy);执行以上代码，输出结果为： {&quot;type&quot;:&quot;Buffer&quot;,&quot;data&quot;:[1,2,3,4,5]} &lt;Buffer 01 02 03 04 05&gt;缓冲区合并语法Buffer.concat(list[, totalLength])参数参数描述如下： list - 用于合并的 Buffer 对象数组列表。 totalLength - 指定合并后Buffer对象的总长度。 返回值返回一个多个成员合并的新 Buffer 对象。 实例var buffer1 = Buffer.from((&apos;菜鸟教程&apos;)); var buffer2 = Buffer.from((&apos;www.runoob.com&apos;)); var buffer3 = Buffer.concat([buffer1,buffer2]); console.log(&quot;buffer3 内容: &quot; + buffer3.toString());执行以上代码，输出结果为： buffer3 内容: 菜鸟教程www.runoob.com缓冲区比较语法Node Buffer 比较的函数语法如下所示, 该方法在 Node.js v0.12.2 版本引入 buf.compare(otherBuffer);参数参数描述如下： otherBuffer - 与 buf 对象比较的另外一个 Buffer 对象。 返回值返回一个数字，表示 buf 在 otherBuffer 之前，之后或相同。 实例var buffer1 = Buffer.from(&apos;ABC&apos;); var buffer2 = Buffer.from(&apos;ABCD&apos;); var result = buffer1.compare(buffer2); if(result &lt; 0) { console.log(buffer1 + &quot; 在 &quot; + buffer2 + &quot;之前&quot;); }else if(result == 0){ console.log(buffer1 + &quot; 与 &quot; + buffer2 + &quot;相同&quot;); }else { console.log(buffer1 + &quot; 在 &quot; + buffer2 + &quot;之后&quot;); }执行以上代码，输出结果为： ABC在ABCD之前拷贝缓冲区语法buf.copy(targetBuffer[, targetStart[, sourceStart[, sourceEnd]]]) targetBuffer - 要拷贝的 Buffer 对象。 targetStart - 数字, 可选, 默认: 0 sourceStart - 数字, 可选, 默认: 0 sourceEnd - 数字, 可选, 默认: buffer.length 返回值没有返回值。 实例var buf1 = Buffer.from(&apos;abcdefghijkl&apos;); var buf2 = Buffer.from(&apos;RUNOOB&apos;); //将 buf2 插入到 buf1 指定位置上 buf2.copy(buf1, 2); console.log(buf1.toString());执行以上代码，输出结果为： abRUNOOBijkl缓冲区裁剪Node 缓冲区裁剪语法如下所示： buf.slice([start[, end]])参数参数描述如下： start - 数字, 可选, 默认: 0 end - 数字, 可选, 默认: buffer.length 返回值返回一个新的缓冲区，它和旧缓冲区指向同一块内存，但是从索引 start 到 end 的位置剪切。 实例 var buffer1 = Buffer.from(&apos;runoob&apos;); // 剪切缓冲区 var buffer2 = buffer1.slice(0,2); console.log(&quot;buffer2 content: &quot; + buffer2.toString()); 执行执行以上代码，输出结果为： buffer2 content: ru缓冲区长度buf.length;返回值返回 Buffer 对象所占据的内存长度。 实例 var buffer = Buffer.from(&apos;www.runoob.com&apos;); // 缓冲区长度 console.log(&quot;buffer length: &quot; + buffer.length);执行以上代码，输出结果为： buffer length: 14Node.js Stream(流)Stream 是一个抽象接口，Node 中有很多对象实现了这个接口。例如，对http 服务器发起请求的request 对象就是一个 Stream，还有stdout（标准输出）。 Node.js，Stream 有四种流类型： Readable - 可读操作。 Writable - 可写操作。 Duplex - 可读可写操作. Transform - 操作被写入数据，然后读出结果。 所有的 Stream 对象都是 EventEmitter 的实例。常用的事件有： data - 当有数据可读时触发。 end - 没有更多的数据可读时触发。 error - 在接收和写入过程中发生错误时触发。 finish - 所有数据已被写入到底层系统时触发。 从流中读取数据创建 input.txt 文件，内容如下： 菜鸟教程官网地址：www.runoob.com var fs = require(&quot;fs&quot;); var data = &apos;&apos;; // 创建可读流 var readerStream = fs.createReadStream(&apos;input.txt&apos;); // 设置编码为 utf8。 readerStream.setEncoding(&apos;UTF8&apos;); // 处理流事件 --&gt; data, end, and error readerStream.on(&apos;data&apos;, function(chunk) { data += chunk; }); readerStream.on(&apos;end&apos;,function(){ console.log(data); }); readerStream.on(&apos;error&apos;, function(err){ console.log(err.stack); }); console.log(&quot;程序执行完毕&quot;);以上程序会将 data 变量的数据写入到 output.txt 文件中。代码执行结果如下： $ node main.js 程序执行完毕 写入完成。查看 output.txt 文件的内容： $ cat output.txt 菜鸟教程官网地址：www.runoob.com管道流管道提供了一个输出流到输入流的机制。通常我们用于从一个流中获取数据并将数据传递到另外一个流中。 设置 input.txt 文件内容如下： 菜鸟教程官网地址：www.runoob.com 管道流操作实例创建 main.js 文件, 代码如下： var fs = require(&quot;fs&quot;); // 创建一个可读流 var readerStream = fs.createReadStream(&apos;input.txt&apos;); // 创建一个可写流 var writerStream = fs.createWriteStream(&apos;output.txt&apos;); // 管道读写操作 // 读取 input.txt 文件内容，并将内容写入到 output.txt 文件中 readerStream.pipe(writerStream); console.log(&quot;程序执行完毕&quot;);代码执行结果如下： $ node main.js 程序执行完毕查看 output.txt 文件的内容： $ cat output.txt 菜鸟教程官网地址：www.runoob.com 管道流操作实例链式流链式是通过连接输出流到另外一个流并创建多个流操作链的机制。链式流一般用于管道操作。 接下来我们就是用管道和链式来压缩和解压文件。 创建 compress.js 文件, 代码如下： var fs = require(&quot;fs&quot;); var zlib = require(&apos;zlib&apos;); // 压缩 input.txt 文件为 input.txt.gz fs.createReadStream(&apos;input.txt&apos;) .pipe(zlib.createGzip()) .pipe(fs.createWriteStream(&apos;input.txt.gz&apos;)); console.log(&quot;文件压缩完成。&quot;);代码执行结果如下： $ node compress.js 文件压缩完成。执行完以上操作后，我们可以看到当前目录下生成了 input.txt 的压缩文件 input.txt.gz。 接下来，让我们来解压该文件，创建 decompress.js 文件，代码如下： var fs = require(&quot;fs&quot;); var zlib = require(&apos;zlib&apos;); // 解压 input.txt.gz 文件为 input.txt fs.createReadStream(&apos;input.txt.gz&apos;) .pipe(zlib.createGunzip()) .pipe(fs.createWriteStream(&apos;input.txt&apos;)); console.log(&quot;文件解压完成。&quot;);代码执行结果如下： $ node decompress.js 文件解压完成。Node.js模块系统为了让Node.js的文件可以相互调用，Node.js提供了一个简单的模块系统。 模块是Node.js 应用程序的基本组成部分，文件和模块是一一对应的。换言之，一个 Node.js 文件就是一个模块，这个文件可能是JavaScript 代码、JSON 或者编译过的C/C++ 扩展。 创建模块在 Node.js 中，创建一个模块非常简单，如下我们创建一个 main.js 文件，代码如下: var hello = require(&apos;./hello&apos;); hello.world();以上实例中，代码 require(‘./hello’) 引入了当前目录下的 hello.js 文件（./ 为当前目录，node.js 默认后缀为 js）。 Node.js 提供了 exports 和 require 两个对象，其中 exports 是模块公开的接口，require 用于从外部获取一个模块的接口，即所获取模块的 exports 对象。 接下来我们就来创建 hello.js 文件，代码如下： exports.world = function() { console.log(&apos;Hello World&apos;); }在以上示例中，hello.js 通过 exports 对象把 world 作为模块的访问接口，在 main.js 中通过 require(‘./hello’) 加载这个模块，然后就可以直接访 问 hello.js 中 exports 对象的成员函数了。 有时候我们只是想把一个对象封装到模块中，格式如下： module.exports = function() { // ... }例如: //hello.js function Hello() { var name; this.setName = function(thyName) { name = thyName; }; this.sayHello = function() { console.log(&apos;Hello &apos; + name); }; }; module.exports = Hello;这样就可以直接获得这个对象了： //main.js var Hello = require(&apos;./hello&apos;); hello = new Hello(); hello.setName(&apos;BYVoid&apos;); hello.sayHello(); 模块接口的唯一变化是使用 module.exports = Hello 代替了exports.world = function(){}。 在外部引用该模块时，其接口对象就是要输出的 Hello 对象本身，而不是原先的 exports。 服务端的模块放在哪里也许你已经注意到，我们已经在代码中使用了模块了。像这样： var http = require(&quot;http&quot;); ... http.createServer(...);Node.js 中自带了一个叫做 http 的模块，我们在我们的代码中请求它并把返回值赋给一个本地变量。 这把我们的本地变量变成了一个拥有所有 http 模块所提供的公共方法的对象。 Node.js 的 require 方法中的文件查找策略如下： 由于 Node.js 中存在 4 类模块（原生模块和3种文件模块），尽管 require 方法极其简单，但是内部的加载却是十分复杂的，其加载优先级也各自不同。如下图所示： 从文件模块缓存中加载尽管原生模块与文件模块的优先级不同，但是都会优先从文件模块的缓存中加载已经存在的模块。 从原生模块加载原生模块的优先级仅次于文件模块缓存的优先级。require 方法在解析文件名之后，优先检查模块是否在原生模块列表中。以http模块为例，尽管在目录下存在一个 http/http.js/http.node/http.json 文件，require(“http”) 都不会从这些文件中加载，而是从原生模块中加载。 原生模块也有一个缓存区，同样也是优先从缓存区加载。如果缓存区没有被加载过，则调用原生模块的加载方式进行加载和执行。 从文件加载当文件模块缓存中不存在，而且不是原生模块的时候，Node.js 会解析 require 方法传入的参数，并从文件系统中加载实际的文件，加载过程中的包装和编译细节在前一节中已经介绍过，这里我们将详细描述查找文件模块的过程，其中，也有一些细节值得知晓。 require方法接受以下几种参数的传递： http、fs、path等，原生模块。 ./mod或../mod，相对路径的文件模块。 /pathtomodule/mod，绝对路径的文件模块。 mod，非原生模块的文件模块。 在路径 Y 下执行 require(X) 语句执行顺序： 1. 如果 X 是内置模块 a. 返回内置模块 b. 停止执行 2. 如果 X 以 &apos;/&apos; 开头 a. 设置 Y 为文件根路径 3. 如果 X 以 &apos;./&apos; 或 &apos;/&apos; or &apos;../&apos; 开头 a. LOAD_AS_FILE(Y + X) b. LOAD_AS_DIRECTORY(Y + X) 4. LOAD_NODE_MODULES(X, dirname(Y)) 5. 抛出异常 &quot;not found&quot; LOAD_AS_FILE(X) 1. 如果 X 是一个文件, 将 X 作为 JavaScript 文本载入并停止执行。 2. 如果 X.js 是一个文件, 将 X.js 作为 JavaScript 文本载入并停止执行。 3. 如果 X.json 是一个文件, 解析 X.json 为 JavaScript 对象并停止执行。 4. 如果 X.node 是一个文件, 将 X.node 作为二进制插件载入并停止执行。 LOAD_INDEX(X) 1. 如果 X/index.js 是一个文件, 将 X/index.js 作为 JavaScript 文本载入并停止执行。 2. 如果 X/index.json 是一个文件, 解析 X/index.json 为 JavaScript 对象并停止执行。 3. 如果 X/index.node 是一个文件, 将 X/index.node 作为二进制插件载入并停止执行。 LOAD_AS_DIRECTORY(X) 1. 如果 X/package.json 是一个文件, a. 解析 X/package.json, 并查找 &quot;main&quot; 字段。 b. let M = X + (json main 字段) c. LOAD_AS_FILE(M) d. LOAD_INDEX(M) 2. LOAD_INDEX(X) LOAD_NODE_MODULES(X, START) 1. let DIRS=NODE_MODULES_PATHS(START) 2. for each DIR in DIRS: a. LOAD_AS_FILE(DIR/X) b. LOAD_AS_DIRECTORY(DIR/X) NODE_MODULES_PATHS(START) 1. let PARTS = path split(START) 2. let I = count of PARTS - 1 3. let DIRS = [] 4. while I &gt;= 0, a. if PARTS[I] = &quot;node_modules&quot; CONTINUE b. DIR = path join(PARTS[0 .. I] + &quot;node_modules&quot;) c. DIRS = DIRS + DIR d. let I = I - 1 5. return DIRSexports 和 module.exports 的使用 如果要对外暴露属性或方法，就用 exports 就行，要暴露对象(类似class，包含了很多属性和方法)，就用 module.exports。 Node.js 函数在JavaScript中，一个函数可以作为另一个函数的参数。我们可以先定义一个函数，然后传递，也可以在传递参数的地方直接定义函数。 Node.js中函数的使用与Javascript类似，举例来说，你可以这样做： function say(word) { console.log(word); } function execute(someFunction, value) { someFunction(value); } execute(say, &quot;Hello&quot;);以上代码中，我们把 say 函数作为execute函数的第一个变量进行了传递。这里传递的不是 say 的返回值，而是 say 本身！ 这样一来， say 就变成了execute 中的本地变量 someFunction ，execute可以通过调用 someFunction() （带括号的形式）来使用 say 函数。 当然，因为 say 有一个变量， execute 在调用 someFunction 时可以传递这样一个变量。 匿名函数我们可以把一个函数作为变量传递。但是我们不一定要绕这个”先定义，再传递”的圈子，我们可以直接在另一个函数的括号中定义和传递这个函数： function execute(someFunction, value) { someFunction(value); }我们在 execute 接受第一个参数的地方直接定义了我们准备传递给 execute 的函数。 用这种方式，我们甚至不用给这个函数起名字，这也是为什么它被叫做匿名函数 。 函数传递是如何让HTTP服务器工作的带着这些知识，我们再来看看我们简约而不简单的HTTP服务器： var http = require(&quot;http&quot;); http.createServer(function(request, response) { response.writeHead(200, {&quot;Content-Type&quot;: &quot;text/plain&quot;}); response.write(&quot;Hello World&quot;); response.end(); }).listen(8888);现在它看上去应该清晰了很多：我们向 createServer 函数传递了一个匿名函数。 用这样的代码也可以达到同样的目的： var http = require(&quot;http&quot;); function onRequest(request, response) { response.writeHead(200, {&quot;Content-Type&quot;: &quot;text/plain&quot;}); response.write(&quot;Hello World&quot;); response.end(); } http.createServer(onRequest).listen(8888);Node.js 路由我们要为路由提供请求的 URL 和其他需要的 GET 及 POST 参数，随后路由需要根据这些数据来执行相应的代码。 因此，我们需要查看 HTTP 请求，从中提取出请求的 URL 以及 GET/POST 参数。这一功能应当属于路由还是服务器（甚至作为一个模块自身的功能）确实值得探讨，但这里暂定其为我们的HTTP服务器的功能。 我们需要的所有数据都会包含在 request 对象中，该对象作为 onRequest() 回调函数的第一个参数传递。但是为了解析这些数据，我们需要额外的 Node.JS 模块，它们分别是 url 和 querystring 模块。 url.parse(string).query | url.parse(string).pathname | | | | | ------ ------------------- http://localhost:8888/start?foo=bar&amp;hello=world --- ----- | | | | querystring.parse(queryString)[&quot;foo&quot;] | | querystring.parse(queryString)[&quot;hello&quot;]当然我们也可以用 querystring 模块来解析 POST 请求体中的参数，稍后会有演示。 现在我们来给 onRequest() 函数加上一些逻辑，用来找出浏览器请求的 URL 路径： server.js 文件代码： var http = require(&quot;http&quot;); var url = require(&quot;url&quot;); function start() { function onRequest(request, response) { var pathname = url.parse(request.url).pathname; console.log(&quot;Request for &quot; + pathname + &quot; received.&quot;); response.writeHead(200, {&quot;Content-Type&quot;: &quot;text/plain&quot;}); response.write(&quot;Hello World&quot;); response.end(); } http.createServer(onRequest).listen(8888); console.log(&quot;Server has started.&quot;); } exports.start = start;好了，我们的应用现在可以通过请求的 URL 路径来区别不同请求了–这使我们得以使用路由（还未完成）来将请求以 URL 路径为基准映射到处理程序上。 在我们所要构建的应用中，这意味着来自 /start 和 /upload 的请求可以使用不同的代码来处理。稍后我们将看到这些内容是如何整合到一起的。 现在我们可以来编写路由了，建立一个名为 router.js 的文件，添加以下内容：router.js function route(pathname) { console.log(&quot;About to route a request for &quot; + pathname); } exports.route = route;如你所见，这段代码什么也没干，不过对于现在来说这是应该的。在添加更多的逻辑以前，我们先来看看如何把路由和服务器整合起来。 我们的服务器应当知道路由的存在并加以有效利用。我们当然可以通过硬编码的方式将这一依赖项绑定到服务器上，但是其它语言的编程经验告诉我们这会是一件非常痛苦的事，因此我们将使用依赖注入的方式较松散地添加路由模块。 首先，我们来扩展一下服务器的 start() 函数，以便将路由函数作为参数传递过去，server.js 文件代码如下 var http = require(&quot;http&quot;); var url = require(&quot;url&quot;); function start(route) { function onRequest(request, response) { var pathname = url.parse(request.url).pathname; console.log(&quot;Request for &quot; + pathname + &quot; received.&quot;); route(pathname); response.writeHead(200, {&quot;Content-Type&quot;: &quot;text/plain&quot;}); response.write(&quot;Hello World&quot;); response.end(); } http.createServer(onRequest).listen(8888); console.log(&quot;Server has started.&quot;); } exports.start = start;同时，我们会相应扩展 index.js，使得路由函数可以被注入到服务器中： index.js 文件代码： var server = require(&quot;./server&quot;); var router = require(&quot;./router&quot;); server.start(router.route);在这里，我们传递的函数依旧什么也没做。 如果现在启动应用（node index.js，始终记得这个命令行），随后请求一个URL，你将会看到应用输出相应的信息，这表明我们的HTTP服务器已经在使用路由模块了，并会将请求的路径传递给路由： $ node index.js Server has started. 以上输出已经去掉了比较烦人的 /favicon.ico 请求相关的部分。 浏览器访问 http://127.0.0.1:8888/，输出结果如下：Node.js 全局对象avaScript 中有一个特殊的对象，称为全局对象（Global Object），它及其所有属性都可以在程序的任何地方访问，即全局变量。 在浏览器 JavaScript 中，通常 window 是全局对象， 而 Node.js 中的全局对象是 global，所有全局变量（除了 global 本身以外）都是 global 对象的属性。 在 Node.js 我们可以直接访问到 global 的属性，而不需要在应用中包含它。 全局对象与全局变量global 最根本的作用是作为全局变量的宿主。按照 ECMAScript 的定义，满足以下条 件的变量是全局变量： 在最外层定义的变量； 全局对象的属性； 隐式定义的变量（未定义直接赋值的变量）。 你定义一个全局变量时，这个变量同时也会成为全局对象的属性，反之亦然。需要注 意的是，在 Node.js 中你不可能在最外层定义变量，因为所有用户代码都是属于当前模块的， 而模块本身不是最外层上下文。 注意： 最好不要使用 var 定义变量以避免引入全局变量，因为全局变量会污染命名空间，提高代码的耦合风险。 __filename_filename 表示当前正在执行的脚本的文件名。它将输出文件所在位置的绝对路径，且和命令行参数所指定的文件名不一定相同。 如果在模块中，返回的值是模块文件的路径。 实例创建文件 main.js ，代码如下所示： // 输出全局变量 __filename 的值 console.log( __filename );执行 main.js 文件，代码如下所示: $ node main.js /web/com/runoob/nodejs/main.js__dirname__dirname 表示当前执行脚本所在的目录。 实例 创建文件 main.js ，代码如下所示： // 输出全局变量 __dirname 的值 console.log( __dirname );执行 main.js 文件，代码如下所示: $ node main.js /web/com/runoob/nodejssetTimeout(cb, ms)setTimeout(cb, ms) 全局函数在指定的毫秒(ms)数后执行指定函数(cb)。：setTimeout() 只执行一次指定函数。 返回一个代表定时器的句柄值。 实例 创建文件 main.js ，代码如下所示： function printHello(){ console.log( &quot;Hello, World!&quot;); } // 两秒后执行以上函数 setTimeout(printHello, 2000);执行 main.js 文件，代码如下所示: $ node main.js Hello, World! clearTimeout(t)clearTimeout( t ) 全局函数用于停止一个之前通过 setTimeout() 创建的定时器。 参数 t 是通过 setTimeout() 函数创建的定时器。 实例创建文件 main.js ，代码如下所示： function printHello(){ console.log( &quot;Hello, World!&quot;); } // 两秒后执行以上函数 var t = setTimeout(printHello, 2000); // 清除定时器 clearTimeout(t);执行 main.js 文件，代码如下所示: $ node main.js setInterval(cb, ms)setInterval(cb, ms) 全局函数在指定的毫秒(ms)数后执行指定函数(cb)。 返回一个代表定时器的句柄值。可以使用 clearInterval(t) 函数来清除定时器。 setInterval() 方法会不停地调用函数，直到 clearInterval() 被调用或窗口被关闭。 实例创建文件 main.js ，代码如下所示： function printHello(){ console.log( &quot;Hello, World!&quot;); } // 两秒后执行以上函数 setInterval(printHello, 2000);执行 main.js 文件，代码如下所示: $ node main.js Hello, World! Hello, World! Hello, World! Hello, World! Hello, World! Hello, World! Hello, World!以上程序每隔两秒就会输出一次”Hello, World!”，且会永久执行下去，直到你按下 ctrl + c 按钮。 consoleconsole 用于提供控制台标准输出，它是由 Internet Explorer 的 JScript 引擎提供的调试工具，后来逐渐成为浏览器的实施标准。 Node.js 沿用了这个标准，提供与习惯行为一致的 console 对象，用于向标准输出流（stdout）或标准错误流（stderr）输出字符。 console.log([data][, …])向标准输出流打印字符并以换行符结束。该方法接收若干 个参数，如果只有一个参数，则输出这个参数的字符串形式。如果有多个参数，则 以类似于C 语言 printf() 命令的格式输出。 console.info([data][, …])该命令的作用是返回信息性消息，这个命令与console.log差别并不大，除了在chrome中只会输出文字外，其余的会显示一个蓝色的惊叹号。 console.error([data][, …])输出错误消息的。控制台在出现错误时会显示是红色的叉子。 console.warn([data][, …])输出警告消息。控制台出现有黄色的惊叹号。 console.dir(obj[, options])用来对一个对象进行检查（inspect），并以易于阅读和打印的格式显示。 console.time(label)输出时间，表示计时开始。 console.timeEnd(label)结束时间，表示计时结束。 console.trace(message[, …])当前执行的代码在堆栈中的调用路径，这个测试函数运行很有帮助，只要给想测试的函数里面加入 console.trace 就行了。 console.assert(value[, message][, …])用于判断某个表达式或变量是否为真，接收两个参数，第一个参数是表达式，第二个参数是字符串。只有当第一个参数为false，才会输出第二个参数，否则不会有任何结果。 console.log()：向标准输出流打印字符并以换行符结束。console.log 接收若干 个参数，如果只有一个参数，则输出这个参数的字符串形式。如果有多个参数，则 以类似于C 语言 printf() 命令的格式输出。 第一个参数是一个字符串，如果没有 参数，只打印一个换行。 console.log(&apos;Hello world&apos;); console.log(&apos;byvoid%diovyb&apos;); console.log(&apos;byvoid%diovyb&apos;, 1991); 运行结果为： Hello world byvoid%diovyb byvoid1991iovyb console.error()：与console.log() 用法相同，只是向标准错误流输出。 console.trace()：向标准错误流输出当前的调用栈。 console.trace(); 运行结果为： Trace: at Object.&lt;anonymous&gt; (/home/byvoid/consoletrace.js:1:71) at Module._compile (module.js:441:26) at Object..js (module.js:459:10) at Module.load (module.js:348:31) at Function._load (module.js:308:12) at Array.0 (module.js:479:10) at EventEmitter._tickCallback (node.js:192:40) console.info(&quot;程序开始执行：&quot;); var counter = 10; console.log(&quot;计数: %d&quot;, counter); console.time(&quot;获取数据&quot;); // // 执行一些代码 // console.timeEnd(&apos;获取数据&apos;); console.info(&quot;程序执行完毕。&quot;) 程序开始执行： 计数: 10 获取数据: 0ms 程序执行完毕processprocess 是一个全局变量，即 global 对象的属性。 它用于描述当前Node.js 进程状态的对象，提供了一个与操作系统的简单接口。通常在你写本地命令行程序的时候，少不了要 和它打交道。下面将会介绍 process 对象的一些最常用的成员方法。 exit当进程准备退出时触发。 beforeExit当 node 清空事件循环，并且没有其他安排时触发这个事件。通常来说，当没有进程安排时 node 退出，但是 ‘beforeExit’ 的监听器可以异步调用，这样 node 就会继续执行。 uncaughtException当一个异常冒泡回到事件循环，触发这个事件。如果给异常添加了监视器，默认的操作（打印堆栈跟踪信息并退出）就不会发生。 Signal 事件当进程接收到信号时就触发。信号列表详见标准的 POSIX 信号名，如 SIGINT、SIGUSR1 等。 实例创建文件 main.js ，代码如下所示： process.on(&apos;exit&apos;, function(code) { // 以下代码永远不会执行 setTimeout(function() { console.log(&quot;该代码不会执行&quot;); }, 0); console.log(&apos;退出码为:&apos;, code); }); console.log(&quot;程序执行结束&quot;);执行 main.js 文件，代码如下所示: $ node main.js 程序执行结束 退出码为: 0退出状态码 状态码 名称&amp;描述 1 Uncaught Fatal Exception 有未捕获异常，并且没有被域或 uncaughtException 处理函数处理。 2 Unused 保留 3 Internal JavaScript Parse Error JavaScript的源码启动 Node 进程时引起解析错误。非常罕见，仅会在开发 Node 时才会有。 4 Internal JavaScript Evaluation Failure JavaScript 的源码启动 Node 进程，评估时返回函数失败。非常罕见，仅会在开发 Node 时才会有。 5 Fatal Error V8 里致命的不可恢复的错误。通常会打印到 stderr ，内容为： FATAL ERROR 6 Non-function Internal Exception Handler 未捕获异常，内部异常处理函数不知为何设置为on-function，并且不能被调用。 7 Internal Exception Handler Run-Time Failure 未捕获的异常， 并且异常处理函数处理时自己抛出了异常。例如，如果 process.on(‘uncaughtException’) 或 domain.on(‘error’) 抛出了异常。 8 Unused 保留 9 Invalid Argument 可能是给了未知的参数，或者给的参数没有值。 10 Internal JavaScript Run-Time Failure JavaScript的源码启动 Node 进程时抛出错误，非常罕见，仅会在开发 Node 时才会有。 12 Invalid Debug Argument 设置了参数–debug 和/或 –debug-brk，但是选择了错误端口。 128 Signal Exits 如果 Node 接收到致命信号，比如SIGKILL 或 SIGHUP，那么退出代码就是128 加信号代码。这是标准的 Unix 做法，退出信号代码放在高位。 Process 属性Process 提供了很多有用的属性，便于我们更好的控制系统的交互： 序号 属性&amp;描述 1 stdout 标准输出流。 2 stderr 标准错误流。 3 stdin 标准输入流。 4 argv argv 属性返回一个数组，由命令行执行脚本时的各个参数组成。它的第一个成员总是node，第二个成员是脚本文件名，其余成员是脚本文件的参数。 5 execPath 返回执行当前脚本的 Node 二进制文件的绝对路径。 6 execArgv 返回一个数组，成员是命令行下执行脚本时，在Node可执行文件与脚本文件之间的命令行参数。 7 env 返回一个对象，成员为当前 shell 的环境变量 8 exitCode 进程退出时的代码，如果进程优通过 process.exit() 退出，不需要指定退出码。 9 version Node 的版本，比如v0.10.18。 10 versions 一个属性，包含了 node 的版本和依赖. 11 config 一个包含用来编译当前 node 执行文件的 javascript 配置选项的对象。它与运行 ./configure 脚本生成的 “config.gypi” 文件相同。 12 pid 当前进程的进程号。 13 title 进程名，默认值为”node”，可以自定义该值。 14 arch 当前 CPU 的架构：’arm’、’ia32’ 或者 ‘x64’。 15 platform 运行程序所在的平台系统 ‘darwin’, ‘freebsd’, ‘linux’, ‘sunos’ 或 ‘win32’ 16 mainModule require.main 的备选方法。不同点，如果主模块在运行时改变，require.main可能会继续返回老的模块。可以认为，这两者引用了同一个模块。 实例创建文件 main.js ，代码如下所示： // 输出到终端 process.stdout.write(&quot;Hello World!&quot; + &quot;\n&quot;); // 通过参数读取 process.argv.forEach(function(val, index, array) { console.log(index + &apos;: &apos; + val); }); // 获取执行路径 console.log(process.execPath); // 平台信息 console.log(process.platform);执行 main.js 文件，代码如下所示: $ node main.js Hello World! 0: node 1: /web/www/node/main.js /usr/local/node/0.10.36/bin/node darwin方法参考手册Process 提供了很多有用的方法，便于我们更好的控制系统的交互： 序号 方法 &amp; 描述 1 abort() 这将导致node触发abort事件。会让node退出并生成一个核心文件 2 chdir(directory) 改变当前工作进程的目录，如果操作失败抛出异常。 3 cwd() 返回当前进程的工作目录 4 exit([code]) 使用指定的 code 结束进程。如果忽略，将会使用 code 0。 5 getgid() 取进程的群组标识（参见 getgid(2)）。获取到得时群组的数字 id，而不是名字. 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 6 setgid(id) 设置进程的群组标识（参见 setgid(2)）。可以接收数字 ID 或者群组名。如果指定了群组名，会阻塞等待解析为数字 ID 。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 7 getuid() 获取进程的用户标识(参见 getuid(2))。这是数字的用户 id，不是用户名。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 8 setuid(id) 设置进程的用户标识（参见setuid(2)）。接收数字 ID或字符串名字。果指定了群组名，会阻塞等待解析为数字 ID 。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 9 getgroups() 返回进程的群组 iD 数组。POSIX 系统没有保证一定有，但是 node.js 保证有。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 10 setgroups(groups) 设置进程的群组 ID。这是授权操作，所以你需要有 root 权限，或者有 CAP_SETGID 能力。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 11 initgroups(user, extra_group) 读取 /etc/group ，并初始化群组访问列表，使用成员所在的所有群组。这是授权操作，所以你需要有 root 权限，或者有 CAP_SETGID 能力。 注意：这个函数仅在 POSIX 平台上可用(例如，非Windows 和 Android)。 12 kill(pid[, signal]) 发送信号给进程. pid 是进程id，并且 signal 是发送的信号的字符串描述。信号名是字符串，比如 ‘SIGINT’ 或 ‘SIGHUP’。如果忽略，信号会是 ‘SIGTERM’。 13 memoryUsage() 返回一个对象，描述了 Node 进程所用的内存状况，单位为字节。 14 nextTick(callback) 一旦当前事件循环结束，调用回调函数。 15 umask([mask]) 设置或读取进程文件的掩码。子进程从父进程继承掩码。如果mask 参数有效，返回旧的掩码。否则，返回当前掩码。 16 uptime() 返回 Node 已经运行的秒数。 17 hrtime() 返回当前进程的高分辨时间，形式为 [seconds, nanoseconds]数组。它是相对于过去的任意事件。该值与日期无关，因此不受时钟漂移的影响。主要用途是可以通过精确的时间间隔，来衡量程序的性能。 你可以将之前的结果传递给当前的 process.hrtime() ，会返回两者间的时间差，用来基准和测量时间间隔。 实例创建文件 main.js ，代码如下所示： // 输出当前目录 console.log(&apos;当前目录: &apos; + process.cwd()); // 输出当前版本 console.log(&apos;当前版本: &apos; + process.version); // 输出内存使用情况 console.log(process.memoryUsage());执行 main.js 文件，代码如下所示: $ node main.js 当前目录: /web/com/runoob/nodejs 当前版本: v0.10.36 { rss: 12541952, heapTotal: 4083456, heapUsed: 2157056 }Node.js 常用工具util 是一个Node.js 核心模块，提供常用函数的集合，用于弥补核心JavaScript 的功能 过于精简的不足。 util.inheritsutil.inherits(constructor, superConstructor) 是一个实现对象间原型继承的函数。 JavaScript 的面向对象特性是基于原型的，与常见的基于类的不同。JavaScript 没有提供对象继承的语言级别特性，而是通过原型复制来实现的。 在这里我们只介绍 util.inherits 的用法，示例如下]]></content>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩物丧志]]></title>
    <url>%2F2019%2F08%2F26%2F%E7%8E%A9%E7%89%A9%E4%B8%A7%E5%BF%97%2F</url>
    <content type="text"><![CDATA[曾闻古训戒禽荒，一鹤谁知便丧邦。荥泽当时遍磷火，可能骑鹤返仙乡？ 谨以此致自己被玩儿的岁月!]]></content>
  </entry>
  <entry>
    <title><![CDATA[mac使用brew update无反应,解决方案更新源]]></title>
    <url>%2F2019%2F08%2F23%2Fmac%E4%BD%BF%E7%94%A8brew-update%E6%97%A0%E5%8F%8D%E5%BA%94-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9B%B4%E6%96%B0%E6%BA%90%2F</url>
    <content type="text"><![CDATA[原因 资源访问太慢 解决方案更新源 使用中科大的镜像替换默认源第一步，替换brew.git cd &quot;$(brew --repo)&quot; git remote set-url origin https://mirrors.ustc.edu.cn/brew.git第二步：替换homebrew-core.git cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git最后验证 brew update]]></content>
      <tags>
        <tag>brew</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac中node卸载与安装]]></title>
    <url>%2F2019%2F08%2F23%2FMac%E4%B8%ADnode%E5%8D%B8%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[卸载在终端依次输入以下命令 sudo npm uninstall npm -g sudo rm -rf /usr/local/lib/node /usr/local/lib/node_modules /var/db/receipts/org.nodejs.* sudo rm -rf /usr/local/include/node /Users/$USER/.npm sudo rm /usr/local/bin/node sudo rm /usr/local/share/man/man1/node.1 sudo rm /usr/local/lib/dtrace/node.d验证是否成功node -v //not found npm -v //not found安装brew search node brew install node遇到的坑Error: The `brew link` step did not complete successfully The formula built, but is not symlinked into /usr/local Could not symlink share/doc/node/lldb_commands.py Target /usr/local/share/doc/node/lldb_commands.py already exists. You may want to remove it: rm &apos;/usr/local/share/doc/node/lldb_commands.py&apos; To force the link and overwrite all conflicting files: brew link --overwrite node To list all files that would be deleted: brew link --overwrite --dry-run node解决办法rm &apos;/usr/local/share/doc/node/lldb_commands.py&apos; brew link --overwrite node]]></content>
      <tags>
        <tag>node</tag>
        <tag>npm</tag>
        <tag>brew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL InnoDB MRR 优化]]></title>
    <url>%2F2019%2F08%2F19%2FMySQL-InnoDB-MRR-%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MRR 是 Multi-Range Read 的简写，目的是减少磁盘随机访问，将随机访问转化为较为顺序的访问。适用于 range/ref/eq_ref 类型的查询。 实现原理： 在二级索引查找后，根据得到的主键到聚簇索引找出需要的数据。 二级索引查找得到的主键的顺序是不确定的，因为二级索引的顺序与聚簇索引的顺序不一定一致； 如果没有 MRR，那么在聚簇索引查找时就可能出现乱序读取数据页，这对于机械硬盘是及其不友好的。 MRR 的优化方式： 将查找到的二级索引键值放在一个缓存中； 将缓存中的键值按照 主键 进行排序； 根据排序后的主键去聚簇索引访问实际的数据文件。 当优化器使用了 MRR 时，执行计划的 Extra 列会出现 “Using MRR” 。 如果查询使用的二级索引的顺序本身与结果集的顺序一致，那么使用 MRR 后需要对得到的结果集进行排序。 如何使用使用 MRR 还可以减少缓冲池中页被替换的次数，批量处理对键值的查询操作。 可以使用命令 select @@optimizer_switch; 查看是否开启了 MRR： index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=off,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on,use_invisible_indexes=off,skip_scan=onmrr_cost_based=on 表示是否通过 cost based 的方式来选择使用 MRR 。 用 set @@optimizer_switch=’mrr=on/off’; 命令开启或关闭 MRR 。 select @@read_rnd_buffer_size ; 参数用来控制键值的缓冲区大小，默认 256K，当大于该参数值时，执行器根据主键对已缓存的数据进行排序，然后再通过主键取得行数据。]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据库回表与覆盖索引]]></title>
    <url>%2F2019%2F08%2F19%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9B%9E%E8%A1%A8%E4%B8%8E%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[回表oracle中有有一个很明显的物理ID,叫做rowid,这个是全局唯一的.rowid是物理结构上的,在每条记录insert到数据库中时都会有一个唯一的物理记录. 回表:当查询数据时,在索引中查找到该行索引后,根据索引获得该行的rowid,根据rowid再查询表中数据就是回表. demo SELECT c1,c2,c3 FROM TEST_TABLE WHERE c1=1 如果c1列建立了索引。首先会从索引里面根据c1=1 查找出c1的rowid，然后根据rowid去找到数据块中对应的数据，将c1，c2,c3 查出来。 如果c1没有建立索引，那就需要进行全表扫描。到数据块中扫描一番，这样性能不好。覆盖索引(不需要回表操作)MySQL可以利用索引返回SELECT 列表中的字段。而不必根据索引再次读取数据文件。包含所有满足查询需要的数据的索引成为覆盖索引(Covering Index)。也就是平时所说的不需要回表操作。 判断标准： 在查询前面使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询。 也就是说当前查询所需要的数据直接就可以在索引里面查得到。有时候根据业务，建立多列索引，使用覆盖索引，可以取得相当好的性能优化 回表为什么慢回表是磁盘IO,而磁盘IO远远慢于内存操作主要原因还是随机IO，增加了磁盘 IO的次数，所以mysql针对大表扫描都有MRR优化策略. 参考]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>回表</tag>
        <tag>覆盖索引</tag>
        <tag>数据库</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git回滚已经PUSH的内容]]></title>
    <url>%2F2019%2F08%2F09%2Fgit%E5%9B%9E%E6%BB%9A%E5%B7%B2%E7%BB%8FPUSH%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[git status git log git reset –hard 21e5af0fd58a456caa2727934e0aaf00 git push origin 分支 –force 参考]]></content>
      <tags>
        <tag>git</tag>
        <tag>回滚</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[母子分离日]]></title>
    <url>%2F2019%2F08%2F03%2F%E6%AF%8D%E5%AD%90%E5%88%86%E7%A6%BB%E6%97%A5%2F</url>
    <content type="text"><![CDATA[早上跟媳妇儿视频,看到了镜头中的儿子.小家伙又长高了,真可爱!7:30过一点儿,媳妇儿要去上班了,儿子眼中有了我从未见过的东西!我第一次发现这家伙眼中流露出的不舍!小家伙开始要找妈妈了!第一次对妈妈的离去表现出了不情愿!看来以后上班得偷偷去了! 昨天升级Ipaid,今早上班发现还在升级中,果断拔掉数据线!升级失败ipaid也开不了机了!郁闷,点背喝凉水都塞牙缝!本想潇洒的翘个二郎腿不知是桌子太矮还是大腿太长亦或自己太傻逼,竟然磕到了桌子上!疼死老子了!IPAID也开不机!自己捣鼓了一下没搞定 去四楼找修手机的看看!这哥们蒙我!”你这一点儿都开不了机”要价70真贵!好吧我太穷…6s换电池好点儿的要130!毅然不修走了!看到他的电脑竟然能识别我的IPAID,感觉我自己也能搞定. 回来查资料首先home键跟电源键一块儿按住约5秒进入维护模式itunes 更新到最新版点击恢复…傻瓜示下一步 中间遇见未知错误2015,崩溃难道我真的要花70块钱亦或大老远跑趟西单?!当然不,以锲而不舍的程序员造bug精神,继续上网找资料! 哎呦! 有可能是数据线的问题!好吧我的这跟山寨线有时候还真是充不上电换根试试!好了…人生处处有惊喜啊…]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[曲突徙薪之恩泽,焦头烂额为上客]]></title>
    <url>%2F2019%2F07%2F20%2F%E6%9B%B2%E7%AA%81%E5%BE%99%E8%96%AA%E4%B9%8B%E6%81%A9%E6%B3%BD-%E7%84%A6%E5%A4%B4%E7%83%82%E9%A2%9D%E4%B8%BA%E4%B8%8A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[曲突徙薪客有过主人者(1),见其灶直突(2),旁有积薪(3),客谓主人:”更为曲突(4),远徙其薪(5),不者且有火患”.主人默然不应.俄而果失火,邻里共救之,幸而得息.于是杀牛置酒,谢其邻人,灼烂者在于上行(6),余各以功次坐,而不录言曲突者(7),人谓主人曰:”向使听客之言(8),不费牛酒,终亡火患.今论功而请宾,曲突徙薪亡恩泽,焦头烂额为上客耶?”主人乃寤而请之(9). ――节选自班固《汉书·霍光传》 注释⑴过：拜访，探望。 ⑵突：烟囱。 ⑶薪：柴草。 ⑷更：改。 ⑸徙(xǐ)：搬走。 ⑹灼：烧炙。烂：烧伤。行(háng)：座次。 ⑺录：采，取，这里有邀请的意思。 ⑻向使：向：原先。使：假使。 ⑼寤(wù)：醒悟，明白 有一位客人到主人家拜访，见主人家炉灶的烟囱是直的，旁边又堆有柴薪，这位客人便对主人说：‘您的烟囱应改为弯曲的，并将柴薪搬到远处去，不然的话，将会发生火灾！’主人默然，不予理会。不久，主人家果然失火，邻居们共同抢救，幸而将火扑灭。于是，主人家杀牛摆酒，对邻居表示感谢，在救火中烧伤的被请到上座，其余则各按出力大小依次就坐，却没有请那位建议他改弯烟囱的人。有人对这家主人说：‘当初要是听了那位客人的劝告，就不用杀牛摆酒，终究不会有火灾。如今论功请客酬谢，建议改弯烟囱、移走柴薪的人没有功劳，而在救火时被烧得焦头烂额的人才是上客吗？’主人这才醒悟，将那位客人请来。 “曲突徙薪之恩泽,焦头烂额为上客”：建议改弯烟囱、移走柴薪的人没有功劳，而在救火时被烧得焦头烂额的人成了上客]]></content>
      <categories>
        <category>成语</category>
      </categories>
      <tags>
        <tag>成语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim教程]]></title>
    <url>%2F2019%2F06%2F11%2Fvim%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[linux下 输入命令 vimtutor 基本练习vim使用的区域(块)选择ctrl+v 块选择字符选择v 小写的v字符选择行选择shift+v 大写V行选择vim的模式esc 进入普通模式 shift + : 进入命令模式 普通模式下 a 在光标尾插入 普通模式下 i 在光标首插入 vim包括一般模式,插入模式,命令模式,区域选择在一般模式下, 选择的区域包括固定黑色,闪动黑色,闪动黑色表示光标位置. 在区域选择的情况下,d删除选择的区域,y复制选择的区域,p 粘贴选择的区域,小写p在当前行的下一行粘贴.大写P在当前行 的上一行粘贴.在当前行首添加字符ddd命令模式下 .s/^/ddd/g 在第三行到第六行添加字符ddd3,6s/^/ddd/g在当前行尾添加字符ddd.s/$/ddd/g]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[猪宝起名记]]></title>
    <url>%2F2019%2F05%2F31%2F%E7%8C%AA%E5%AE%9D%E5%8F%96%E5%90%8D%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[接上篇&lt;&lt;猪宝历险记&gt;&gt; 好吧孩子,这几天除了担心你,还在忙活着一件事给你取名.爸爸妈妈想了很多,在此一一记录.希望你长大后更能理解自己名字的由来. 从怀孕开始爸妈就开始想你的名字 卓恩 这是第一个爸妈意向很大的名字,由来英文JUNE(六月)谐音而来你是六月来到的爸妈身边,即有此意.对了爸爸一开始想的是朱恩后来还是你二叔觉得卓恩好.爸爸也觉得这名字不错,可由于你一向喜欢韩国欧巴的妈妈觉得这名字有点韩流,就给否了. 给予 这是爸爸意向差不多最大的一个名字,有三重意思:1是希望你可以做个能帮助别人的人,2是谐音爸妈的家乡冀豫,3是希望你健健康康可思来想去还是怕以后小朋友叫不好你的名字老叫你gei yu!又给否了 春风 小名小野 出自野火烧不尽,春风吹又生!这名字是爸爸一厢情愿你妈特别反对,觉得老掉牙!可爸爸觉得挺好,朴素,辨识度高寓意也好,希望你以后坚韧,茁壮成长!一场春风一场暖,长大当个大暖男!当然咱们家你妈说了算. 由于火爆当下的抖音,爸妈又刷出了几个名字 予桐 锦汐 若凌都由于意向不大没有采纳. 中途还有个搞笑的小名叫抖爆,解释为抖音爆款! 言归正传,如何起个好名字? 爸爸跟妈妈的理解为 寓意好,(女诗经 男楚辞 文论语 武周易 )最好有点出处. 响亮 郎朗上口.最好都为二声,或第一个字四声,第二个字二声. 好写 不要生僻字,最好小学毕业的人都认知. 独特 最好叫的人不多,名字毕竟是个IP.好多人都叫则辨识度太低. 作为传统的中国人,还是希望跟五行八卦相配合的. 出处:李白 侠客行 响亮:都为二声,跟咱这姓氏配合也算郎朗上口. 好写:小学毕业肯定认识,笔画也不多. 独特:好吧奶奶给你上社保的时候就有工作人员夸,说这名字好,之前没见过,爸爸不甘寂寞,上省公安厅查,全省独一份! 跟你的八字五行还是比较配合的,网上测了一下99分. 小名是你10岁的小叔叔起的.家里人一致认为这个名字好听,爸爸也觉得这名字干净,纯洁,有力量. 中途也有人建议花钱找大师起名.爸爸不信这一套!爸爸认为孩子的名字最好是父母来起.因为没有人比父母对你的名字更上心.经过父母深思熟虑起的名字是最有力量的.这个是啥大师都比不了的. 参考的资料有: 给孩子起名字 如何给孩子起名？ 象形字典 象形字典]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[猪宝历险记]]></title>
    <url>%2F2019%2F05%2F28%2F%E7%8C%AA%E5%AE%9D%E5%8E%86%E9%99%A9%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[接上篇&lt;&lt;喜迎猪宝&gt;&gt; 爸爸刚安顿好妈妈就有一个年长一些的护士将爸爸叫到了一旁,说”孩子刚来时好好的,大约过了半小时出现了呼吸急促的现象,正常新生儿一般每分钟40次左右,你家孩子都70次了”. 爸爸当时就蒙了!担心你有危险!询问护士该如何做,此时护士叫来了新生儿科主任,主任将你抱到了新生儿科,与爸爸的焦急相比,主任倒没那么担心,爸爸心中暗责主任的冷血,反过来想也许你这种情况也很常见! 进了新生儿科你就被抱到了NICU,爸爸此时还没有真正看过你的脸,抱你的途中怕你着凉脸一直是遮着的接待爸爸的是李芳医生,人很和气!她给爸爸介绍说出现这种情况的原因可能是因为剖腹产,新生儿由于没有经过产道挤压,肺没有充分扩张,还以为自己在妈妈肚子里,还有一个原因是巨大儿有可能出现这种情况,而孩子正好两条你都符合! 说了一些治疗手段,主要是给你吸氧,增加肺部扩张,若疗效不好就要打一种刺激肺部扩张的药…… 途中医生给爸爸看了你的一个小视频,看的爸爸很是揪心,视频中你呼吸急促,鼻翼抖动明显,脸色发紫,胸腔随着每次呼吸而剧烈抖动.孩子你在跟命运抗争,为生存而奋斗!爸爸在心里给你鼓劲,一定要好起来啊,小家伙. 爸爸向医生要你的视频,医生答应的很好,可最后也没有给爸爸! 医生跟爸爸交代这种情况有三天到五天的危险期!一般一周也就好的差不多了!爸爸好像有了底气,但又担心危险期的你!可能是看出了爸爸的担心,医生又跟爸爸说前48个小时最危险,过了就问题不大.其实最危险的是前24小时…… 整个治理过程家长都不能见到孩子,每周一三五可以向医生询问病情,每天09:00-11:00 16:00-17:00 可以去送奶. 安顿好了你,爸爸就回去照顾妈妈.最可怜的还是你妈,10月怀胎一朝分娩.中途各种心酸暂且不表.看着临床的孩子陆续抱过来,而你又迟迟不到妈妈身边,爸爸知道得告诉妈妈了,不过爸爸耍了个小心机,没有把你的真实情况说明,只是说你有点儿呼吸急促,医生让观察观察. 当天晚上爸爸一夜不眠!想到视频中你的样子,想到你正在跟命运的抗争,想到你在里面吃啥,哭了有人哄吗……爸爸静静的望着隔壁6楼的窗户,想着里面的你当时的境况,五味杂陈…… 第二天早上爸爸去儿科送湿纸巾,刚送完,就收到了你姥爷的电话,询问爸爸为什么车门是开着的? 爸爸这是才意识到刚才拿东西时,忘记了关车门!原来人在遇到大事时真的会六神无主.爸爸要向你学习,与命运抗争,当下给自己鼓劲儿,我不能倒,我还有孩子在NICU,媳妇儿还需要照顾,我必须振作,加油,一切都会好起来的. 你也是真争气,医生告诉爸爸昨天下午,你就呼吸正常了,不过还是要观察几天.至此爸爸跟妈妈总算松了口气.]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[上线准备流程]]></title>
    <url>%2F2019%2F04%2F18%2F%E4%B8%8A%E7%BA%BF%E5%87%86%E5%A4%87%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[未来校长之家上线准备流程准备 搭建生产环境(PHP,Mysql,Redis等已完成) 移动端与web端准备上线包 清除生产垃圾数据 核心流程图 注意事项 点击查看接口调用地址 超管生成基础参数非必须 超管权限程序不可修改]]></content>
  </entry>
  <entry>
    <title><![CDATA[喜迎猪宝]]></title>
    <url>%2F2019%2F03%2F26%2F%E5%96%9C%E8%BF%8E%E7%8C%AA%E5%AE%9D%2F</url>
    <content type="text"><![CDATA[2019年三月十三日农历二月初七今天是个特殊的日子,阳光明媚,春风和煦,孩子你来到了我们身边. 在过了预产期三天后,在我们得知你有可能超过八斤之后,在你妈妈日渐痛苦(因为你太沉了,累的你妈妈睡不好觉,腰疼,翻身困难,吃饭泛酸水等等),我和你妈还是想顺产,但当你超过预产期又有可能因为羊水浑浊而感染时,我们坚定的认为得刨了! 三月十二号早上我跟你妈还有你芳芳姨一块去人民医院咨询住院事宜,很幸运,接待的医生很热情!当天还有二十几个出院的!医院床位充足,医生在了解了你的情况之后表示:随时可以住院! 中午我跟你妈美美的吃了一顿你奶奶做的家常饭!你妈又在你姥姥家洗了个澡,姥姥还给你妈搓的澡!下午我们就拎着大包小包住院了!住院过程很顺利,不过爸妈还是来的有点儿晚,这时候双人间已经满了,没办法我们只能住三人间,害的你妈跟我抱怨”应该上午来的时候办手续”! 我们住在了三床,隔壁2床是一个顺产的小姑娘!环境说不上多不好,但跟家里比是差多了,我跟你妈都有些不适应!医生警告”不允许离开三层住院部”,可在爸爸在楼下买东西看到别的出来吃饭的孕妇后,果断的决定带你妈回家吃饭,可能的话还想在家过夜. 护士很负责任,吃饭途中就给我们打了电话,询问去处,答曰:吃饭!护士严厉警告:不许出楼,答曰:是是是,前后打了三四通电话,老爸真有点后悔带你妈回家! 上午妈妈进了手术室,在一片手忙脚乱中(包括准备手术铺盖,准备你的抱被…..)等待的过程是漫长的,爸爸想了很多,各种担心,担心妈妈下不了手术台,担心你有啥问题……爸爸长这么大,经历了大大小小无数次考试,但从来没有像今天这样紧张! 大约过了一个半小时吧!姥姥突然叫爸爸过去抱你,原来你跟妈妈不是一个门出来,而爸爸一直在妈妈进去的门口等!你被护士抱着交给了爸爸,你是那么的软,抱被半遮着你的脸,爸爸看不真切你的脸,倒是伸出的小手给了个特写,又细又长,帅! 爸爸把你抱到楼上观察室观察,(前一天睡前妈妈还特意跟爸爸交代一定要亲手抱你上楼,然后寸步不离的看着你,洗澡等,目的就是怕把你弄丢!上手术室前又交代了一遍,伟大的妈妈.你长大可得要对你妈好啊!)然后就下楼等你妈妈出来. 你妈终于出手术室了,豆大的一滴泪挂在她的眼角,她没有一声呻吟,表情坚毅!爸爸从心里佩服你妈,她是个坚强的女子!女儿本柔,为母则刚!爸爸还是第一次从你妈妈身上感触到这种坚强! 这次迎接你到来的有,姥姥,姥爷,奶奶,妈妈,爸爸.因为妈妈是剖腹产,出手术室后要换床,需要人抬,咱们家来人少,主要也是没经验.所以抬妈妈有些困难,还好隔壁床有两位叔叔帮忙一块儿抬的妈妈.他们都是咱们家的大恩人,虽然爸爸也记不清他们了,但爸爸希望你做个好人,做个助人为乐的人.顺便涨了个经验,生孩子家里可得多来点儿人!]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel学习笔记]]></title>
    <url>%2F2019%2F02%2F22%2FLaravel%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[阅读文档官方文档(本文以5.7为例)Laravel文档 安装环境(Laravel Homestead)Laravel Homestead文档]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[过年请假]]></title>
    <url>%2F2019%2F02%2F13%2F%E8%BF%87%E5%B9%B4%E8%AF%B7%E5%81%87%2F</url>
    <content type="text"><![CDATA[年关将至，抢票不易!然小禾佑我，得票一张。 忧喜交集,喜与孕妻朝欢暮,又忧公司业务急! 遂背Mac,随时call我! 恭祝:新春吉祥如意，事事顺达，阖家幸福。]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[homestead 安装PHP mongo 扩展]]></title>
    <url>%2F2018%2F12%2F17%2Fhomestead-%E5%AE%89%E8%A3%85PHP-mongo-%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[解决痛点: homestead多个PHP版本,某个版本安装mongo扩展1. 进入虚拟机vagrant ssh2. 切换到管理员sudo su 3. 查看PHP版本路径// 选择你要安装的PHP版本(我是PHP5.6) php --ini 或 find / -name php.ini 返回 /etc/php/7.1/cli/php.ini /etc/php/7.1/fpm/php.ini /etc/php/7.2/cli/php.ini /etc/php/7.2/fpm/php.ini /etc/php/7.0/cli/php.ini /etc/php/7.0/fpm/php.ini /etc/php/5.6/cli/php.ini /etc/php/5.6/fpm/php.ini4. 进入工作目录(这个随意,我习惯进入/etc/php/5.6)cd /etc/php/5.65.下载php mongo扩展git clone https://github.com/mongodb/mongo-php-driver-legacy.git6. 进入下载的目录cd mongo-php-driver-legacy/7. 选择对应的扩展// 参考文档 https://docs.mongodb.com/ecosystem/drivers/php/#drivers git branch -a git checkout v1.68. 编译PHP的mongo扩展//（不同php版本的情况下phpize版本不同） /usr/bin/phpize5.6 //（这里边也需要根据情况指定php-config的版本，且和phpize的版本保持一致。） ./configure --with-php-config=/usr/bin/php-config5.6 make &amp;&amp; make install 编译完成后，mongo的php扩展在module目录中，它的文件名是mongo.so* 9. 查看php的extension_dir/usr/bin/php5.6 -i|grep extension_dir 返回 extension_dir =&gt; /usr/lib/php/20131226 =&gt; /usr/lib/php/20131226 这说明php的扩展目录是/usr/lib/php/20131226 或者你用phpinfo()输出一个页面，在里面找extension_dir也可以找到* 10. 把mongo.so扩展模块移入php扩展目录中mv ./module/mongo.so /usr/lib/php/20131226 注意，前提要求当前工作目录是在刚才编译的mongo-php-driver-legacy目录中 11. 添加php配置文件的ini文件sudo touch /etc/php/5.6/fpm/conf.d/20-mongo.ini12. 使用vi编辑器写入如下内容vim /etc/php/5.6/fpm/conf.d/20-mongo.ini extension=mongo.so 记得使用vi编辑器时使用：wq命令保存 13. 重启PHPservice php5.6-fpm restart]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>homestead</tag>
        <tag>mongo</tag>
        <tag>php扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vagrant基本用法]]></title>
    <url>%2F2018%2F09%2F11%2FVagrant%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[官网: https://www.vagrantup.com/intro 介绍what is vagrant (流浪汉是什么)Introduction to Vagrant (流浪汉简介)Vagrant is a tool for building and managing virtual machine environments in a single workflow. With an easy-to-use workflow and focus on automaiton, Vagrant lowers development setup time, increases production parity,and makes the &quot;works on my machine&quot; excuse a relic of the past. if you are already familiar with the basics of Vagrant, the documentation provides a better reference build for all available features and internals. Vagrant是一种在单个工作流程中构建和管理虚拟环境的工具.通过易于使用的工 作流程并专注于自动化,Vagrant降低了开发环境的设置时间,提高了生产平价, 并使&quot;在我的假期上工作&quot;称为过去的遗留物. 如果您已经熟悉Vagrant的基础知识,那么该文档可为所有可用功能和内部提供 更好的参考构建.why Vagrant (为什么选择Vagrant)vagrant provides easy to configure,reproducible,and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team. To achieve its magic,Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox,VMware,AWS,or any other provider,Then,Industry-standard providioning tools such as shell scripts,Chef,or Puppet,can automatically install and configure software on the virtual machine. Vagrant 提供易于配置,可重复和便携的工作环境,基于行和标准技术构建,并由单一 一致的工作流程控制,以帮助您和您的团队最大限度地提高生成力和灵魂性. 为了实现其魔力,Vagrant站在巨人的肩膀上.在VirtualBox,VMware,AWS或 任何其他提供商之上配置计算机.然后,行业标准配置工具(如shell脚本,Chef或 Puppet)可以在虚拟机上自动安装和配置软件.For Developers (对于开发者)if you are a developer,Vagarnt will isolate dependencies and their configuration within a single disposable,consistent environment,without sacrificing any of the tools you are used to working with(editors,browsers,debuggers,etc.).Once you or someone else creates a single Vagrantfile,you just need to vagrant up and everything is installed and configured for you to work .Other members of your team create their development environments form the same configuration,so whether you are working on Linux,Mac OSX,or Windows,all your team members are running code in the same environment ,against the same dependencies,al configured the same way. Say goodbye to &quot;works on my machine&quot;bugs. 如果您是一位开发人员,Vagrant将在一个一致的环境中隔离依赖及其配置, 而不会牺牲您习惯使用的任何工具(编辑器,浏览器,调试器等).一旦您或其他人 创建了单个Vagrant文件,您只需要运行vagrant up命令安装并配置所有内容 即可使用.团队的其他成员使用相同的配置创建他们的开发环境,因此无论您是在 Linux,Mac OS X还是Windows上工作,您的所有团队成员都在同一环境中运行 代码,针对相同的依赖项,所有组件都配置相同办法.告别&quot;在我的机器上工作&quot;的 错误.For Operators (对于运维)if you are an operations engineer or DevOps engineer,Vagrant gives you a disposable environment and consisitent workflow for developing and testing infrastructure management scripts. you can quickly test things like shell scripts,Chef cookbooks, Puppet modules,and more using local virtualization such as VirtualBox or VMware.Then,with the same configuration,you can test these scripts on remote clouds such as AWS or RackSpace with the same workflow.Ditch your custom scripts to recycle EC2 instances,stop juggling SSH prompts to various machines, and start using Vagrant to bring sanity to your life. 如果你是运维工程师或者开发运维工程师,Vagrant为您提供一次性环境和一致的 工作流程,用于开发和测试基础架构管理脚本.您可以使用VirtualBox或VMware 等本地虚拟化快速测试shell脚本,Chef cookbook,Puppet模块等内容.然后 ,使用相同的配置,您可以使用相同的工作流在远程云(如AWS或RackSpace)上测试 这些脚本.抛弃自定义脚本以回收EC2实例,停止将SSH提示传递给各种计算机,并 开始使用Vagrant为您的生活带来理智.For Designers(对于设计)If you are a designer,Vagrant will automatically set everything up that is required for that web app in order for you to focus on doing what you do best:design.Once a developer configures Vagrant,you do not need to worry about how to get that app running ever again.No more bothering other developers to help you fix your environment so you can test designs.Just check out the code ,vagrant up,and start designing. 如果你是个设计师,Vagrant 将自动设置该web应用程序所需的所有内容,以便你 集中精力做你最擅长的事情:设计.当开发人员配置了一次Vagrant,你再也不用 担心怎样去运行应用程序.不必再打扰其他开发人员来帮助你修复环境,因此你能 测试你的设计.仅打出单词,vagrant up ,就可以开始设计了.For Everyone(对于任何人)Vagrant is designed for erveyone as the easiest and fastest way to create a virtualized environment! Vagrant 的设计对任何人来说都是最简单最快速的获取虚拟环境的方式.Vagrant vs. Other Software (Vagrant 与其他软件的对比)Vagrant is not the only tool to manage virtual machines and development environments.This section compares Vagrant to these other software choices. Vagrant 不是唯一管理虚拟机和开发环境的工具,本节将比较Vagrant与其他 软件以便选择. Due to the bias of the comparisons,we attempt to only use facts.If you find something that is invalid or out of date in the comparisons,please open an issue and we&apos;ll address it as soon as possible. 由于比较的偏颇,我们试图只用事实说话,在比较中假如你发现了无效的或者过期 的内容,请开启一个issue,我们将尽可能的处理它. Use the navigation on the left to read comparisons of Vagrant versus similar software. 使用左侧导航栏去阅读Vagrant与相似软件的比较CLI ToolsVagrant vs CLI ToolsVirtualization software like VirtualBox and VMware come with command line utilities for managing the lifecycle of machines on their platform.Many people make use of these utilties for managing the lifecycle of machines on their platform.Many people make use of these utilities to write their own automation. Vagrant actually uses many of these utilties internally. 虚拟化软件如VirtualBox和VMware,带有命令行工具来管理平台上的机器的生命 周期.许多人使用这些工具来写他们自己的自动化程序.Vagrant实际上在内部用了 很多这样的工具. The difference between these CLI tool and Vagrant is that Vagrant builds on top of these utilties in a number of ways while still providing a consistent workflow.Vagrant supports multiple provisioners to setup the machine,automatic SSH setup, creating HTTP tunnels into your development environment,and more. All of these can be configured using a single simple configuration file. 这些CLI工具与Vagrant的区别在于,Vagrant以多种方式在这些实用程序之上 构建,同时仍然提供一致的工作流.Vagrant 支持多种同步文件夹类型,设置机器 的多个提供程序 自动SSH设置 创建多开发环境中的HTTP隧道等.所有这些都可以 使用一个简单的配置文件来配置. Vagrant still has a number of improvements over manual scripting even if you ignore all the higher-level features Vagrant provides. The command-line utilities provided by vitualization software often change each version or have subtle bugs with workarounds. Vagrant automatically detects the version,uses the correct flags, can work around known issues.So if you&apos;re using one version of VirtualBox and a co-worker is using a different version, Vagrant will still work consistently. Vagrant在手动脚本方面仍有许多改进.即使你忽略了流浪汉提供的所有高级特征. 虚拟化软件提供的命令行工具经常改变每个版本或有变通方法的细微错误. 流浪汉自动检测版本,使用正确的标志,能围绕已知问题工作. 因此假如你使用一个版本的VirtualBox而另一个同事使用不同的版本,Vagrant 仍然可以一致工作. For highly-specifil workflows that don&apos;t change often.it can still be beneficial to maintain custom scripts .Vagrant is tageted at building development environments but some advanced users still use the ClI tools underneath to do other manual things. 对于不经常改变的高度特定的工作流,维护自定义脚本仍然是有益的.Vagrant 的目标是构建开发环境,但是一些高级用户仍然使用下面的CLI工具来完成 其他手动操作.DockerVagrant vs. DockerVagrant is a tool focused on providing a consistent development environment workflow across multiple operating systems.Docker is a container management that can consistently run sofeware as long as a containerization system exists. Vagrant是一个专注于跨多个操作系统提供一致的开发环境工作流的工具. Docker是一种容器管理,只要存在容器化系统,就可以始终如一地运行软件. Containers are generally more lightweight than virtual machines,so starting and stopping containers is extremely fast. Most common development machines don&apos;t have a containerization system built-in, and Docker uses a virtual machine with Linux installed to provide that. 容器一般比虚拟机更轻量级,因此开启或停止容器是非常快的.大多数常见的 开发及其没有内置化的容器系统,Doker使用安装了Linux的虚拟机来提供这 一点. Currently,Docker lacks support for certain operating systems(such as BSD).if you target deployment is one of these operating systems,Docker will not provide the same prodution parity as tool like Vagrant.Vagrant will allow you to run a Windows development environment on Mac or Linux,as well. 目前,Docker缺乏对某些操作系统(如:BSD)的支持.如果你的目标是部署 这些操作系统之一,那么Docker不会像Vagrant一样提供相同的一致产品. Vagrant允许你在Mac或Linux上运行Windows开发环境. For microservice heavy environments,Docker can be attractive because you can easily start a single Docker VM and start many containers above that very quickly.This is a good use case for Docker.Vagrant can do this as well with the Docker provider.A primary benefit for Vagrant is a consistent workflow but there are many cases where a pure-Docker workflow does make sense. Both Vagrant and Docker have a vast library of community-contributed &quot;images&quot;or&quot;boxes&quot;to choose from. 对于微服务繁重的环境,Docker可能很有吸引力,因为您可以单个Docker VM 并快速启动多个容器.这是Docker的一个很好的用例.Vagrant也可以 使用Docker提供程序执行此操作.Vagrant的主要好处是一致的工作流程, 但在很多情况下,纯Docker工作流程确实有意义. Vagrant和Docker都拥有庞大的社区贡献&quot;图像&quot;或&quot;盒子&quot;库供您选择.TerraformVagrant vs. Terraform]]></content>
      <categories>
        <category>虚拟机</category>
      </categories>
      <tags>
        <tag>vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F07%2F27%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[日常操作命令查看当前所在的工作目录的全路径pwd[root@localhost ~]# pwd /root查看当前系统的时间date[root@localhost ~]# date +%Y-%m-%d date +%Y-%m-%d --date=&quot;-1 day&quot; #加减也可以 month | year date -s &quot;2016-07-28 16:12:00&quot; ## 修改时间查看有谁在线(哪些人登陆了服务器)who 查看当前在线 last 查看最近的登陆历史记录关机/重启关机(必须用root用户) shutdown -h now ## 立刻关机 shutdown -h +10 ## 10分钟以后关机 shutdown -h 12:00:00 ## 12点整的时候关机 halt # 等于立刻关机 重启 shutdown -r now reboot # 等于立刻重启清屏clear ## 或者用快捷键 Ctrl + 1退出当前进程Ctrl + c ##有些程序也可以用q键退出挂起当前进程Ctrl + z ## 进程会挂起到后台 bg jobid ## 进程在后台继续执行 fg jobid ## 让进程回到前台echo相当于Java中System.out.println(userName) a=&quot;test&quot; echo a ## a echo $a ## test目录操作查看目录信息ls / ## 查看根目录下的子节点(文件夹和文件)信息 ls -al ## -a是显示隐藏文件 -l是以更详细的列表形式显示 ls -l ## 有一个别名: ll 可以直接使用ll&lt;是两个L&gt;切换工作目录cd ~ ##切换都用户主目录 cd - ##切换上次所在的目录 cd 什么都不带,则回到用户的主目录创建文件夹mkdir aaa ## 这是相对路径的写法 mkdir /data ## 这是绝对路径的写法 mkdir -p aaa/bbb/ccc ## 级联创建目录删除文件夹rmdir aaa ##可以删除空目录 rm -r aaa ## 可以把aaa整个文件夹及其中的所有子节点全部删除 rm -rf aaa ## 强制删除aaa修改文件夹名称mv aaa boy mv本质上是移动 mv install.log aaa/ 将当前目录下的install.log移动到aaa文件夹中去 rename 可以用来批量更改文件名 [root@localhost aaa]# ll total 0 -rw-r--r--. 1 root root 0 Jul 28 17:33 1.txt -rw-r--r--. 1 root root 0 Jul 28 17:33 2.txt -rw-r--r--. 1 root root 0 Jul 28 17:33 3.txt [root@localhost aaa]# rename .txt .txt.bak * [root@localhost aaa]# ll total 0 -rw-r--r--. 1 root root 0 Jul 28 17:33 1.txt.bak -rw-r--r--. 1 root root 0 Jul 28 17:33 2.txt.bak -rw-r--r--. 1 root root 0 Jul 28 17:33 3.txt.bak]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五笔口诀]]></title>
    <url>%2F2018%2F07%2F25%2F%E4%BA%94%E7%AC%94%E5%8F%A3%E8%AF%80%2F</url>
    <content type="text"><![CDATA[五笔字型最直观,依照笔画把码编;键名汉字打四下,基本字根请照搬;一二三末取四码,顺序拆分大优先;不足四码要注意,交叉识别补后边 86版五笔字根1区横起笔11G 王旁青头戋（兼）五一12F 土士二干十寸雨13D 大犬三（羊）古石厂14S 木丁西15A 工戈草头右框七2区竖起笔21H 目具上止卜虎皮22J 日早两竖与虫依23K 口与川，字根稀24L 田甲方框四车力25M 山由贝，下框几3区撇起笔31T 禾竹一撇双人立，反文条头共三一32R 白手看头三二斤33E 月彡（衫）乃用家衣底34W 人和八，三四里35Q 金勺缺点无尾鱼，犬旁留儿一点夕，氏无七（妻）4区点起笔41Y 言文方广在四一，高头一捺谁人去42U 立辛两点六门疒43I 水旁兴头小倒立44O 火业头，四点米45P 之字军盖道建底，摘礻（示）衤（衣）5区折起笔51N 已半巳满不出己，左框折尸心和羽52B 子耳了也框向上53V 女刀九臼山朝西54C 又巴马，丢矢矣55X 慈母无心弓和匕，幼无力]]></content>
  </entry>
  <entry>
    <title><![CDATA[深入解读RabbitMQ工作原理及Java中简单使用]]></title>
    <url>%2F2018%2F07%2F16%2F%E6%B7%B1%E5%85%A5%E8%A7%A3%E8%AF%BBRabbitMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8AJava%E4%B8%AD%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引用: https://mp.weixin.qq.com/s/ryu-zD3U62m32BZdByNxng http://www.cnblogs.com/vipstone/RabbitMQ简介在介绍RabbitMQ之前首先介绍一下MQ ,MQ是什么? MQ全称是Message Queue.可以理解为消息队列的意思.简单的说就是消息以管道的方式进行传递 RabbitMQ是一个实现了AMQP(Advanced Message Queuing Protocol)高级消息队列协议的消息队列服务,用Erlang语音写成. 使用场景在我们秒杀抢购商品的时候,系统会提醒我们稍等排队中,而不是像几年前一样页面卡死或报错给用户. 像这种排队结算就是用到了消息队列机制,放入通道里面一个一个结算处理,而不是某个时间段突然涌入大批量的查询新增把数据库给搞宕机.所以RabbitMQ本质上起到的作用就是削峰填谷,为业务保驾护航. 为什么选择RabbitMQ现在市面上有很多MQ可以选择,比如ActiveMQ ZeroMQ Appche Qpid,那问题来了为啥要选择RabbitMQ? 1: 除了Qpid,RabbitMQ是唯一一个实现了AMQP标准的消息服务器;2: 可靠性,RabbitMQ的持久化支持,保证了消息的稳定性;3: 高并发,RabbitMQ使用了Erlang开发语言,Erlang是为电话交换机开发的语言,天生自带高并发光环,和高可用特性;4: 集群部署简单,正是因为Erlang使得RabbitMQ集群部署变得超级简单;5: 社区活跃度高,根据网上资料来看,RabbitMQ也是首选; 工作机制生产者 消费者和代理在了解消息通讯之前首先要了解3个概念:生产者 消费者和代理. 生产者:消息的创建者,负责创建和推送数据到消息服务器; 消费者:消息的接收方,用于处理数据和确认消息; 代理者:就是RabbitMQ本身,用于扮演”快递”的角色,本身不生产消息,只是扮演”快递”的角色. 消息发送原理首先你必须连接到Rabbit才能发布和消费消息,那怎么连接和发送消息呢? 你的应用程序和Rabbit Server之间会创建一个TCP连接,一旦TCP打开,并通过认证,认证就是你试图连接Rabbit之前发送的Rabbit服务器连接信息和用户名和密码,有点像程序连接数据库,使用Java有两种连接认证的方式,后面代码会详细介绍,一旦认证通过你的应用程序和Rabbit就创建了一条AMQP信道(Channel). 信道是创建在”真实”TCP上的虚拟连接,AMQP命令都是通过信道发送出去的,每个信道都会有唯一的ID,不论是发布消息,订阅队列或者介绍消息都是通过信道完成的. 为什么不通过TCP直接发送命令?对于操作系统来说创建和销毁TCP会话是非常昂贵的开销,假设高峰期每秒有成千上万条连接,每个连接都要创建一条TCP会话,这就造成了TCP连接的巨大浪费,而且操作系统每秒能创建的TCP也是有限的,因此很快就会遇到系统瓶颈. 如果我们每个请求都使用一条TCP连接,既满足了性能的需要,又能确保每个连接的私密性,这就是引入信道概念的原因. 你必须知道的RabbitMQ想要真正的了解Rabbit有些名词是你必须知道的. 包括:ConnectionFactory(连接管理器) Channel(信道)Exchange(交换器) Queue(队列) RoutingKey(路由键)BindingKey(绑定键) ConnectionFactory(连接管理器): 应用程序与Rabbit之间建立连接的管理器,程序代码中使用; Channel(信道) :消息推送使用的通道; Exchange(交换器) :用于接受 分配消息; Queue(队列): 用于存储生产者的消息; RoutingKey(路由键): 用于把生成者的数据分配到交换器上; bingdingKey(绑定键): 用于把交换器的消息绑带到队列上; 消息持久化Rabbit队列和交换器有一个不可告人的秘密,就是默认情况下重启服务器会导致消息丢失,那么怎么保证Rabbit在重启的时候不丢失呢?答案就是消息持久化. 当你把消息发送到Rabbit服务器的时候,你需要选择你是否要进行持久化,但这并不能保证Rabbit能重崩溃中恢复,想要Rabbit消息能恢复必须要满足3个条件: 投递消息的时候durable设置为true,消息持久化; 消息已经到达持久化交换器上; 消息已经到达持久化的队列; 持久化工作原理Rabbit会将你的持久化消息写入磁盘上的持久化日志文件,等消息被消费后,Rabbit会把这条消息标识为等待垃圾回收. 持久化的缺点消息持久化的优点显而易见,但缺点也很明显,那就是性能,因为要写入硬盘要比写入内存性能低很多,从而降低了服务器的吞吐量,尽管使用SSD硬盘可以使事情得到缓解,但他仍然吸干了Rabbit的性能,当消息成千上万条要写入磁盘的时候,性能是很低的. 所以使用者要根据自己的的情况,选择适合自己的方式. 虚拟主机每个Rabbit都能创建很多vhost,我们称之为虚拟主机,每个虚拟主机其实都是mini版的RabbitMQ,拥有自己的队列,交换器和绑定,拥有自己的权限机制. 环境搭建如果你是在Windows10上去安装那就更简单了，先放下载地址： Erlang/Rabbit Server百度网盘链接：https://pan.baidu.com/s/1TnKDV-ZuXLiIgyK8c8f9dg 密码：wct9 当然也可去Erlang和Rabbit官网去下，就是速度比较慢。我的百度云Rabbit最新版本：3.7.6，Erlang版本：20.2，注意：不要下载最新的Erlang，在Windows10上打开扩展插件有问题，打不开。 1.安装Erlang； 2.安装Rabbit Server； 3.进入安装目录sbin下，使用命令“rabbitmq-plugins enable rabbitmq_management”启动网页管理插件； 4.重启Rabbit服务； 使用：http://localhost:15672进行测试，默认的登陆账号为：guest，密码为：guest 重复安装Rabbit Server的坑如果不是第一次在Windows上安装Rabbit Server一定要把Rabbit和Erlang卸载干净之后，找到注册表：HKEY_LOCAL_MACHINESOFTWAREEricssonErlangErlSrv 删除其下的所有项。 不然会出现Rabbit安装之后启动不了的情况，理论上卸载的顺序也是先Rabbit在Erlang。 代码实现java版实现,使用maven项目. 项目创建成功之后,添加Rabbit Client jar包,只需要在pom.xml里面配置,如下信息: &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;4.7.0&lt;/version&gt; &lt;/dependency&gt;java实现代码分为两个类,第一个是创建Rabbit连接,第二是应用类使用最简单的方式发布和消费消息. Rabbit的连接,两种方式:方式一: public static Connection GetRabbitConnection() { ConnectionFactory factory = new ConnectionFactory(); factory.setUsername(Config.UserName); factory.setPassword(Config.Password); factory.setVirtualHost(Config.VHost); factory.setHost(Config.Host); factory.setPort(Config.Port); Connection conn = null; try { conn = factory.newConnection(); } catch (Exception e) { e.printStackTrace(); } return conn; }方式二: public static Connection GetRabbitConnection() { ConnectionFactory factory = new ConnectionFactory(); // 连接格式：amqp://userName:password@hostName:portNumber/virtualHost String uri = String.format( &quot;amqp://%s:%s@%s:%d%s&quot;, Config.UserName, Config.Password, Config.Host, Config.Port, Config.VHost); Connection conn = null; try { factory.setUri(uri); factory.setVirtualHost(Config.VHost); conn = factory.newConnection(); } catch (Exception e) { e.printStackTrace(); } return conn; }第二部分: 应用类,使用最简单的方式发布和消费消息public static void main(String[] args) { Publisher(); // 推送消息 Consumer(); // 消费消息 } /** * 推送消息 */ public static void Publisher() { // 创建一个连接 Connection conn = ConnectionFactoryUtil.GetRabbitConnection(); if (conn != null) { try{ // 创建通道 Channel channel = conn.createChannel(); // 声明队列【参数说明：参数一：队列名称，参数二：是否持久化；参数三：是否独占模式；参数四：消费者断开连接时是否删除队列；参数五：消息其他参数】 channel.queueDeclare(Config.QueueName, false, false, false, null); String content = String.format(&quot;当前时间: %s&quot;,new Date().getTime()); // 发送内容【参数说明：参数一：交换机名称；参数二：队列名称，参数三：消息的其他属性；参数四：消息主体】 channel.basicPublish(&quot;&quot;, Config.QueueName, null, content.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;已发送消息：&quot; + content); // 关闭连接 channel.close(); conn.close(); } catch(Exception e) { e.printStackTrace(); } } } /** * 消费消息 */ public static void Consumer() { // 创建一个连接 Connection conn = ConnectionFactoryUtil.GetRabbitConnection(); if(conn != null) { try { // 创建通道 Channel channel = conn.createChannel(); // 声明队列[参数说明:1:队列名称,2:是否持久化,3:是否独占模式,4:消费者断开连接时是否删除队列,5:消息其他参数] channel.queueDelare(Config.QueueName,false,false,false,null); //创建订阅器,并接受消息 channel.basicConsume(Config.QueueName,false,&quot;&quot;,new DefaultConsumer(channel) { @Overrride public void handleDelivery( String consumerTag, Envelope envelope, AMQP.BasicPropeties properties, byte[] body) throws IOException { String routingKey = envelope.getRoutingkey(); // 队列名称 String contentType = properties.getContentType(); // 内容类型 String content = new String(body,&quot;utf-8&quot;); // 消息正文 System.out.println(&quot;消息正文:&quot; + content); channel.basicAck(envelope.getDeliveryTag(),false); // 手动确认消息(参数1:该消息的index;2:是否批量应答,true批量确认小于index的消息) } }); } catch(Exception e) { e.printStackTrace(); } } }代码里面已经写了很详细的注释，在这里也不过多的介绍了。 执行效果，如图：]]></content>
      <categories>
        <category>rabbitMQ</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不止代码]]></title>
    <url>%2F2018%2F07%2F06%2F%E4%B8%8D%E6%AD%A2%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[不止代码理解 将学到的东西真正试试,才能理解更加深刻. I hear and i forget .I see and i remember.I do and i understand.]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicInteger原理分析]]></title>
    <url>%2F2018%2F07%2F04%2FAtomicInteger%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[AtomicInteger通俗的讲就是:对某个内存值拷贝一个副本,某个线程若读到这个副本,则对其进行计算,输出结果,在写入内存时,再次取出内存值与该副本比较,若副本与内存值相同则把新的值写入内存. 较为官方的解释:通过CAS(AtomicInteger)实现, CAS算法CAS有三个操作数,内存值V,旧的预期值A,要修改的新值B.当且仅当预期值A和内存值V相同时,将内存值V修改为B,否则什么都不做. 两个问题:(1) CAS算法仍然可能出现冲突,例如A,B两个线程,A已经进入写内存但未完成，此时A读取到的副本且读取成功，AB两个线程同时进入写内存操作，必然会造成冲突。 CAS算法本质并非完全无锁，而是把获得锁和释放锁推迟至CPU原语实现，相当于尽可能的缩小了锁的范围；直接互斥地实现系统状态的改变，它的使用基本思想是copy-on-write——在修改完对象的副本之后再用CAS操作将副本替换为正本。 (2)ABA问题，若其中一个线程修改A-&gt;B-&gt;A，另外一个线程仍然读取到A，虽然值是预期值，但并不能说明该内存值没有变化。]]></content>
      <tags>
        <tag>AtomicInteger</tag>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicInteger类的理解与使用]]></title>
    <url>%2F2018%2F07%2F04%2FAtomicInteger%E7%B1%BB%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引用:https://blog.csdn.net/u012734441/article/details/51619751 首先看两段代码，一段是Integer的，一段是AtomicInteger的，为以下： public class Sample1 { private static Integer count = 0; synchronized public static void increment() { count++; } }以下是AtomicInteger的： public class Sample2 { private static AtomicInteger count = new AtomicInteger(0); public static void increment() { count.getAndIncrement(); } }对比发现:使用Integer时必须加上synchronized保证不会出现并发线程同时访问的情况,而AtomicInteger中却不用加上synchronized,在这里AtomicInteger是提供原子操作的. AtomicInteger是一个提供原子操作的Integer类，通过线程安全的方式操作加减。 AtomicInteger使用场景 AtomicInteger提供原子操作来进行Integer的使用，因此十分适合高并发情况下的使用。 AtomicInteger源码部分讲解 public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try{ valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception e) { throw new Error(ex); } } private volatile int value; }以上为AtomicInteger中的部分源码，在这里说下其中的value，这里value使用了volatile关键字，volatile在这里可以做到的作用是使得多个线程可以共享变量，但是问题在于使用volatile将使得VM优化失去作用，导致效率较低，所以要在必要的时候使用，因此AtomicInteger类不要随意使用，要在使用场景下使用。 AtomicInteger实例使用以下就是在多线程情况下，使用AtomicInteger的一个实例，这段代码是借用IT宅中的一段代码。 public class AtomicTest { static long randomTime() { return (long) (Math.random() * 1000); } public static void main(String[] args) { // 阻塞队列，能容纳100个文件 final BlockingQueue&lt;File&gt; queue = new LinkedBlockingQueue&lt;File&gt;(100); // 线程池 final ExecutorService exec = Executors.newFixedThreadPool(5); final File root = new File(&quot;D:\\ISO&quot;); // 完成标志 final File exitFile = new File(&quot;&quot;); // 原子整型，读个数 // AtomicInteger可以在并发情况下达到原子化更新，避免使用了synchronized，而且性能非常高。 final AtomicInteger rc = new AtomicInteger(); // 原子整型，写个数 final AtomicInteger wc = new AtomicInteger(); // 读线程 Runnable read = new Runnable() { public void run() { scanFile(root); scanFile(exitFile); } public void scanFile(File file) { if (file.isDirectory()) { File[] files = file.listFiles(new FileFilter() { public boolean accept(File pathname) { return pathname.isDirectory() || pathname.getPath().endsWith(&quot;.iso&quot;); } }); for (File one : files) scanFile(one); } else { try { // 原子整型的incrementAndGet方法，以原子方式将当前值加 1，返回更新的值 int index = rc.incrementAndGet(); System.out.println(&quot;Read0: &quot; + index + &quot; &quot; + file.getPath()); // 添加到阻塞队列中 queue.put(file); } catch (InterruptedException e) { } } } }; // submit方法提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future。 exec.submit(read); // 四个写线程 for (int index = 0; index &lt; 4; index++) { // write thread final int num = index; Runnable write = new Runnable() { String threadName = &quot;Write&quot; + num; public void run() { while (true) { try { Thread.sleep(randomTime()); // 原子整型的incrementAndGet方法，以原子方式将当前值加 1，返回更新的值 int index = wc.incrementAndGet(); // 获取并移除此队列的头部，在元素变得可用之前一直等待（如果有必要）。 File file = queue.take(); // 队列已经无对象 if (file == exitFile) { // 再次添加&quot;标志&quot;，以让其他线程正常退出 queue.put(exitFile); break; } System.out.println(threadName + &quot;: &quot; + index + &quot; &quot; + file.getPath()); } catch (InterruptedException e) { } } } }; exec.submit(write); } exec.shutdown(); } }AtomicInteger使用总结AtomicInteger是在使用非阻塞算法实现并发控制，在一些高并发程序中非常适合，但并不能每一种场景都适合，不同场景要使用使用不同的数值类。]]></content>
      <tags>
        <tag>AtomicInteger</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA开发快捷键(IDEA tool Keyboard shutcuts)]]></title>
    <url>%2F2018%2F07%2F04%2FIntelliJ-IDEA%E5%BC%80%E5%8F%91%E5%BF%AB%E6%8D%B7%E9%94%AE-IDEA-tool-Keyboard-shutcuts%2F</url>
    <content type="text"><![CDATA[IDEA tool Keyboard shutcuts： Action Mac OSX Win/Linux 注释代码(//) Cmd + / Ctrl + / 注释代码(/**/) Cmd + Option + / Ctrl + Shift + / 格式化代码 Cmd + Option + L Ctrl + Alt + L 清除无效包引用 Option + Control + O Alt + Ctrl + O 查找 Cmd + F Ctrl + F 查找+替换 Cmd + R Ctrl + R 上下移动代码 Option + Shift + Up/Down Alt + Shift + Up/Down 删除行 Cmd + Delete Ctrl + Y 扩大缩小选中范围 Option + Up/Down Ctrl + W/Ctrl + Shift + W 快捷生成结构体 Cmd + Option + T Ctrl + Alt + T 快捷覆写方法 Cmd + O Ctrl + O 快捷定位到行首/尾 Cmd + Left/Right Ctrl + Left/Right 折叠展开代码块 Cmd + Plus,Minus Ctrl + Plus/Minus 折叠展开全部代码块 Cmd + Shift + Plus,Minus Ctrl + Shift + Plus,Minus 文件方法结构 Cmd + F12 Ctrl + F12 查找调用的位置 Ctrl + Option + H Ctrl + Alt + H 大小写转换 Cmd + Shift + U Ctrl + Shift + U 找到使用 Alt+F7 Alt+F7 显示使用 Ctrl+Alt+F7 Ctrl+Alt+F7]]></content>
      <tags>
        <tag>idea</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php中unset详解]]></title>
    <url>%2F2018%2F06%2F20%2Fphp%E4%B8%ADunset%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[unset()经常会被用到,用于销毁指定的变量,但它有自己的行为模式,如果不仔细的话可能被中文解释给迷惑: 先来看看官方文档的说法: unset —- unset a given variable void unset(mixed $var [,mixed $…]); parameters: var:The variable to be unset. //要unset的变量 …Anther variable… // 其他需要unset的变量 return Values:No value is returned. //unset不返回值 Because this is a language construct and not a function,itcannot be called using variable functions //unset()是语言结构,不是函数,因此不能被函数变量调用,具体参照函数变量. 使用function_exists(‘unset’)返回的false,以此证明unset并不是一个函数,所以无法使用$fun=’unset’;$fun()的方式调用unset() it is possible to unset even object properties visible in current context. // 通用环境下unset可以销毁对象或者对象的可见属性(public) It is not possible to unset $this inside on object method since PHP5 // 在PHP5之前unset无法销毁对象中的$this方法 when using unset() on inaccessible object properties,the _unset()overloading method will be called,if declare. 当unset()无法销毁对象中的属性,例如私有属性,保护属性,那么会自动加载对象中的_unset方法. description: unset()destroys the specified variables. //unset()销毁指定的变量 The behavior of unset()inside of a function can vary depending on what type of variable you are attempting to destroy. // unset()的行为在函数内部可以根据你所指定销毁的变量类型变化. 情况一: if a globalized variable is unset() inside of a function,only the localvariable is destroyed.The variable in the calling environment willretain the same value as before unset() was called. 如果在函数内使用一个global使其全局化的变量,使用unset进行销毁,那么只有局部的变量会被销毁,在调用环境的变量将会保留没有unset()销毁之前的调用的变量值. the example: &lt;?php function destroy_foo() { global $foo; unset($foo); } $foo = &apos;bar&apos;; destroy_foo(); echo $foo; ?&gt; the above example will output:bar 这是官方文档的例子,可能这样还是不太明显,把上面的例子改成下面这样,一切就很清晰了. &lt;?php function des(){ global $foo; $foo=&apos;bars&apos;; unset($foo); echo $foo; } $foo=&apos;bar&apos;; echo &quot;The globalized variable is unset() inside of a function:&quot;; des(); echo &quot;&lt;br/&gt;&quot;; echo &quot;The variable in the calling environment:&quot;; echo $foo;]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>unset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode]]></title>
    <url>%2F2018%2F05%2F31%2FLeetCode%2F</url>
    <content type="text"><![CDATA[两数之和给定一个整数数组和一个目标值，找出数组中和为目标值的两个数。 你可以假设每个输入只对应一种答案，且同样的元素不能被重复利用。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1]分析: 思路一：暴力解法，两次for循环，遍历所有可能，这也是容易想到的方法，时间复杂度O(n^2),空间复杂度O(1); 思路二：利用哈希表，每次存储target减去当前数的差值(key)，当前值的下标(value)，当再碰到这个值时，即找到了符合要求的值。时间复杂度O(n),空间复杂度O(n);代码: 1: //思路一暴力解法 public int[] twoSum(int[] nums, int target) { // write your code here int[] a = new int[2]; for (int i = 0; i &lt; nums.length - 1; i++){ // 注意j等于i + 1;若j = 1则循环顺序不对 for (int j = i + 1; j &lt; nums.length; j++ ){ if (nums[i] + nums[j] == target){ a[0] = i; a[1] = j; break; } } } return a; }2: //思路二利用哈希表 public int[] twoSum(int[] nums, int target) { int[] a = new int[2]; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for (int i = 0; i &lt; nums.length; i++){ if (map.containsKey(nums[i])){ a[0] = map.get(nums[i]); a[1] = i; return a; } map.put(target - nums[i], i); } return a; }两数相加给定两个非空链表来表示两个非负整数。位数按照逆序方式存储，它们的每个节点只存储单个数字。将两数相加返回一个新的链表。 You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. 示例： 输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 原因：342 + 465 = 807结题思路方法: 初等数学 我们是有变量来跟踪进位,并从包含最低有效位的表头开始模拟逐位相加的过程. 如图所示,对两数相加方法的可视化:342 + 465 = 807,每个节点都包含一个数字,并且数字按位逆序存储. 算法 就像你在纸上计算两个数字的和那样,我们首先从最低有效位也就是列表l1和l2的表头开始相加.由于每位数字都应当处于0…9的范围内,我们计算两个数字的和时可能会出现”溢出”.例如:5+7 = 12.在这种情况下,我们会将当前位的数值设置为2,并将进位carry = 1带入下一次迭代.进位carry必定是0或者1,这是因为两个数字相加(考虑到进位)可能出现的的最大和为9+ 9+1=19 伪代码如下: 将x设为节点p的值.如果p已经到达l1的末尾,则将其设置为0. 将y设为节点q的值,如果q已经到达l2的末尾,则将其设置为0. 设定sum = x + y + carry. 更新进位的值,carry = sum/10. 创建一个数值为(sum mod 10) 的新节点,并将其设置为当前节点的下一个节点,然后将当前节点 前进到下一个节点. 同时,将p和q前进到下一个节点. 检查carry = 1是否成立,如果成立,则向返回列表追加一个含有数字1的新节点. 返回哑节点的下一个节点. 请注意我们使用哑节点来简化代码.如果没有哑节点,则必须编写额外的条件语句来初始化表头的值. 请特别注意以下的情况: 测试用例 说明 l1 = [0,1] l2 = [0,1,2] 当一个列表比另一个列表长时 l1 = [] l2 = [0,1] 当一个列表为空时,即出现空列表 l1 = [9,9] l2 = [1] 求和运算最后可能出现额外的进位,这一点很容易被遗忘 复杂度分析 时间复杂度: O(max(m,n)),假设m和n分别表示l1和l2的长度,上面的算法最多重复max(m,n)次. 空间复杂度: O(max(m,n)),新列表的长度最多为max(m,n) + 1. 拓展 如果链表中的数字不是按逆序存储的呢?例如:(3-&gt;4-&gt;2) + (4-&gt;6-&gt;5) = 8-&gt;0-&gt;7 代码(java)/** * Definition for singly-linked list. * public class ListNode { * int val; * LsitNode next; * ListNode (int x) { val = x;} * } */ class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead = new ListNode(0); ListNode p = l1, q = l2, curr = dummyHead; int carry =0; //进位 while (p != null || q != null) { int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = x + y + carry; carry = sum/10; curr.next = new listNode(sum%10); curr = curr.next; if(p != null) p=p.next; if(q != null) q=q.next; } if(carry&gt;0) { curr.next = new ListNode(carry); } return dummyHead.next; } }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境变量总结]]></title>
    <url>%2F2018%2F05%2F28%2Flinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[引用https://www.jianshu.com/p/ac2bc0ad3d74Linux是一个多用户多任务的操作系统,可以在Linux中为不同的用户设置不同的运行环境,具体做法是设置不同用户的环境变量. Linux环境变量分类一 按照生命周期来分,Linux环境变量可以分为两类:1 永久的:需要用户修改相关的配置文件,变量永久生效.2 临时的:用户利用export命令,在当前终端下声明环境变量,关闭shell终端失效. 二 按照作用域来分,Linux环境变量可以分为:1 系统环境变量:系统环境变量对系统中的所有用户都有效.2 用户环境变量:顾名思义,这种类型的环境变量只对特定的用户有效. Linux设置环境变量的方法一 在/etc/profile文件中增加变量,改变量将会对Linux下所有用户有效,并且是永久的. example: vim /etc/profile export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib注意:修改文件后要想马上生效还要运行$ source ~/.bash_profile不然只能在下次重进此用户是生效. 二 在用户目录下的.bash_profile文件中增加变量[对单一用户生效(永久的)]用vim ~/.bash_profile文件中增加变量,改变仅会对当前用户有效,并且是”永久的”. vim ~/.bash.profile export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib注意:修改文件后要想马上生效还要运行$ source ~/.bash_profile不然只能在下次重进此用户时生效. 三 直接运行export命令定义变量[只对当前shell(bash)有效(临时的),]在shell的命令行下直接使用 export 变量名=变量值定义变量，该变量只在当前的shell（BASH）或其子shell（BASH）下是有效的，shell关闭了，变量也就失效了，再打开新shell时就没有这个变量，需要使用的话还需要重新定义。 Linux环境变量使用一 Linux中常见的环境变量有: PATH :指定命令的搜索路径 PATH声明用法: PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------:&lt;PATH n&gt; export PATH 你可以自己加上指定的路径,中间用冒号隔开.环境变量更改后,在用户下次登录时生效. echo $path 查看当前系统path路径 HOME: 指定用户的主工作目录(即用户登陆到Linux系统中时,默认的用户目录) HISTSIZE: 指保存历史命令记录的条数. LOGNAME: 指当前用户的登陆名. HOSTNAME: 指定主机的名称,许多应用程序如果用到主机名的话,通常是从这个环境变量中来取得的 SHELL: 指当前用户用的是哪种shell. LANG/LANGUGE: 和语言相关的环境变量,使用多种语言的用户可以修改此环境变量. MAIL: 指当前用户的邮件存放目录. 注意:上述变量的名字并不固定,如:HOSTNAME在某些Linux系统中可能设置成HOST 二 Linux也提供了修改和查看环境变量的命令,下面通过几个实例来说明: echo 显示某个环境变量值 echo $PATH export 设置一个新的环境变量 export HELLO=”hello”(可以无引号) env 显示所有环境变量 set 显示本地定义的shell变量 unset 清除环境变量 unset HELLO readonly 设置只读环境变量 readonly HELLO 三 C程序调用环境变量函数 getenv() 返回一个环境变量. setenv() 设置一个环境变量. unsetenv() 清除一个环境变量.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!]]></title>
    <url>%2F2018%2F05%2F11%2FWARNING-REMOTE-HOST-IDENTIFICATION-HAS-CHANGED%2F</url>
    <content type="text"><![CDATA[参考: https://blog.csdn.net/nahancy/article/details/51052127问题On branch masternothing to commit, working tree clean@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the DSA key sent by the remote host isSHA256:br9IjFspm1vxR3iA35FWE+4VTyz1hYVLIE2t1/CeyWQ.Please contact your system administrator.Add correct host key in /Users/xiongzixu/.ssh/known_hosts to get rid of this message.Offending RSA key in /Users/xiongzixu/.ssh/known_hosts:1DSA host key for github.com has changed and you have requested strict checking.Host key verification failed.fatal: Could not read from remote repository. Please make sure you have the correct access rightsand the repository exists. 原因:找了好久发现有篇文章里面提到.ssh/known_hosts文件,原来known_hosts是记录远程主机的公钥的文件，之前更新了系统，而保存的公钥还是未重装系统的系统公钥，在ssh链接的时候首先会验证公钥，如果公钥不对，那么就会报错 解决方案(3种): 1: 使用shh-keygen 命令（强烈建议使用此方法） 比如我们要将172.16.152.209的公钥信息清除，使用命令（请自己将172.16.152.209替换成自己的IP或域名）： 2: 将known_hosts文件中的与登录错误的IP的公钥删除即可，下图就是我的218机子的公钥（实则是之前系统的公钥），然后将其删除，再ssh 登录 great 登录成功了。 3: 将known_hosts文件中的内容清空即可，但不建议使用此方法，里面还保存有其他机子的公钥。]]></content>
      <categories>
        <category>异常处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mac下chrome快捷键]]></title>
    <url>%2F2018%2F05%2F09%2Fmac%E4%B8%8Bchrome%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Chrome在grwin环境下的刷新是F5,强制刷新是Ctrl+F5 Mac下Chrome的刷新是command+R,强制刷新为command+shift+R option+shift+可以打出(logo) 引用 https://blog.csdn.net/fjh658/article/details/8860967标签页和窗口快捷键 按键 作用 ⌘+N 打开新窗口 ⌘+T 打开新标签 ⌘+shift+N 在隐身模式下打开新窗口 按 ⌘+O，然后选择文件 在 Google Chrome 浏览器中打开计算机中的文件。 按住 ⌘ 键，然后点击链接。或用鼠标中键（或鼠标滚轮）点击链接。 从后台在新标签页中打开链接。 按住 ⌘+Shift 键，然后点击链接。或按住 Shift 的同时用鼠标中键（或鼠标滚轮）点击链接。 在新标签页中打开链接并切换到刚打开的标签页。 按住 Shift 键，然后点击链接。 在新窗口中打开链接。 ⌘+Shift+T 重新打开上次关闭的标签页。Google Chrome 浏览器可记住最近关闭的 10 个标签页。 将标签页拖出标签栏。 在新窗口中打开标签页。 将标签页从标签栏拖到现有窗口中。 在现有窗口中打开标签页。 同时按 ⌘+Option 和左或右箭头键。 左右切换标签页。 ⌘+W 关闭当前标签页或弹出窗口。 ⌘+Shift+W 关闭当前窗口。 ⌘+Y 打开历史记录 按 Delete 或 ⌘-[ 转到当前标签页的上一页浏览历史记录。 按 Shift-Delete 或 ⌘-] 。 转到当前标签页的下一页浏览历史记录。 按住 Shift，然后点击窗口左上方的 + 按钮。 最大化窗口。 ⌘+M 最小化窗口。 ⌘+H 隐藏chrome浏览器 ⌘+option+H 隐藏其他所有窗口 ⌘+Q 关闭浏览器 ⌘+Shift+B 打开和关闭书签栏 ⌘+Option+B 打开书签管理器 ⌘- 打开偏好设置对话框 ⌘+Y 打开历史记录 ⌘+shift+J 打开下载内容页面 ⌘+shift+delete 打开清除浏览记录对话框 ⌘+shift+M 在多个用户之间切换 输入搜索词,然后按Enter 使用默认搜索引擎进行搜索 输入搜索引擎关键字,按空格键,再输入搜索字词,再按Enter 使用与关键字相关联的搜索引擎进行搜索 首先输入搜索引擎网址,然后在系统提示时按Tab,输入搜索字词,再按Enter 使用与网址相关联的搜索引擎进行搜索 输入网址，然后按 ⌘-Enter。 在新后台标签页中打开网址。 ⌘-L 突出显示网址。 ⌘-Option-F 将“?”置于地址栏中。在问号后输入搜索字词可用默认搜索引擎执行搜索。 同时按 Option 和向左箭头键。 将光标移到地址栏中的前一个关键字词 同时按 Option 和向右箭头键。 在地址栏中将光标移到下一个关键字词 同时按 Shift-Option 和向左箭头键。 在地址栏中突出显示上一关键字词 同时按 Shift-Option 和向右箭头键。 在地址栏中突出显示下一关键字词 ⌘-Delete 在地址栏中删除光标前的关键字词 用键盘上的方向键从地址栏下拉菜单中选择一个条目，然后按 Shift-Fn-Delete。 从浏览历史记录中删除所选条目（如果可以）。 ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt ⌘+ tt]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
        <tag>mac</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hhkb配置Mac]]></title>
    <url>%2F2018%2F05%2F07%2Fhhkb%E9%85%8D%E7%BD%AEMac%2F</url>
    <content type="text"><![CDATA[引用https://www.douban.com/note/657191565/Pro2,总共有60个 按键 方向键为 上: Fn + [ 下: Fn + / 左: Fn + ; 右: Fn + ‘ 光标移动的快捷键就和Mac系统一致: 上一行: ctrl+p 下一行: ctrl+n 跳到行首: ctrl+a]]></content>
      <tags>
        <tag>键盘</tag>
        <tag>hhkb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客备份]]></title>
    <url>%2F2018%2F05%2F05%2FHexo%E5%8D%9A%E5%AE%A2%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[参考：https://www.jianshu.com/p/57b5a384f234遇到的坑 CNAME必须放在source目录中不然会导致页面无法访问404 注意千万不要合并主干否则......你懂的]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下tar.gz,tar,bz2,zip等压缩与解压缩总结]]></title>
    <url>%2F2018%2F04%2F28%2FLinux%E4%B8%8Btar-gz-tar-bz2-zip%E7%AD%89%E5%8E%8B%E7%BC%A9%E4%B8%8E%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[tar命令基本用法:tar命令的选项有很多(用man tar可以查看到),常用的就下面几个 tar -cf all.tar *.jpg 这条命令是将所有.jpg的文件打成一个名为all.tar的包.-c是表示 生成新的包,-f指定包的文件名. tar -rf all.tar *.gif 这条命令是将所有.gif的文件增加到all.tar的包里面去.-r是表示增 加文件的意思. tar -uf all.tar logo.gif 更新原来all.tar中logo.gif文件,-u是表示更新文件的意思 tar -tf all.tar 列出all.tar中的所有文件,-u表示更新文件的意思 tar -xf all.tar 解出all.tar中的所有文件,-x是解开文件的意思 以上就是tar的最基本的用法,为了方便用户在打包解包的同时可以压缩或解压文件,tar提供了一种特殊的功能.就是tar可以在打包或解包的同时调用其他的压缩程序,比如调用gzip bzip2等. 1)tar调用gzipgzip是GNU组织开发的一个压缩程序,.gz结尾的文件是gzip压缩的结果.与gzip相对 的解压程序是gunzip.tar中使用-z这个参数来调用gzip tar -czf all.tar.gz *.jpg 将所有.jpg的文件打成一个tar包,并将其用gzip压缩,生成一个gzip压缩过的包,包名为all.tar.gz tar -xzf all.tar.gz 解压包 2) tar调用bzip2bzip2是一个压缩能力更强的压缩程序,.bz2结尾的文件是bzip压缩的结果. 与bzip相对的解压程序是bunzip2.tar中使用-j这个参数来调用gzip. tar -cjf all.tar.bz2 *.jpg 这条命令是将所有.jpg的文件打成一个tar包,并且将其用bzip2压缩,生成一个bzip2相对的压缩]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>tar</tag>
        <tag>压缩</tag>
        <tag>解压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.zip和.tar.gz的文件有什么区别]]></title>
    <url>%2F2018%2F04%2F27%2Fzip%E5%92%8C-tar-gz%E7%9A%84%E6%96%87%E4%BB%B6%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[转自:https://blog.csdn.net/suyu_yuan/article/details/52733117.tar.gz 压缩格式用于unix的操作系统,但在windows系统中用WinRar工具 同样可以解压缩tar.gz格式的 zip流行于windows系统上的压缩文件(其他系统也可以打开).zip格式开发且 免费.zip支持分卷压缩,128/256-bitAES加密算法等功能.zip的含义是速度,其 目标是为顶替ARC而诞生的”职业”压缩软件. tar是”table archive”(磁带存档)的简称,它出现在还没有软盘驱动器 硬盘和 光盘驱动器的计算机早期阶段,随着时间的推移,tar命令逐渐变为一个将很多文件 进行存档的工具,目前许多用于Linux操作系统的程序就是打包为tar档案文件的形式 .在Linux里面,tar一般和其他没有文件管理的压缩算法文件结合使用,用tar打包整 个文件目录结构成一个文件,再用gz,bzip等压缩算法压缩成一次,也是Linux常见的 压缩归档的处理方法.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu16.04The System is running in low-graphics mode终极解决办法]]></title>
    <url>%2F2018%2F04%2F26%2Fubuntu16-04_The_system_is_running_in_low_graphics_mode%E7%BB%88%E6%9E%81%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[问题: The system is running in low-graphics mode引用: https://blog.csdn.net/gpwner/article/details/79178832大道至简,找了好多答案,最后发现这种方法最简单 sudo apt update sudo apt upgrade]]></content>
      <categories>
        <category>异常处理</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux简介]]></title>
    <url>%2F2018%2F04%2F24%2FLinux%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Linux内核最初是由芬兰人李纳斯.托瓦兹(Linux Torvalds)在赫尔辛基上大学时出于个人爱好而编写的. Linux是一套免费使用和自由传播的类Unix操作系统.是一个基于POSIX和UNIX的多用户 多任务 支持多线 程和多CPU的操作系统. Linux能运行主要的UNIX工具软件 应用程序和网络协议.它支持32位和64位硬件.Linux继承了Unix以网络 为核心的设计思想,是一个性能稳定的多用户网络操作系统.Linux的发行版本Linux的发行版本简单说就是讲Linux内核与应用软件做一个打包. 目前市面上比较知名的发行版有:UbuntuReaHatCentOSDebianFeforaSuSEOpenSUSEArch LinuxSolusOSLinux 系统启动过程Linux系统的启动的启动过程分为5个阶段 内核的引导 运行init 系统初始化 建立终端 用户登录系统 init 程序的类型 SysV:init,CentOS5之前,配置文件: /etc/initab. Upstart:init,CentOS6,配置文件: /etc/inittab,/etc/init/*.conf. Systemd: systemd,CenOS 7配置文件: /user/lib/systemd/system /etc/systemd/system 内核引导当计算机打开电源后,首先是BIOS开机自检,按照BIOS中设置的启动设备(通常是硬盘)来启动.操作系统接管硬件以后,首先读入/boot目录下的内核文件 操作系统 —–&gt; boot —&gt; 运行initinit进程是系统所有进程的起点,你可以把它比拟成系统所有进程的老祖宗,没有这个进程,系统中任何进程都不会启动.init程序首先需要读取配置文件 /etc/inittab. 操作系统 —–&gt; boot —&gt; init进程 —&gt;运行级别 Linux系统有七个运行级别 0 : 系统停机状态,系统默认运行级别不能设为0,否则不能正常启动 1 : 单用户工作状态,root权限,用于系统维护,禁止远程登录 2 : 多用户状态(没有NFS) 3 : 完全的多用户状态,登录后进入控制台命令行模式 4 : 系统未使用,保留 5 : X11控制台,登录后进入图形GUI模式 6 : 系统正常关闭并重启,默认运行级别不能设为6,否则不能正常启动 系统初始化在init的配置文件中有这么一行: si:sysinit:/etc/rc.d/rc.sysint 它调用执行了 /etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit,而rc.sysinit是一个bash shell 的脚本 ,它主要是完成一些系统初始化的工作,rc.sysinit是每一个运行级别都 要首先运行的重要脚本. 它主要完成的工作有:激活交换区,检查磁盘,加载硬件模块以及其他一些需要优先执行 任务. 15:5:wait:/etc/rc.d/rc 5 这一行表示以5为参数运行/etc/rc.d/rc, /etc/rc.d/rc是一个shell脚本,它接收5作为参数 ,去执行/etc/rc.d/rc5.d/目录下的所有的rc启用脚本,/etc/rc.d/rc5.d/目录中的这些启动 脚本实际上都是一些连接文件,而不是真正的rc启动脚本,真正的rc启动脚本实际上都是放在 /etc/rc.d/init.d/目录下 而这些rc启动脚本有着类似的用法,它们一般能接受start stop restart status等参数. /etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件,用于以S开头的启动脚本 ,将以start参数来运行. 而如果发现存在相应的脚本也存在K打头的连接,而且已经处于运 行状态了(以/var/lock/subsys/下的文件为标志),则将首先以stop为参数停止这些已经启动 了的守护进程,然后再重新运行. 这样做是为了保证当init改变运行级别时,所有相关的守护进程将重启. 至于在每个运行级别中将运行哪些守护进程,用户可以通过chkconfig或setup中的 “System Services”来自行设定. 操作系统 —&gt; /boot —&gt; init进程 —&gt; 运行级别 —&gt; /etc/init.d 建立终端rc执行完毕后,返回init.这时基本系统环境已经设置好了,各种守护进程也已经启动了. init接下来会打开6个终端,以便用户登录系统.在inittab中的以下6行就是定义了6个终 端: 1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 从上面可以看出在2 3 4 5的运行级别中都将以 respawn 方式运行mingetty程序能打开终端 设置模式.同时它会显示一个文本登录界面,这个界面就是我们经常看到的登录界面,在这个等 录界面中会提示用户输入用户名,而用户输入的用户名将作为参数传给login程序来验证用户的 身份 用户登录系统一般来说,用户的登录方式有三种: 1 命令行登录 2 ssh登录 3 图形界面登录 操作系统 –&gt; /boot –&gt; init进程 –&gt; 运行级别 –&gt; /etc/init.d –&gt; 用户登录 对于运行级别为5的图形方式用户来说,他们的登录是通过一个图形化的登录界面.登录 成功后可以直接进入 KDE 或 Gnome 等窗口管理器 而本文主要讲的是文本登录:当我们看到mingetty的登录界面时,我们就可以输入用户名 和密码来登录系统了. Linux的账号验证程序是login,login会接收mingetty传来的用户名作为用户名参数. 然后login会对用户名进行分析:如果用户名不是root,且存在/etc/nologin文件,login 将输出nologin文件的内容,然后退出. 这通常用来系统维护时防止非root用户登录.只有/etc/securetty中登记了的终端才允许 root用户登录,如果不存在这个文件,则root用户可以在任何终端上登录. /etc/usetty文件用于对用户作出附加访问限制,如果不存在这个文件,则没有其他限制 图形模式与文字模式的切换方式Linux预设提供了六个命令 窗口终端机让我们来登录. 默认我们登录的就是第一个窗口,也就是tty1,这六个窗口分别为 tt1,tt2,tt3…tt6,你可以按下 Ctrl + Alt + F1 ~ F6 来切换它们 如果你安装了图形界面,默认情况下是进入图形界面的,此时你就可以按Ctrl+Alt+F1~F6来进入其中一个命令窗口界面.当你进入命令窗口界面后再返回图形界面只要按下 Ctrl + Alt + F7就回来了 如果你用的vmware虚拟机,命令窗口切换的快捷键位Alt+Space+F1~F6.如果你在图形界面下 请按Alt+Shift+Ctrl+F1~F6切换至命令窗口. 操作系统 –&gt; /boot –&gt; init进程 –&gt; 运行级别 –&gt; /etc/init.d | | login shell &lt;–用户登录 Linux 关机在Linux领域内大多用再服务器上,很少遇到关机的操作,毕竟服务器上跑一个服务时永无止境的,除非特殊情况下,不得已才会关机. 正确的关机流程为 : sync &gt; shutdown &gt; reboot &gt; halt 关机指令为 : shutdown,你可以man shutdown来看一下邦之文档. sync 将数据由内存同步到硬盘中 shutdown 关机指令,你可以man shutdown来看一文档 shutdown -h 10 10分钟后关机 shutdown -h now 立马关机 shutdown -h 20:25 系统会在今天20:25关机 shutdown -h +10 十分钟后关机 shutdown -r now 立马重启 shutdown -r +10 十分钟后重启 reboot 重启,等同于 shutdown -r now halt 关闭系统,等同于 shutdown -h now 和 poweroff 最后总结一下，不管是重启系统还是关闭系统，首先要运行 sync 命令，把内存中的数据写到磁盘中。关机的命令有 shutdown –h now halt poweroff 和 init 0 , 重启系统的命令有 shutdown –r now reboot init 6。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS防火墙设置与端口开放的方法]]></title>
    <url>%2F2018%2F04%2F23%2FCentOS%E9%98%B2%E7%81%AB%E5%A2%99%E8%AE%BE%E7%BD%AE%E4%B8%8E%E7%AB%AF%E5%8F%A3%E5%BC%80%E6%94%BE%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Centos升级到7后,内置的防火墙已经从iptables变成了firewalld,所以,端口 的开启还是要从两种情况来说明的,即iptables和firewalld. 更多内容请参考Rehat官网iptables开启防火墙(重启后永久有效) : chkconfig iptables on 关闭防火墙(重启后永久有效) : chkconfig iptables off 开启防火墙(即时生效,重启后失效) : service iptables start 关闭防火墙(即时生效,重启后失效) : service iptables stop 重启防火墙 :service iptables restartd 查看打开的端口 /etc/init.d/iptables status 打开某个端口(以8080为例) (1) 开启端口 iptables -A INPUT -p tcp --dport 8080 -j ACCEPT (2)保存并重启防火墙 /etc/rc.d/init.d/iptables save /etc/init.d/iptables restart 打开49152~65534之间的端口 iptables -A INPUT -p tcp --dport 49152:65534 -j ACCEPT 同样,这里需要对设置进行保存,并重启防火墙. 其他打开方式 我们还可以通过修改/etc/sysconfig/iptables文件方式开启端口,如下 vi /etc/sysconfig/iptables 然后再文件中增加一行 -A RH-Firewall-1-INPUT -m state -state NEW -m tcp -p tcp -dport 8080 -j ACCEPT 参数说明: -A 参数就看成是添加一条规则 -p 指定是什么协议,我们常用的tcp协议,当然也有udp,例如53端口的DNS -dport 就是目标端口,当数据从外部进入服务器为目标端口 -sport 数据从服务器出去,则为数据源端口使用 -j 就是指定是ACCEPT -接收或者DROP不接收firewalldCentos7默认安装了firewalld,如果没有安装的话,可以使用 yum install firewalld firewalld-config进行安装. 1启动防火墙 systemctl start firewalld 2 禁用防火墙 systemctl stop firewalld 3 设置开机启动 systemctl enable firewalld 4 停止并禁用开机启动 systemctl disable firewalld 5 重启防火墙 firewall-cmd --reload 6 查看状态 systemctl status firewalld或者 firewall-cmd --state 7查看版本 firewall-cmd --version 8查看帮助 firewall-cmd --help 9查看区域信息 firewall-cmd --get-active-zones 10查看指定接口所属区域信息 firewall-cmd --get-zone-of-interface=eth0 11 拒绝所有包 firewall-cmd --panic-on 12 取消拒绝状态 firewall-cmd --panic-off 13 查看是否拒绝 firewall-cmd --query-panic 14将接口添加到区域(默认接口都在public) firewall-cmd --zone=public --add-interface=eth0(永久生效再加上 --permanent 然后reload防火墙) 15 设置默认接口区域 firewall-cmd --set-default-zone=public(立即生效,无需重启) 16 更新防火墙规则 firewall-cmd --reload或firewall-cmd --complete-reload(两 者的区别就是第一个无需断开连接,就是firewalld特性之一动态 添加规则,第二个需要断开连接,类似重启服务) 17 查看指定区域所有打开的端口 firewall-cmd --zone=public --list-ports 18指定区域打开端口(记得重启防火墙) firewall-comd --zone=public --add-port=80/tcp(永久生效再加上 --permanent) 说明: -zone 作用域 -add-port=8080/tcp 添加端口,格式为:端口/通讯协议 -permanent #永久生效,没有此参数重启后失效 参考文章： http://havee.me/linux/2015-01/using-firewalls-on-centos-7.html]]></content>
      <tags>
        <tag>linux</tag>
        <tag>CentOS</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 远程连接22端口]]></title>
    <url>%2F2018%2F04%2F23%2FUbuntu-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A522%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[安装OpenSSHUbuntu缺省没有安装SSH Server,使用以下命令安装:sudo apt-get install openssh-server openssh-client配置完成后重启命令sudo /etc/init.d/ssh restart]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kotlin]]></title>
    <url>%2F2018%2F04%2F20%2FKotlin%2F</url>
    <content type="text"><![CDATA[引用: https://baike.baidu.com/item/Kotlin/1133714?fr=aladdinKotlin 是一个用于现代多平台应用的静态编程语言,有JetBrains开 发. Kotlin可以编译称为Java字节码,也可以编译成JavaScript,方便在没有 JVM的设备上运行. Kotlin已正式成为Android官方支持开发语言.简介JetBrains,作为广受欢迎的java IDE intelliJ的提供商,在Apache许可 下已经开源其Kotlin编程语言.设计目标创建一种兼容java的语言 让它比java更安全,能够静态检测常见的陷阱.如:引用空指针 让它比java更简洁,通过支持variable type inference,higher-order function(closures),extension functions,mixins and first-class delegation等实现. 让它比最成熟的竞争对手Scala语言更加简洁.开发源代码其基础编译器(他们将其改为kompiler---开创了一系列以K字打头的用语 ---甚至连 contributors这类词他们也用改成了kontributors)可以被独立 出来并嵌入到Maven Ant或Gradle工具链中,这使得在IDE中开发的代码能够 利用已有的机制来构建,从而尽可能的减少了在新环境中使用所受的干预,哪 怕与那些没有安装Kotlin插件的开发人员一起合作项目也没有问题. The Intellij Kotlin插件扩展了Java编译器使得Kotlin代码能够得以编写 编译和调试.除此之外,关于基本的Java集合,已经有编写好的帮助函数,可以 更顺畅地衔接在java8中出现的集合扩展. 有两篇文章对Kotlin与Java以及Scala分别进行了比较,对各自特性和异同进 行了对比.即便Scala可能还是更为强大些,Kotlin还是尝试提供比java更好 的函数 模式匹配 空指针预防和泛型.该语言同时支持特征(traits)和模式匹配 Kotlin插件在当前版本的IntelliJ和Eclipse中均已能使用. Kotlin,类似Xtend一样,旨在提供一种更好的java而非重建整个新平台.这两种 语言都向下编译为字节码(虽然Xtend是首先转换成相应的java代码,再让java 编译器完成繁重的工作),而且两者都引入了函数和扩展函数(在某个有限范围 内静态地增加一个新方法到某个已有类型的能力).Xtend是基于Eclipse的,而 Kotlin是基于IntelliJ的,两者都提供无界面构建.能够首先演变到其他IDE的语 言有可能成为最后的赢家.]]></content>
      <tags>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu Linux下安装软件方法]]></title>
    <url>%2F2018%2F04%2F20%2FUbuntu-Linux%E4%B8%8B%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引用: https://www.linuxidc.com/Linux/2015-01/111216.htmLinux系统中,软件通常以源代码或者编译包的形式提供. (1)源代码需要编译为二进制的机器码才能够使用,安装比较 耗时,不过您可以自行调节编译选项,决定需要的功能或组 件,或者针对硬件平台做一些优化. (2)预编译的软件包,通常是由软件的发布者进行编译,您只要 将软件拷贝到系统中就可以了.考虑到预编译软件包的适用性 ,预编译软件通常不会针对某种硬件平台优化.它所包含的功能 和组件也是通用的组合.1 deb包的安装方式deb是debian系Linux的包管理方式,Ubuntu是属于debian系的 Linux发行版,所以默认支持这种软件安装方式,当下载到一个 deb格式的软件后,在终端输入这个命令就能安装: sudo dpkg -i *.deb 或者直接双击安装.2 编译安装方式(小贴士: 使用编译安装前,需要建立编译环境,使用一下命令建立 基本的编译环境: sudo apt-get install bulid-essential) 在Linux的世界,有很多软件只提供了源代码给你,需要你自己进行 编译安装,一般开源的软件都会使用tar.gz压缩档来进行发布,当然 还有其他的形式,拿到源代码的压缩文档,把它解压缩到/tmp目录下 ,进入/tmp/软件目录,然后执行下三个命令: 1 ./configure 2 make 3 sudo make install 在第一步./configure时可能会提示说某某软件找不到,例如提示”libgnome”这个开发包找不到,那就把libgnome这个关键词copy,然后打开新立得软件管理器,在里面搜索libgnome这个关键词,就会找到libgnome相关的项目,把前面有个ubuntu符号的libgnome包(注意:同样需要安装dev包,但可以不装doc包)全部安装,通过这个方法把./configure过程中缺失的开发包全部装上就ok了,第一步顺利通过,第二三步基本问题不大. 3 apt-get安装方法ubuntu世界有许多软件源,在系统安装篇已经介绍过如何添加源,apt-get的基本 软件安装命令是: sudo apt-get install 软件名4 新立得软件包管理打开: 系统 --系统管理--新立得软件包管理,这个工具其实跟apt一样,可以搜索 ,下载,安装ubuntu源里的软件,具体安装方式很简单,看看界面应该会懂,就不详细 介绍了.5 二进制包的安装方式有不少开源的商业软件都会采用这种方式发布Linux软件,例如google earth,拿到 二进制软件后,把它放到/tmp目录,在终端下进入安装目录,在安装目录下执行: ./软件名 然后按照一步步提示,就能安装该软件.例如安装realplayer播放器:你直接到官网 http://www.real.com/linux 下载RealPayer的安装包,安装包是.bin格式,用如下 命令安装: chomd +x RealPlayer11GOLD.bin ./RealPlayer11GOLD.bin6 rpm包的安装方式rpm 包是deb包最常见的一种管理方式,但ubuntu同样可以使用rpm的软件资源.首先 我们安装一个rpm转deb的软件 sudo apt-get install alien 然后就可以对rpm格式的软件转换成deb格式了: alien -d *.rpm 然后就可以用deb的安装方式进行软件安装.也可以不需转换而直接对rpm包进行安装: alien -i *.rpm 更多的alien使用方法可以用-h参数查看相应说明文档.7 其他安装方式其他安装方式一般还有脚本安装方式,这类软件,你会在安装目录下发现类似后缀名的文件 ,如: .sh .py .run等的,有的甚至连后缀名都没有,直接一个INSTALL文件,对于这种软件, 可以尝试以下几种方式安装: 最简单的就是直接在软件目录下输入: ./软件名*(注意有一个*号,那是一般可以通配所有 后缀名) 或者: sh 软件名.sh 或者: python软件名.py TIP:如以上方法均无法安装软件,可以参考软件源代码下面的README文档.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learn Linux]]></title>
    <url>%2F2018%2F04%2F20%2FLearn-Linux%2F</url>
    <content type="text"><![CDATA[学习Linux问题与总结1 如何打开Ubuntu命令行工具 按快捷键,Ctrl+Alt+F2/F3/F4/F5/F6,后面的F2到6是或者的意思 然后会进入命令行的登录界面,这时候需要输入用户名和密码. 密码是不可见的,输入后直接回车即可 2 如何关闭Ubuntu命令行工具(即切换到桌面) 按快捷键,Ctrl+Alt+F7 3 Ubuntu下查看IP ifconfig -a 4 使用locale查看系统当前编码5 Ubuntu设置root用户初始密码安装ubuntu成功后,都是普通用户权限,并没有最高root权限如果需要root权限的时候,通常都会在命令前面加上sudo.有时 候感觉很麻烦... 我们一般使用su命令来直接切换到root用户的,但是如果没有设 置root初始密码,就会抛出su : Authentication failure这样的 问题.所以我们只要给root用户设置一个初始密码就好了. 输入sudo passwd命令,输入一般用户密码并设定root用户密码. 设定root密码成功后,输入su命令,并输入刚才设定的root密码, 就可以切换成root 了.提示符$代表一般用户,提示符#代表root用户 总结 sudo passwd 设置初始root用户密码 6 查看所有用户组$cat /etc/group ssl-cert:x:110:postgres 最前面一个字段ssl-cert是用户组名,最后一个字段postgres是用户名7 查看所有用户$sudo cat /etc/shadow postgres:$6$m8anDHdE$FDY4j0CdAbgeLOM90EH1xCW/IMqHEZwM87sepyHHjUYccdmFOCVaFealGTd2zGBVfDV.AR9CWTlGz0Sw/JivL1:15910:0:99999:7::: postgres是用户名8 远程连接Linux(Ubuntu配置SSH服务)端口22安装OpenSSH Ubuntu缺省没有安装SSH Server,使用一下命令安装: sudo apt-get install openssh-server openssh-client 不过Ubuntu缺省已经安装了ssh client. 配置完成后重启: sudo /etc/init.d/ssh restart windows客户端用putty连接命令shell模式9 如何查看Linux系统版本信息查看Linux内核版本命令(两种方式) cat /proc/version uname -a 查看Linux系统版本命令(3种方式) lsb_release -a 这个命令适用于所有的Linux发行版,包括ReHat SUSE Debian…等发行版 cat /etc/redhat-release, 这种方式只适合Redhat系的Linux cat /etc/issue 这种方式适用于所有的Linux发行版 10 ubuntu 安装 上传下载工具lrzszapt-get install lrzsz y11 Linux中运行.sh(Shell脚本)文件有两种方法: 1 直接./加文件名.sh,如运行hello.sh为./hello.sh[hello.sh必须有x权限] 2 直接sh加上文件名.sh,如运行hello.sh为sh hello.sh[hello.sh]可以没有x权限] 步骤 1 cd到.sh文件所在目录 2 给.sh文件添加x执行权限,已hello.sh文件为例 chmod u+x hello.sh 3 执行 ./hello.sh 或者 sh hello.sh 备注 绝对路径执行*.sh以hello.sh 为例 ./home/test/shell/hello.sh ,可以这样运行时因为当前登录用户是root,当前路径 是在/下,.代表当前路径. /home/test/shll/hello.sh,此路径为真实绝对路径,但此方法运行的条件是该用户对 hello.sh拥有执行权限,即已执行chmod u+x hello.sh sh/home/test/shell/hello.sh,用sh命令执行shell脚本不需要该用户拥有hello.sh的执行 权限即可执行.12 zip 或unzip的安装和使用Linux系统没有自带的压缩解压缩工具;需要我们自己安装;当用到zip或者unzip如果没有安装 就会出现unzip:Command Not Found 或 zip:Command Not Found; 1 apt-get安装: apt-get install zip 2 yum安装 yum install -y unzip zip13 虚拟机中CentOS无法上网(connect:network is unreachable)表现:ping时提示connet network is unreachable 原因: ifconfig发现网卡没有分配IP地址,考虑是DHCP的问题. 临时解决方案: sudo dhclient,发现可以上网,重启又没有IP了, 一劳永逸解决方案: 修改etc目录下网卡配置信息 vim /etc/sysconfig/network-scripts/ifcfg-[网络设备名] 发现最后一行的ONBOOT选项竟然是no,将其改为yes,然后就正常了.14 重启系统 reboot init 615 关机halt 立刻关机 poweroff 立刻关机 shutdown -h now 立刻关机(root用户使用) shutdown -h 10 10分钟后自动关机 如果是通过shutdown命令设置关机的话,可以用shutdown -c命令取消重启 推荐使用shutdown命令16 centOS安装lrzszyum install lrzsz]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php调用shell的方法]]></title>
    <url>%2F2018%2F04%2F20%2Fphp%E8%B0%83%E7%94%A8shell%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引用:http://www.jb51.net/article/57118.htm这篇文章主要介绍了PHP调用shell的方法,包括相关的原理 注意事项及函数的用法,需要的朋友可以参考下一 配置查看php.ini中配置是否打开安全模式,主要是以下三个地方 safe_mode = (这个如果是off下面两个就不用管了) disable_functions = safe_mode_exec_dir = 二使用由于PHP是基本是用于WEB程序开发的,所以安全性成了人们考虑的一个重要方面.于是PHP的设计者们给 PHP加了一个门:安全模式.如果运行在安全模式下,那么PHP脚本中将受到如下四个方面的限制: 执行外部命令 在打开文件时有些限制 连接MYSQL数据库 基于HTTP的认证 在安全模式下,只有在特定目录中的外部程序才可以被执行,对其他程序的调用将被拒绝.这个目录可以在 PHP.ini文件中用safe_model_exex_dir指令,或在编译PHP时加上–with-exec-dir选项来指定,默认是 /usr/local/php/bin. 如果你调用一个应该可以输出结果的外部命令(意思是PHP脚本没有错误),得到的却是一片空白,那么很可能 你的网管已经把PHP运行在安全模式下了. 三如何做在PHP中调用外部命令,可以用如下三种方法来实现: 1 ) 用PHP提供的专门函数 php提供了3个专门的执行外部命令的函数: system(),exec(),passthru().system()原型: string system(string command[,int return_var]) system()函数和其他语言中的差不多,它执行给定的命令,输出和返回结果.第二个参数是可选的,用来得到命令执行后的状态码. 例子: system(“/usr/local/bin/webalizer/webalizer”); exec()原型: string exex(string command[,string array[,int return_var]]) exec()函数与system()类似,也执行给定的命令,但不输出结果,而是返回结果的最后一行.虽然它只返回命令 结果的最后一行,但用第二个参数array可以得到完整的结果,方法是吧结果逐行追加到 array的结尾处.所 以如果array不是空的,在调用之前最好用unset()把它清掉.只有指定了第二个参数时,才可以用第三个参数,用来取得命令执行的状态码. 例子: exec(“/bin/ls -|”); exec(“/bin/ls -|”,$res);’ $res是一个数据,每个元素代表结果的一行 exec(“/bin/ls -|”,$res,$rc);’ $rc的值是命令/bin/ls -|的状态码.成功的情况下通常是0 passthru() 原型: void passthru(string command[,int return_var]) passthru()只调用命令,不返回任何结果,但把命令的运行结果原样 地直接输出到标准输出设备上.所以passthru()函数经常用来调用像 pbmplus(Unix下的一个处理图片的工具,输出二进制的原始图片的流) 这样的程序.同样它也可以得到命令执行的状态码. 例子 header(“Content-type:image/gif”); passthru(“./ppmtogif hunte.ppm”);]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My New Post]]></title>
    <url>%2F2018%2F04%2F20%2FMy-New-Post%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[learning-hexo]]></title>
    <url>%2F2018%2F03%2F29%2Flearning-hexo%2F</url>
    <content type="text"><![CDATA[this is a test test chapter 1chapter 2]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
